{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cryptography\n",
    "A Quality Read: [Crypto-IT](http://www.crypto-it.net/eng/index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Cryptography\n",
    "\n",
    "**What is cryptography?**\n",
    "> **Cryptography** is the practice and study of techniques for secure communication in the presence of third parties called adversaries. More generally, cryptography is about constructing and analyzing protocols that prevent third parties or the public from reading private messages; various aspects in information security such as **data confidentiality**, **data integrity**, **authentication**, and **non-repudiation** are central to modern cryptography. Modern cryptography exists at the intersection of the disciplines of mathematics, computer science, electrical engineering, communication science, and physics. Applications of cryptography include electronic commerce, chip-based payment cards, digital currencies, computer passwords, and military communications.\n",
    "\n",
    "Cryptography prior to the modern age was effectively synonymous with encryption, the conversion of information from a readable state to apparent nonsense. The originator of an encrypted message shared the decoding technique needed to recover the original information only with intended recipients, thereby precluding unwanted persons from doing the same. The cryptography literature often uses the name Alice (\"A\") for the sender, Bob (\"B\") for the intended recipient, and Eve (\"eavesdropper\") for the adversary. \n",
    "\n",
    "**History of Cryptography:**\n",
    "- Refer to the History segment inside the following PDF: Blockchain/CryptographyI/LectureSlides/Week1/Introduction.pdf\n",
    "- [History of Cryptography](https://www.tutorialspoint.com/cryptography/origin_of_cryptography.htm)\n",
    "\n",
    "**Modern Cryptography:**\n",
    ">Modern cryptography is heavily based on mathematical theory and computer science practice; **cryptographic algorithms are designed around computational hardness assumptions**, making such algorithms hard to break in practice by any adversary. It is theoretically possible to break such a system, but it is infeasible to do so by any known practical means. These schemes are therefore termed computationally secure; theoretical advances, e.g., improvements in integer factorization algorithms, and faster computing technology require these solutions to be continually adapted. There exist **information-theoretically secure** schemes that probably cannot be broken even with unlimited computing power—an example is the one-time pad—but these schemes are more difficult to implement than the best theoretically breakable but computationally secure mechanisms.\n",
    "\n",
    "More on: [Modern Cryptography](https://www.tutorialspoint.com/cryptography/modern_cryptography.htm)\n",
    "\n",
    "**Cryptology:**<br>\n",
    "The art of devising ciphers (i.e cryptography) and breaking them i.e., cryptanalysis) is collectively known as cryptology.\n",
    "\n",
    "**Cryptanalysis:**<br>\n",
    "Cryptanalysis is the study of analyzing information systems in order to study the hidden aspects of the systems. Cryptanalysis is used to breach cryptographic security systems and gain access to the contents of encrypted messages, even if the cryptographic key is unknown.\n",
    "\n",
    "In addition to mathematical analysis of cryptographic algorithms, cryptanalysis includes the study of side-channel attacks that do not target weaknesses in the cryptographic algorithms themselves, but instead exploit weaknesses in their implementation.\n",
    "\n",
    ">Cryptanalysis is the sister branch of Cryptography and they both co-exist. The cryptographic process results in the cipher text for transmission or storage. It involves the study of cryptographic mechanism with the intention to break them. Cryptanalysis is also used during the design of the new cryptographic techniques to test their security strengths.\n",
    "\n",
    "**Kerckhoffs's Principle (also called Open Design or Shannon Maxim):**<br>\n",
    ">Kerckhoffs's principle is one of the basic principles of modern cryptography. It was formulated in the end of the nineteenth century by Dutch cryptographer Auguste Kerckhoffs. The principle goes as follows: **A cryptographic system should be secure even if everything about the system, except the key, is public knowledge**. Basically, it implies that the attacker knows the cryptographic system, i.e., the encryption and decryption schemes and security relies on the secrecy of keys.\n",
    "\n",
    "More on [Kerckhoffs's Principle](http://www.crypto-it.net/eng/theory/kerckhoffs.html).\n",
    "\n",
    "**Steganography:**<br>\n",
    "Steganography is the practice of concealing/hiding a file, message, image, or video within another file, message, image, or video. Steganography works on the principle of **Security by Obscurity** (which is contrary to Kerckhoff's Principle).\n",
    "\n",
    "### Security Services of Cryptography\n",
    "\n",
    "The primary objective of using cryptography is to provide the following **four fundamental information security services:**\n",
    "\n",
    "**Confidentiality**\n",
    "\n",
    "Confidentiality is the fundamental security service provided by cryptography. It is a security service that keeps the information from an unauthorized person. It is sometimes referred to as privacy or secrecy. \n",
    "\n",
    "Confidentiality can be achieved through numerous means starting from physically securing to the use of mathematical algorithms for data encryption.\n",
    "\n",
    "**Data Integrity**\n",
    "\n",
    "It is security service that deals with identifying any alteration to the data. The data may get modified by an unauthorized entity intentionally or accidentally. Integrity service confirms that whether data is intact or not since it was last created, transmitted, or stored by an authorized user.\n",
    "\n",
    "Data integrity cannot prevent the alteration of data, but provides a means for detecting whether data has been manipulated in an unauthorized manner.\n",
    "\n",
    "**Authentication**\n",
    "\n",
    "Authentication provides the identification of the originator. It confirms to the receiver that the data received has been sent only by an identified and verified sender.\n",
    "\n",
    ">Authentication service has two variants:\n",
    "- Message authentication identifies the originator of the message without any regard router or system that has sent the message.\n",
    "- Entity authentication is assurance that data has been received from a specific entity, say a particular website.\n",
    "\n",
    "Apart from the originator, authentication may also provide assurance about other parameters related to data such as the date and time of creation/transmission.\n",
    "\n",
    "**Non-repudiation**\n",
    "\n",
    "It is a security service that ensures that an entity cannot refuse the ownership of a previous commitment or an action. It is an assurance that the original creator of the data cannot deny the creation or transmission of the said data to a recipient or third party.\n",
    "\n",
    "Non-repudiation is a property that is most desirable in situations where there are chances of a dispute over the exchange of data. For example, once an order is placed electronically, a purchaser cannot deny the purchase order, if non-repudiation service was enabled in this transaction.\n",
    "\n",
    "### Cryptography Primitives\n",
    "\n",
    "Cryptographic primitives are well-established, low-level cryptographic algorithms that are frequently used to build cryptographic protocols for computer security systems. Alternatively, cryptography primitives can be defined as the tools and techniques in Cryptography that can be selectively used to provide a set of desired security services. \n",
    "\n",
    "Following are some cryptography primitives:\n",
    "- Encryption\n",
    "- Hash functions\n",
    "- Message Authentication codes (MAC)\n",
    "- Digital Signatures\n",
    "\n",
    "When creating cryptographic systems, designers use cryptographic primitives as their most basic building blocks. Because of this, cryptographic primitives are designed to do one very specific task in a highly reliable fashion.\n",
    "\n",
    "\n",
    "The following table shows the primitives that can achieve a particular security service on their own.\n",
    "\n",
    "![](./Images/CryptoPrimitives.png \"Crypto Primitives and thier corresponding security service\")\n",
    "\n",
    "Note: Cryptographic primitives are intricately related and they are often combined to achieve a set of desired security services from a cryptosystem.\n",
    "\n",
    "### The three fundamental steps in cryptography:\n",
    ">When we introduce/devise a new primitive these 3 steps have to be rigorously followed:\n",
    "1. **Precisely specify threat model:** Threat model basically is knowing the capabilities of the adversaries, i.e., what can an adversarial do to attack the primitive and what is his goal in forging the primitive. In order to show that the primitive or cryptographic protocol is secure we need to prove that an adversary with the following capabilities would not be able to break the primitive/protocol. More on [Threat Model](https://www.youtube.com/watch?v=f4tk2pnOUos)\n",
    "2. **Propose a construction**\n",
    "3. **Prove that breaking construction under threat model will solve an underlying hard problem**: A basic example would be, it is easy to multiply to large prime to get a value N, but it's hard to recover the factors given the value N. So, if our prime works on that concept than if an adversary breaks our primitive/protocol than it would land a solution to solving that hard problem.\n",
    "\n",
    "**Key Note:** For production system usage, never ever use your own implementation of the primitive or any cryptographic algorithm (as aside from the implementation errors there could be many side channels which could potentially result in easy breaching of your implementation). It is always recommended to use a trusted library for applying ciphering to production level data/information. [Explanatory Video](https://www.youtube.com/watch?v=3Re5xlEjC8w)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crash Course on Discrete Probability\n",
    "\n",
    "Why Discrete Probability?\n",
    "> Over the years many natural cryptographic constructions were found to be insecure. In response, modern cryptography was developed as a rigorous science where constructions are always accompanied by a proof of security. The language used to describe security relies on discreet probability.<br>\n",
    "\n",
    "Reference Reads: \n",
    "- **Highly recommended (Easy to Digest and Preferable read to get it all):** [Discrete Probability](https://en.wikibooks.org/wiki/High_School_Mathematics_Extensions/Discrete_Probability)\n",
    "-  Refer to the Discrete Probability Crash Course segment inside the following PDF: Blockchain/CryptographyI/LectureNotes/Week1/Introduction.pdf\n",
    "- [Discrete vs Continuous Random Variables](http://www.henry.k12.ga.us/ugh/apstat/chapternotes/7supplement.html)\n",
    "- [Random Variable vs Events](https://www.quora.com/What-is-the-difference-between-an-event-and-a-random-variable)\n",
    "\n",
    "Reference Videos: \n",
    "- [Discrete Probability Crash Course [Part 1]](https://www.coursera.org/learn/crypto/lecture/qaEcL/discrete-probability-crash-course)\n",
    "- [Discrete Probability Crash Course [Part 2]](https://www.coursera.org/learn/crypto/lecture/JkDRg/discrete-probability-crash-course-cont)\n",
    "- [Probability Distribution for Random Variable X](https://www.youtube.com/watch?v=cqK3uRoPtk0)\n",
    "\n",
    "**Deterministic vs Randomized Algorithms:**\n",
    "> It's due to Discrete Probability that cryptographic algorithms took a leap from being deterministic, producing same output for a given input each time, in nature to being randomized algorithms that we use today. <br><br>\n",
    ">**Randomized Algorithms:** are those which produce different outputs given the same input, i.e., even though the input to the randomized algorithm is the same, it will produce different output each time, as Random Algorithm have an implicit argument, say r, which is sampled anew, from it's give universe, every time the algorithm is run therefore making the outcome different.<br><br>\n",
    "The output of this Random Algorithm is basically a random variable which is a distribution over the set of all possible encryption of message m under a  uniform key r.\n",
    "\n",
    "More on Randomized Algorithm: Refer to the Randomized Algorithms topic undert Discrete Probability segment inside the following PDF: Blockchain/CryptographyI/LectureNotes/Week1/Introduction.pdf\n",
    "\n",
    "**XOR:**\n",
    "XOR is very important when it comes to cryptography. Review: XOR of two bit string is their bitwise addition mod 2. Also, something XORed with itself yields zeros => x XOR x = 0.\n",
    "[Why XOR is imp in cryptography?](https://www.quora.com/Why-is-XOR-important-in-cryptography).\n",
    "\n",
    "![](./Images/XOR-Property.png \"The Important Property of XOR\")\n",
    "\n",
    "Note: Review the following video [Discrete Probability Crash Course [Part 2]](https://www.coursera.org/learn/crypto/lecture/JkDRg/discrete-probability-crash-course-cont), watch it from 6:19 where description of the important property of XOR is explained which makes it so useful in cryptography.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cryptosystems\n",
    "\n",
    "A cryptosystem is an implementation of cryptographic techniques and their accompanying infrastructure to provide information security services. A cryptosystem is also referred to as a cipher system.\n",
    "\n",
    "### Components of a Cryptosystem\n",
    "\n",
    "The various components of a basic cryptosystem are as follows:\n",
    "\n",
    "- **Plaintext:** It is the data to be protected during transmission.\n",
    "\n",
    "- **Encryption Algorithm:** It is a mathematical process that produces a ciphertext for any given plaintext and encryption key. It is a cryptographic algorithm that takes plaintext and an encryption key as input and produces a ciphertext.\n",
    "\n",
    "- **Ciphertext:** It is the scrambled version of the plaintext produced by the encryption algorithm using a specific the encryption key. The ciphertext is not guarded. It flows on public channel. It can be intercepted or compromised by anyone who has access to the communication channel.\n",
    "\n",
    "- **Decryption Algorithm:** It is a mathematical process, that produces a unique plaintext for any given ciphertext and decryption key. It is a cryptographic algorithm that takes a ciphertext and a decryption key as input, and outputs a plaintext. The decryption algorithm essentially reverses the encryption algorithm and is thus closely related to it.\n",
    "\n",
    "- **Encryption Key:** It is a value that is known to the sender. The sender inputs the encryption key into the encryption algorithm along with the plaintext in order to compute the ciphertext.\n",
    "\n",
    "- **Decryption Key:** It is a value that is known to the receiver. The decryption key is related to the encryption key, but is not always identical to it. The receiver inputs the decryption key into the decryption algorithm along with the ciphertext in order to compute the plaintext.\n",
    "\n",
    "For a given cryptosystem, a collection of all possible decryption keys is called a **key space**.\n",
    "\n",
    "An interceptor (an attacker) is an unauthorized entity who attempts to determine the plaintext. He can see the ciphertext and may know the decryption algorithm. He, however, must never know the decryption key.\n",
    "\n",
    "### Types of Cryptosystems\n",
    "Fundamentally, there are two types of cryptosystems based on the manner in which encryption-decryption is carried out in the system:\n",
    "\n",
    "- Symmetric Key Cryptosystems\n",
    "- Asymmetric Key Cryptosystems\n",
    "\n",
    "The main difference between these cryptosystems is the relationship between the encryption and the decryption key. Logically, in any cryptosystem, both the keys are closely associated. It is practically impossible to decrypt the ciphertext with the key that is unrelated to the encryption key.\n",
    "\n",
    "### Cryptographic Attacks\n",
    "The basic intention of an attacker is to break a cryptosystem and to find the plaintext from the ciphertext. To obtain the plaintext, the attacker only needs to find out the secret decryption key, as the algorithm is already in public domain.\n",
    "\n",
    "Hence, he applies maximum effort towards finding out the secret key used in the cryptosystem. Once the attacker is able to determine the key, the attacked system is considered as broken or compromised.\n",
    "\n",
    "Based on the methodology used, attacks on cryptosystems are categorized as follows:\n",
    "\n",
    "- **Ciphertext Only Attacks (COA):** In this method, the attacker has access to a set of ciphertext(s). He does not have access to corresponding plaintext. COA is said to be successful when the corresponding plaintext can be determined from a given set of ciphertext. Occasionally, the encryption key can be determined from this attack. Modern cryptosystems are guarded against ciphertext-only attacks.<br><br>\n",
    "\n",
    "- **Known Plaintext Attack (KPA):** In this method, the attacker knows the plaintext for some parts of the ciphertext. The task is to decrypt the rest of the ciphertext using this information. This may be done by determining the key or via some other method. The best example of this attack is linear cryptanalysis against block ciphers.<br><br>\n",
    "\n",
    "- **Chosen Plaintext Attack (CPA):** In this method, the attacker has the text of his choice encrypted. So he has the ciphertext-plaintext pair of his choice. This simplifies his task of determining the encryption key. An example of this attack is differential cryptanalysis applied against block ciphers as well as hash functions. A popular public key cryptosystem, RSA is also vulnerable to chosen-plaintext attacks.<br><br>\n",
    "\n",
    "- **Dictionary Attack:** This attack has many variants, all of which involve compiling a ‘dictionary’. In simplest method of this attack, attacker builds a dictionary of ciphertexts and corresponding plaintexts that he has learnt over a period of time. In future, when an attacker gets the ciphertext, he refers the dictionary to find the corresponding plaintext.<br><br>\n",
    "\n",
    "- **Brute Force Attack/Extensive Search:** In this method, the attacker tries to determine the key by attempting all possible keys. If the key is 8 bits long, then the number of possible keys is 28 = 256. The attacker knows the ciphertext and the algorithm, now he attempts all the 256 keys one by one for decryption. The time to complete the attack would be very high if the key is long.<br><br>\n",
    "\n",
    "- **Birthday Attack:** This attack is a variant of brute-force technique. It is used against the cryptographic hash function. When students in a class are asked about their birthdays, the answer is one of the possible 365 dates. Let us assume the first student's birthdate is 3rd Aug. Then to find the next student whose birthdate is 3rd Aug, we need to enquire 1.25*√365 ≈ 25 students. <br><br> Similarly, if the hash function produces 64 bit hash values, the possible hash values are 1.8x10^19. By repeatedly evaluating the function for different inputs, the same output is expected to be obtained after about 5.1x10^9 random inputs. If the attacker is able to find two different inputs that give the same hash value, it is a collision and that hash function is said to be broken.<br><br>\n",
    "\n",
    "- **Man in Middle Attack (MIM):**  The targets of this attack are mostly public key cryptosystems where key exchange is involved before communication takes place.\n",
    "    - Host A wants to communicate to host B, hence requests public key of B.\n",
    "    - An attacker intercepts this request and sends his public key instead.\n",
    "    - Thus, whatever host A sends to host B, the attacker is able to read.\n",
    "    - In order to maintain communication, the attacker re-encrypts the data after reading with his public key and sends to B.\n",
    "    - The attacker sends his public key as A’s public key so that B takes it as if it is taking it from A.<br><br>\n",
    "\n",
    "- **Side Channel Attack (SCA):** This type of attack is not against any particular type of cryptosystem or algorithm. Instead, it is launched to exploit the weakness in physical implementation of the cryptosystem. They map things like the time taken for encryption or the power consumed during encryption to deduce the key.<br><br>\n",
    "\n",
    "- **Timing Attacks:** They exploit the fact that different computations take different times to compute on processor. By measuring such timings, it is be possible to know about a particular computation the processor is carrying out. For example, if the encryption takes a longer time, it indicates that the secret key is long.<br><br>\n",
    "\n",
    "- **Power Analysis Attacks:** These attacks are similar to timing attacks except that the amount of power consumption is used to obtain information about the nature of the underlying computations.<br><br>\n",
    "\n",
    "- **Fault analysis Attacks:** In these attacks, errors are induced in the cryptosystem and the attacker studies the resulting output for useful information.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Symmetric Key Cryptosystems\n",
    "\n",
    "The encryption process where **same keys are used for encrypting and decrypting** the information is known as Symmetric Key Encryption. The study of symmetric cryptosystems is referred to as symmetric cryptography. Symmetric cryptosystems are also sometimes referred to as **secret key cryptosystems**.\n",
    "\n",
    "A few well-known examples of symmetric key encryption methods are: Digital Encryption Standard (DES), Triple-DES (3-DES), IDEA, RC4, eStreams and BLOWFISH.\n",
    "![](./Images/SymmetricEncryption.png)\n",
    "\n",
    "\n",
    "**Crypto Lesson:** In a symmetric cryptosystem, you should never use a single shared key to encrypt data/information in both direction i.e. traffic from Client(C) to Sever(S) should not be encrypted with the same key as used for encrypting the traffic from Server to Client. Hence, the shared key should be a pair of keys => $K_{shared}$ = {$K_{C>>S}$, $K_{S>>C}$} where prior is used to encrypt/decrypt the information from client to server and the latter from server to client.\n",
    "\n",
    "**Symmetric Ciphers:**\n",
    "![](./Images/SymmetricCipherDef.png )\n",
    "\n",
    "**Type of symmetric ciphers:**<br>\n",
    "An important distinction in symmetric cryptographic algorithms is between stream and block ciphers. \n",
    "- **[Stream ciphers](#Stream-Ciphers)** convert one symbol of plaintext directly into a symbol of ciphertext. \n",
    "- **[Block ciphers](#Block-Ciphers)** encrypt a group of plaintext symbols as one block. \n",
    "\n",
    "\n",
    "Prior to 1970, all cryptosystems employed symmetric key encryption. Even today, its relevance is very high and it is being used extensively in many cryptosystems. It is very unlikely that this encryption will fade away, as it has certain advantages over asymmetric key encryption.\n",
    "\n",
    "The **salient features of cryptosystem based on symmetric key encryption** are:\n",
    "- Persons using symmetric key encryption must share a common key prior to exchange of information.\n",
    "- Keys are recommended to be changed regularly to prevent any attack on the system.\n",
    "- A robust mechanism needs to exist to exchange the key between the communicating parties. As keys are required to be changed regularly, this mechanism becomes expensive and cumbersome.\n",
    "- In a group of n people, to enable two-party communication between any two persons, the number of keys required for group is $\\frac{n\\times (n-1)}{2}$.\n",
    "- Length of Key (number of bits) in this encryption is smaller and hence, process of encryption-decryption is faster than asymmetric key encryption.\n",
    "- Processing power of computer system required to run symmetric algorithm is less.\n",
    "\n",
    "**Challenge of Symmetric Key Cryptosystem**<br>\n",
    "There are two restrictive challenges of employing symmetric key cryptography:\n",
    "\n",
    "- **Key establishment:** Before any communication, both the sender and the receiver need to agree on a secret symmetric key. It requires a secure key establishment mechanism in place.\n",
    "\n",
    "- **Trust Issue:** Since the sender and the receiver use the same symmetric key, there is an implicit requirement that the sender and the receiver ‘trust’ each other. For example, it may happen that the receiver has lost the key to an attacker and the sender is not informed.\n",
    "\n",
    "These two challenges are highly restraining for modern day communication. Today, people need to exchange information with non-familiar and non-trusted parties. For example, a communication between online seller and customer. These limitations of symmetric key encryption gave rise to **asymmetric key encryption** schemes.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Time Pad and Information Theoretic Security: \n",
    "Short Intuitive Description: [One Time Pad](https://www.khanacademy.org/computing/computer-science/cryptography/crypt/v/one-time-pad \"by Khan Academy\")<br>\n",
    "Recommended Watch: [One Time Pad and Information Theoretic Security](https://www.coursera.org/learn/crypto/lecture/cbnX1/information-theoretic-security-and-the-one-time-pad \"by Coursera: Cryptography I\") <br>\n",
    "Go through the One Time Pad section in: Blockchain/CryptographyI/LectureSlides/Week1/StreamCiphers.pdf\n",
    "\n",
    "One-time pad (OTP), also called Vernam-cipher or the perfect cipher, is a crypto algorithm where plaintext is combined with a random key (where the random key is a uniform random variable from a key space K, i.e., selection of any key from K has equal uniform/equal probability). It is the only existing mathematically unbreakable encryption and is a symmetric cipher.\n",
    "\n",
    ">The one-time pad (OTP) is an encryption technique that cannot be cracked, but requires the use of a one-time pre-shared key the same size as, or longer than, the message being sent. In this technique, a plaintext is paired with a random secret key (also referred to as a one-time pad). Then, each bit or character of the plaintext is encrypted by combining it with the corresponding bit or character from the pad using modular addition. If the key is truly random, is at least as long as the plaintext, is never reused in whole or in part, and is kept completely secret, then the resulting ciphertext will be impossible to decrypt or break.\n",
    "\n",
    ">Even infinite computational power and infinite time cannot break one-time pad encryption, simply because it is mathematically impossible. However, if only one of these rules is disregarded, the cipher is no longer unbreakable.\n",
    "- The key is at least as long as the message or data that must be encrypted.\n",
    "- The key is truly random (not generated by a simple computer function or such)\n",
    "- Key and plaintext are calculated modulo 10 (digits), modulo 26 (letters) or modulo 2 (binary)\n",
    "- Each key is used only once (that's why we call it **One Time Pad**), and both sender and receiver must destroy their key after use. If the same key is used twice, the security will be compromised.\n",
    "- There should only be two copies of the key: one for the sender and one for the receiver (some exceptions exist for multiple receivers)\n",
    "\n",
    "**Perfect Secrecy:** Perfect secrecy is the notion that, given an encrypted message (or ciphertext) from a perfectly secure encryption system (or cipher), absolutely nothing will be revealed about the unencrypted message (or plaintext) by the ciphertext i.e. perfect secrecy could be defined as having an absolute immunity to Cipher text only attacks. <br>\n",
    "\n",
    "How One Time Pad has perfect secrecy?\n",
    ">Shannon proved in 1949 that One Time Pad has perfect secrecy due to uniform probability distribution of all mssgs (of same length) that could have resulted in the cipher text c (that adversary might have hold to) with the key k (of same length). That means, given a cipher text c (generated using a key k of length n) the probability of all the possible message, of length n, to be encrypted to that c is uniform/equal. Hence, c is equally probable of being an encryption of $m_{1}$, $m_{2}$ ...$m_{xyz}$. While there exist only single key that maps m to c (given as k = m XOR c).\n",
    "\n",
    "**Pitfalls:** \n",
    "- One Time Pad though have a perfect secrecy but it still is largely impractical to implement (because of the length of key being equal to that of the message, and if we even found a way to secretly transfer message-long key then it would be a better approach to use that transfer mechanism to secretly transfer the message at the first place).\n",
    "- Thought it is secure to Cipher Text only attacks, but it is vulnerable to other forms of attacks.\n",
    "\n",
    "**Bad News:** Shannon who proved that the OTP has the perfect secrecy later proved a theorem that states: **\"To have perfect secrecy the key size must always be greater than or equal to the size of the message\"**. Hence, ciphers that use keys smaller in size than the messages don't have perfect secrecy. \n",
    "Why? Because if the size of key (say n) is smaller than the message size (m), then the universe of keys (all possible keys of length n) would not have enough unique keys for encrypting each message in the universe of message (containing all the messages of of length m). And therefore we will end up using keys multiple times (at least twice) which breaks the perfect secrecy (Attack 1).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stream Ciphers\n",
    "\n",
    "**Question:** How to make a cipher that, if not have a perfect secrecy but still provides acceptable levels of security (i.e. how to make OTP practical)?\n",
    ">**Solution:** Replace the random keys (of length equal or greater than the message) with psuedorandom keys (smaller length keys). These psuedorandom keys are generated using a **PRG (Psuedo Random Generator)** which is basically a function that takes in a seed space (initial key space, say $[0,1]^{s}$) and expand it to $[0,1]^{n}$ such that n>>s. And it is out of this inflated space a key is chosen at random. Ciphers using PRG are referred to as Stream Ciphers and they also maintain the aspect of using the psuedorandom key only to pad one mssg and not multiple messages.\n",
    "\n",
    "![](./Images/PRG.png \"Generator  G expands the key space and chose a key, which is psuedorandom in nature, at random from it to XOR with the message\")\n",
    "Note: PRG should be efficiently computable by a deterministic algorithm. The key, from the space G(k), XORed with mssg is a psuedorandom pad and not a truly random pad.\n",
    "\n",
    "**Stream Cipher:** A stream cipher is a symmetric key cipher where plaintext digits are combined with a pseudorandom cipher digit stream (keystream). In a stream cipher, each plaintext digit is encrypted one at a time with the corresponding digit of the keystream, to give a digit of the ciphertext stream. Since encryption of each digit is dependent on the current state of the cipher, it is also known as state cipher. In practice, a digit is typically a bit and the combining operation an exclusive-or (XOR).<br>\n",
    "Note: Stream ciphers convert one symbol of plaintext directly into a symbol of ciphertext.\n",
    "\n",
    "**Redefining Security:**<br>\n",
    "**Stream ciphers cannot have perfect secrecy!!** Therefore, we need to rethink how we define security as perfect secrecy is not practically feasible. So:\n",
    "- Need a different definition of security\n",
    "- Security will depend on specific PRG >> [Security Definition](#PRG-Security-Definition)\n",
    "\n",
    "**Fundamental Requirement to secure Stream Ciphers:**<br>\n",
    "A minimal property that a psuedo random generator must have is property of being unpredictable, i.e., **PRG must be unpredictable**. Therefore, for a stream cipher to be secure, at it's minimum, the PRG it uses must be unpredictable in nature.\n",
    "\n",
    "What it mean to be unpredictable for a generator is that given first few bits of the output of the generator (which is the psuedorandom key), say 1...i bits, there is no efficient algorithm that can compute the rest, i+1...n, bits of the stream.\n",
    "\n",
    "**Attacks on One Time Pad/Stream ciphers:**\n",
    "- Attack 1: **Two time pad is insecure**, i.e., if we used the same key (or psuedorandom key) to pad two different messages(m1 and m2) and produce c1 and c2 cipher texts then for an adversary who captured both of those cipher texts, it's fairly easy to recover both m1 and m2 using the CT only attack. Hence a Stream Cipher key or a One Time Pad key should never, never ever, be used more than once.\n",
    "![](./Images/TwoTimePad.png)\n",
    "<br>\n",
    "- Attack 2: One Time Pad or the Stream Ciphers in general provides **no integrity** at all (all they do is try to provide confidentiality when the key is only used once) and therefore are referred as malleables.\n",
    "![](./Images/MalleableOTP.png)\n",
    "\n",
    "Real World Examples:<br>\n",
    "- **Old Stream Ciphers:** RC4, CSS etc.\n",
    "- **Modern Stream Ciphers:** eStream project (qualify 5 Stream ciphers), Modern stream cipher in addition to seed uses nonce which is a non-repeating value for a given key. Hence, we can reuse a key because the nonce make the (k, r) pair unique.\n",
    "![](./Images/ModernStreamCiphers.png)\n",
    "\n",
    "---\n",
    "\n",
    "### PRG Security Definition\n",
    "Recommended Watch: [PRG Security](https://www.coursera.org/learn/crypto/lecture/De10M/prg-security-definitions)\n",
    "\n",
    "Security of a Stream Cipher depends on how secure is the Psuedo Random Generator it uses is. In turn the the PRG is regarded as secure if the output of the PRG is **indistinguishable from the truly random output.** That is, the distribution of pseudo random is indistinguishable from a truly (random) uniform distribution.\n",
    "\n",
    "![](./Images/IndistinguishablePRG.png)\n",
    ">Goal: To show that the psuedorandom output G(k), where k is a random variable from (seed)K = {0, 1}$^{s}$ and G(k) is the psuedorandom output from the expanded space, {0 , 1}$^n$, of the seed is indistinguishable from truly random r selected from a key space of {0, 1}$^n$ (not an expansion space).\n",
    "\n",
    "How to show this indistinguishability from random? : Using **Statistical Test**<br>\n",
    "\n",
    "**Statistical Test:**\n",
    "Let's define what is a Statistical test on space {0, 1}$^{n}$:<br>\n",
    "It's basically an algorithm (A) such that:\n",
    "- A takes and input x (which is an n bit string) and \n",
    "- Outputs 0 (means input don't seem random) and 1 (means the input seems to be random)\n",
    "\n",
    "One can think of any number of statistical tests, therefore, while considering indistinguishability we only account for efficient statistical tests.\n",
    "\n",
    "A statistical test uses the concept of Advantage over a PRG to determine that whether it could distinguish the psuedorandom input from a truly random or not. Following image shows the formulation for calculation of Advantage of a given Statistical test A over a generator PRG.\n",
    "![](./Images/Advantage-ST.png \"G(k) is psuedorandom and r is truly random; Pr abbriviation for probability\")\n",
    "Note: We only want to consider the advantage of efficient statistical test for the generator PRG (we don't give a damn about inefficient ones). Also, we want the advantage to be negligible, i.e., a close to zero as possible (which indicates the statistical test wasn't able to distinguish).\n",
    "\n",
    "Hence, crypto definition for a secure PRG is as follows:\n",
    "![](./Images/SecurePRGs.png)\n",
    "Note: Efficient algo (statistical test) theoretical means that finishes in polynomial time and practically could be regarded as one which finishes in a given time.\n",
    "\n",
    "**Secure PRG is an unpredictable generator and vice versa**\n",
    "\n",
    "A secure PRG implies: It's unpredictable (which covers the minimal requirement for a secure PRG). \n",
    "![](./Images/SecureMeanUnpredict.png)\n",
    "\n",
    "Also, there exist a theorem that proved that: an unpredictable generator is secure in nature.\n",
    "![](./Images/UnpredictMeanSecure.png)\n",
    "\n",
    "**General Representation:**\n",
    "![](./Images/GeneralSecure.png)\n",
    "Note: For Stream Cipher, $P_{1}$ is G(K) [psuedorandom distribution] and $P_{2}$ is a truly random distribution\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semantic Security\n",
    "\n",
    "Recall: Shannon's idea of security: CT should not reveal anything about PT, this is the concept of semantic security. <br>\n",
    "In semantic security, an adversary sends 2 messages (of equal length) and our cipher(E) encrypt it and sends the ciphertext back to the the adversary and if the adversary have no idea about which message this ciphertext correspond to then our cipher is said to be semantically secure.\n",
    "\n",
    "Overview:\n",
    ">An adversary (A) chooses two messages: $m_{0}$,$m_{1}$ and supplies it to the encryption algorithm (E) and it encrypts one of these messages: c←E(k,$m_{b}$) where b = 0, 1 and offer it back to the adversary.<br>\n",
    "The adversary tries to guess which message was ciphered and outputs $b^{'}$ = 0 or 1 corresponding to the message number that the adversary thinks the ciphertext is encryption of (either  $m_{0}$,$m_{1}$).<br>\n",
    "\n",
    "Corresponding Watch: [Semantic Security](https://www.coursera.org/learn/crypto/lecture/q0h9g/semantic-security)                 \n",
    "![](./Images/SemanticSecurity.png)\n",
    "\n",
    "Description: \n",
    ">We have 2 experiments, namely Exp(0) and Exp(1), where in the Exp(0) encryptor (E) gives back the ciphertext for $m_{0}$ (out of the supplied two) and in Exp(1) it sends back the ciphertext for $m_{1}$. Based on the experiments we have 2 events $W_{0}$ and $W_{1}$ where $W_{0}$ represents an event where for Exp(0) adversary outputted $b^{'}$ as 1 (thinking, wrongly, that the ciphertext corresponds to $m_{1}$). Similarly, $W_{1}$ represents an event where for Exp(1) adversary outputted $b^{'}$ as 1 (rightly guessed). The advantage is defined such that if the probability of both the events $W_{0}$ and $W_{1}$ is similar or close to each other then advantage would be close to zero, which would mean that the adversary isn't able to distinguish that whether the ciphertext was of $m_{0}$ or $m_{1}$. \n",
    "\n",
    "Note: Semantic Security (One time key) means that the adversary is provided with only a single ciphertext (which could correspond to any of the two supplied message).\n",
    "\n",
    "**E is said to be semantically secure if for all \"efficient\" A (adversary), Adv$_{SS}$ [A, E] = negligible.**\n",
    "\n",
    "OTP is semantically secure (it has perfect semantic security due to uniform probability distribution):\n",
    "![](./Images/OTPSemantic.png)\n",
    "\n",
    ">Theorem: **Given that G is a secure PRG (i.e. holds the indistinguishability property). A Stream Cipher E derived from or incorporates G is semantically secure.** [Proof!!](https://www.coursera.org/learn/crypto/lecture/VeLNT/stream-ciphers-are-semantically-secure-optional)\n",
    "\n",
    "![](./Images/StreamSemantic.png)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Block Ciphers\n",
    "\n",
    "Overview:\n",
    ">A block cipher is an encryption method that applies a **deterministic algorithm along with a symmetric key to encrypt a block of text**, rather than encrypting one bit at a time as in stream ciphers. For example, a common block cipher, AES, encrypts 128 bit blocks with a key of predetermined length: 128, 192, or 256 bits. **Block ciphers are pseudorandom permutation (PRP) families** that operate on the fixed size block of bits. <br>\n",
    "Note: PRPs are functions that cannot be differentiated from completely random permutations and thus, are considered reliable, until proven unreliable.\n",
    "\n",
    "![](./Images/BlockCiphers.png)\n",
    "\n",
    "Block cipher **modes of operation have been developed to eliminate the chance of encrypting identical blocks of text the same way**, the ciphertext formed from the previous encrypted block is applied to the next block. A block of bits called an **initialization vector (IV)** is also used by modes of operation to ensure ciphertexts remain distinct even when the same plaintext message is encrypted a number of times.\n",
    "\n",
    "Some of the various modes of operation for block ciphers include **CBC** (cipher block chaining), **CFB** (cipher feedback), **CTR** (counter), and **GCM** (Galois/Counter Mode), among others. Above is an example of CBC mode. Where an IV is crossed with the initial plaintext block and the encryption algorithm is completed with a given key and the ciphertext is then outputted. This resultant cipher text is then used in place of the IV in subsequent plaintext blocks.\n",
    "\n",
    "**Working of Block Ciphers (Generic):**\n",
    "\n",
    "![](./Images/BlockCipher-Working.png)\n",
    "Description: \n",
    "1. key is expanded into n number of keys called round keys (where n is the number of rounds which is subjective to individual block cipher).\n",
    "2. Cipher uses these round keys by iteratively encrypting the message again and again and again using what's referred to as the round function.\n",
    "3. Round function takes 2 inputs: Current state of the message and a round key (corresponding to that round). \n",
    "4. The output of one round function acts as the new state of the original message which is fed into the next round function. The output from the $n^{th}$ round function is the ciphertext.\n",
    "\n",
    "In order to specify a particular block cipher (built by iteration, like DES) one has to specify the key expansion mechanism and the round function. (Those are the two dynamic part of a block cipher).\n",
    "\n",
    "Note: Block ciphers are relatively slower than the stream cipher (and slower by large magnitude to eStream ciphers) but we will see that we can do many things with block ciphers that we couldn't do very efficiently with stream ciphers.\n",
    "\n",
    "**Block Cipher aka Psuedo Random Permutation (PRP)**<br>\n",
    "PRP accurately captures what a block ciphers basically is, in other words, **PRP is a mathematical abstraction of a Block Cipher**. <br>\n",
    "How?\n",
    ">As per my perception: A block cipher with size of the key as K, used (to say XOR), dictates the size of the block of the message M. Hence limiting the size of message block from its true gigantic universe to a small key-size universe and while we operate the key onto the message block the resultant/output is another state of the message belonging from the key-size universe (i.e. with the help of key we mapped the current state of message from the key-sized message universe to another state in itself, in a one-to-one mapping fashion, therefore permuted).\n",
    "\n",
    "Therefore, in many places PRPs and block ciphers are used interchangebly depending on the context.\n",
    "\n",
    "![](./Images/PRP.png)\n",
    "where,\n",
    "- PRF: [K: Key, X: Input domain, Y: Output domain] \n",
    "- PRP: [K: Key, X: Input and Output Domain]\n",
    "\n",
    "**Why Block ciphers are PRPs and not PRFs?**\n",
    "> Because PRF may or maynot be invertible, however, PRPs are by definition invertible (with one-to-one mapping) and block ciphers needs to be invertible for being able to be decrypted using the reverse process of the encryption mechanism (as we will see in DES, AES etc.), and therefore PRPs capture the essence of block ciphers.\n",
    "\n",
    "Explanatory Read: [Psuedorandom Functions and Permutations](http://www.crypto-it.net/eng/theory/prf-and-prp.html)\n",
    "\n",
    "![](./Images/PRP&PRF.png)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Secure Block Cipher:\n",
    "Explanatory video: [Block Ciphers and Secure PRFs](https://www.coursera.org/learn/crypto/lecture/t4JJr/what-are-block-ciphers)\n",
    "\n",
    "Exploring what it means for a PRP or PRF (in general) to be secure and this concept will essentially captures what it means for a block cipher to be secure.\n",
    "\n",
    "![](./Images/SecurePRF.png)\n",
    "Description: \n",
    "- The set of all the possible function from X to Y is gigantic which is referred, above, as Funs[X,Y]. However, we get a relatively smaller set of functions $S_{F}$ (which is regarded as a set of psuedo random function cuz it is in some sense determined by the key) when we restrict the size of X to be equal to the size of key (as we have to perform XOR or another operation b/w input domain X and Key K, therefore there lengths must be equal). \n",
    "- Hence, the PRF is restricted in it's domain by the size of the key (say 128 bits for AES then domain is of size $2^{128}$).\n",
    "- Given that $S_{F}$ <<<< Funs[X, Y] a PRF is considered secure if the uniform distribution from a set of psuedo random functions ($S_{F}$) is indistinguishable from the uniform distribution of truly random functions (Funs[X,Y]).\n",
    "\n",
    "Note: The above is a description for a secure PRF. For a secure PRP instead of choosing a random function from X to Y we are going to choose a random permutation on the set X (Perms[X]), in other words,  a random one-to-one function on the set x. The adversary can either query this random permutation on the set X or it can query a psuedo random permutation $S_{F}$ (which is <<< then random permutation Perms[X]) and if the adversary cannot tell the difference then the PRP is secure.\n",
    "\n",
    "\n",
    "**Secure PRP Implies a Secure PRF**\n",
    "![](./Images/SecurePRP2PRF.png)\n",
    "\n",
    "\n",
    "**Relation between PRF(Psuedo Random Functions) and PRG (Psuedo Random Generators):**\n",
    "![](./Images/PRF2PRG.png)\n",
    "Description: \n",
    "- Assume we have a psuedo random function F (here, it's PGP as defined one to one on {0, 1}$^{n}$) which is secure.\n",
    "- Now we define a PRG (G) whose seed space (K) is same as the Key Space (K) for the PRF and its output space is basically going to be t blocks of n bits each and concatenated to get the generator value. So we basically took the key of the PRF and expanded to t times of n bits each.\n",
    "- Key property of such a generator would be that it's parallelizable, which means, if we have 2 cores to compute on than we can compute the even entries on one core and odd entries on the other and concatinate at the end. Hence, we a cipher using such a generator would be paralellizable. Where as many of the previous stream ciphers that we looked before were inherently sequential like RC4 which therefore can't take the advantage of multi cores.\n",
    "- Such a PGF derived PGR is secure because the PGF is indistinguishable from truly random therefore as we can see the Generator is just a concatination of t different PGFs and hence it would also be indistinguishable and therefore secure in nature.\n",
    "\n",
    "Bottom line: A secure PRF gives rise to secure PRG which has this key property of being parallelizable.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DES (Data Encryption Standard):\n",
    "\n",
    "Recommended Watch: \n",
    "- [DES Explained Concisely](https://www.youtube.com/watch?v=Y61qn_SQl40)\n",
    "- [DES In Depth](https://www.coursera.org/learn/crypto/lecture/TzBaf/the-data-encryption-standard)\n",
    "<br>\n",
    "\n",
    "Read: [DES Quick Read](https://www.tutorialspoint.com/cryptography/data_encryption_standard.htm)\n",
    "\n",
    "The Data Encryption Standard (DES) is a symmetric-key block cipher which is an implementation of a Feistel Network. It uses 16 round Feistel structure. The block size is 64-bit. Though, key length is 64-bit, DES has an effective key length of 56 bits, since 8 of the 64 bits of the key are not used by the encryption algorithm (function as check bits only). General Structure of DES is depicted in the following illustration:\n",
    "\n",
    "![](./Images/DES.png)\n",
    "where, [IP: Initial Permutation]\n",
    "<br>\n",
    "\n",
    "**Fundamental Component of DES: The Feistel Network:**\n",
    "![](./Images/FeistelNetwork.png)\n",
    "\n",
    "The key property of the Feistel Network is that it is invertible:<br>\n",
    "![](./Images/Invertible-Feistel.png)\n",
    "\n",
    "This property of the Feistel Network results in an easy formulation of the Decryption algorithm for DES.\n",
    "![](./Images/DES-Decryption.png)\n",
    "Note: The Feistel mechanism is a general method for making invertible functions from arbitrary functions and is infact used in many different block ciphers. Although, interestingly it's not used in AES.\n",
    "\n",
    "**Is DES a secure block cipher?**<br>\n",
    "There is this theorem that states: given that we use a secure PRF (F) in each round, then a 3-round Feistel network (therefore, also a 16 round Feistel network i.e. DES), with 3 independently derived keys being passed to F, results in a secure PRP (which implicitly means a secure block cipher).\n",
    "![](./Images/SecureFeistel.png)\n",
    "\n",
    "**Overview of DES and the Round function:**\n",
    "\n",
    "![](./Images/DES-View.png)\n",
    "\n",
    "\n",
    "The heart of DES cipher is the round function. The function applies a 48-bit key to the rightmost 32 bits to produce a 32-bit output. Following are the steps:\n",
    "\n",
    "- **Expansion Permutation Box:** Since right input is 32-bit and round key is a 48-bit, we first need to expand right input to 48 bits. \n",
    "- **XOR (Whitener):** After the expansion permutation, DES does XOR operation on the expanded right section and the round key to generate a 48-bit output. The round key is used only in this operation.\n",
    "- **Substitution Boxes:** The S-boxes carry out the real mixing (confusion). DES uses 8 S-boxes, each with a 6-bit input and a 4-bit output. There are a total of eight S-box tables taking a 48-bit input. The output of all eight s-boxes is then combined in to 32 bit section.\n",
    "- **Straight Permutation:** The 32 bit output of S-boxes is then subjected to the straight permutation.\n",
    "\n",
    "![](./Images/DES-Round.png)\n",
    "\n",
    "\n",
    "**Status of DES:**<br>\n",
    "DES is no more recommended for use in production level applications as it can be broke using exhaustive search (brute force over the entire key space) attacks and now a days with the present hardware we can recover a DES key within 24 hours, hence highly insecure. Also, there are many more types of attacks that DES is subjected to like: linear and differential attacks and quantum exhaustive attacks. DES has been superseded by the more secure Advanced Encryption Standard (AES) algorithm. <br>\n",
    "Bottom line: **DES is completely DEAD** [i.e. 56-bits ciphers shouldn't be used anymore].\n",
    "\n",
    "As DES was really popular it was deployed at many places and a lot of hardware support was developed for it, then naturally the next question was what to do next and organically people thought that in order to thwart the exhaustive search lets increase the key space such that it becomes computationally infeasible to do an exhaustive search attack. Hence, **Triple-DES** was born.\n",
    "\n",
    "**Triple DES:**\n",
    "It has, as the name says, triple the key space($2^{168}$) of the normal DES, however it is 3 times slower as well. There is still an attack that can be done on 3-DES in $2^{118}$, but practically it takes too long to perform. In general, anything that has a key space beyond $2^{90}$ is considered secure to exhaustive search. If you are, for some reason, are forced use DES in production then only use Triple DES.\n",
    "\n",
    "![](./Images/3-DES.png)\n",
    "\n",
    "The Whys?:\n",
    "- In triple DES we first do an Encryption of message block with key 1, then a decryption with key 2 and again an encryption with key 3 and all 3 keys are used in the decryption process inversely. Why did we have a decryption in b/w and not 3 consecutive encryptions? cuz there exist a possibility that k1 = k2 = k3 and hence what we have is a single DES but 3 times slower.\n",
    "- Why not use 2-DES, while it also have a secure $2^{112}$ key space? Because it is prone to a special kind of attack known as Meet in the middle attack.\n",
    "\n",
    "**You should never ever use your own crypto implementations or even design a new cipher for delivering security**, due to the following reason:\n",
    "![](./Images/ImplementationAttacks.png)\n",
    "\n",
    "Note: Use a well implemented library instead which take care of these side channel and fault attacks.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AES (Advanced Encryption Standard)\n",
    "\n",
    "Recommended Watch: [AES in Depth](https://www.coursera.org/learn/crypto/lecture/cHOMl/the-aes-block-cipher)\n",
    "\n",
    "The more popular and widely adopted symmetric encryption algorithm likely to be encountered nowadays is the Advanced Encryption Standard (AES). It is found at least six time faster than triple DES.\n",
    "\n",
    "A replacement for DES was needed as its key size was too small. With increasing computing power, it was considered vulnerable against exhaustive key search attack. Triple DES was designed to overcome this drawback but it was found slow.\n",
    "\n",
    "The features of AES are as follows:\n",
    "- Symmetric key symmetric block cipher\n",
    "- encrypts 128-bit block of data using either 128/192/256-bit keys\n",
    "- Stronger and faster than Triple-DES\n",
    "\n",
    "**Security vs Speed Trade-off:** The larger the key size is, the more secure the block cipher is as a psuedo random permutation (PRP) but as it would also have more rounds involve in its operation the slower the cipher become. Hence, AES-128 is fastest while AES-256 is the most secure.\n",
    "\n",
    "**Foundation of AES** [Generic Construction]:\n",
    "![](./Images/AES-Generic.png \"Generic Construction of AES\")\n",
    "\n",
    ">AES is built as a **Substitution Permutation (Subs-Perm) Network** and not a Feistel network. Note that in a Feistel network only have the bits are changed from round to round (the left half of the next round are simply the copy of the right half of the previous round). While in Subs-Perm network all the bits are changed in every round. <br><br>\n",
    "AES also uses the concept of round keys which are derived from 128-bit key space. AES is built to be completely reversible, otherwise the decryption would have not been possible, therefore the substitution layers as well the permutation layers are reversible, i.e., given the ciphertext we can applying all the steps in AES in reverse order (with the same round keys) and produce the original text.\n",
    "\n",
    "Having a view of the generic construction of the AES, now lets look at the specifics of AES:\n",
    "\n",
    "**AES-128**<br>\n",
    "![](./Images/AES-128.png)\n",
    "\n",
    "The Flow(Encryption):\n",
    "1. AES-128 operates on blocks of 128 bits, hence we start off with a $4\\times 4$ byte input block (each cell with 1 byte).\n",
    "2. Then we XOR the input block with a $4\\times 4$ byte block of round key (which are derived, by expansion, from the 16-byte[128] AES key).\n",
    "3. Then a round function is applied which contains 3 sub-routines, namely Byte Substitution, Shift Row and Mix-Column.\n",
    "4. This is done again and again for 10 rounds, but interestingly in the last round the Mix-column routine is absent.\n",
    "5. The output, ciphertext, is the XOR of the last round key and with the output of the last round function.\n",
    "\n",
    "Decryption is just the inverse:\n",
    "The process of decryption of an AES ciphertext is similar to the encryption process in the reverse order. The round keys are applied in reverse order followed by inverted round function. Following are the steps, except for the initial round in reverse order (as it do not contains the mix-column sub-routine) :\n",
    "\n",
    "- Add round key\n",
    "- Mix columns\n",
    "- Shift rows\n",
    "- Byte substitution\n",
    "\n",
    "The round function:\n",
    "\n",
    "![](./Images/AES-Round.png)\n",
    "\n",
    "Description:\n",
    "- ByteSub: Applies a 256-byte S-box(just a lookup table) to each byte in the $4\\times 4$ byte message block and outputs a $4\\times 4$ byte block.\n",
    "- ShiftRows: Applies a cyclic shift to the rows in the $4\\times 4$ byte block (no shift on the first row)\n",
    "- MixColumns:Applies linear transformation independently to each column\n",
    "\n",
    "Note: AES is being used everywhere now as it is easily computable as well as compact. Even Intel and AMD have integrated AES into their processors itself.\n",
    "\n",
    "Attacks on AES:\n",
    "- Best key recovery attack $2^{124}$: Just 4 times better than the exhaustive search($2^{128}$)\n",
    "- Related key attack: Given that we have inp/out pairs from four related keys, key could be recovered in $2^{99}$. But it would require related keys while we chose keys at random.\n",
    "\n",
    "The above two are the only, non efficient, attacks on AES.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Block Ciphers: Modes of Operation\n",
    "There are other modes of operations (which are not discussed below), they can be explored at: [Modes of Operations](https://www.tutorialspoint.com/cryptography/block_cipher_modes_of_operation.htm)\n",
    "\n",
    "Suggestion: Don't bother about the inner-working of AES and 3-DES. Assume both are secure PRPs and we will see how to use them.\n",
    "\n",
    ">**Modes of Operation** are procedural rules for a generic block cipher. Interestingly, the different modes result in different properties being achieved which add to the security of the underlying block cipher.\n",
    "\n",
    "A block cipher processes the data blocks of fixed size. Usually, the size of a message is larger than the block size. Hence, the long message is divided into a series of sequential message blocks, and the cipher operates on these blocks one at a time.\n",
    "\n",
    "#### Electronic Code Book (ECB) Mode\n",
    "Corresponding Watch: [Modes of Operation: One Time Key](https://www.coursera.org/learn/crypto/lecture/QZAHs/modes-of-operation-one-time-key)<br>\n",
    "Take a look at the CryptographyI/LectureSlides/Week 2/UsingBlockCiphers.pdf for more on ECB.\n",
    "\n",
    "This mode is a most straightforward way of processing a series of sequentially listed message blocks.\n",
    "\n",
    "Operations:\n",
    "- Cipher the first block of plaintext and encrypts it with the key to produce the first block of ciphertext.\n",
    "- It then takes the second block of plaintext and follows the same process with same key and so on so forth.\n",
    "\n",
    ">The ECB mode is **deterministic**, that is, if plaintext block $p_{1}$, $p_{2}$,…, $p_{m}$ are encrypted twice under the same key (i.e if there exist an identical plaintext $p_{x}$ = $p_{y}$), the output ciphertext for those blocks will be the same. Therefore, ECB is terrible as it **breaks the semantic security** (the adversary will learn something about the plaintext from the given ciphertext) given that we have two identical plaintext blocks. Attacks like CPA (chosen plain text attacks) breaks ECB, hence,**ECB is not CPA secure**.\n",
    "\n",
    "Bottom line: ECB is not semantically secure for messages that would take more than one block. More generally, deterministic algorithms aren't semantically secure (as they output same ciphertext for same plaintext, hence, allowing the adversary to know that there exist two identical plaintexts in the message just by analyzing their corresponding, identical, ciphertexts).\n",
    "\n",
    "#### Security for Many Time Keys (CPA Security):\n",
    "For in-depth look: [Security for Many Time Keys](https://www.coursera.org/learn/crypto/lecture/1pnne/security-for-many-time-key-cpa-security)\n",
    "\n",
    "Following represents the Threat Model for Many Time Keys(keys that are used to encrypt multiple messages):\n",
    "![](./Images/SSforManyTimeKeys.png)\n",
    "\n",
    "Why deterministic ciphers Insecure against CPA(chosen plain text attack)?\n",
    "![](./Images/DeterministicCiphersInsecure.png)\n",
    "Description:\n",
    "- The CPA ability allows the attacker to do q queries/challenges to the cipher. Where as everything else is same as in the [Semantic Security](#Semantic-Security) setting.\n",
    "- The cipher is deterministic and under the same key, it will produce the same ciphertext given that adversary supplied the same plaintext $m_{0}$, so in both the Exp(0) and Exp(1) the ciphertext for $m_{0}$ will be returned.\n",
    "- The adversary will again challenge the Cipher (as it can do it q times), while the cipher is using the same key. Adversary now sends in $m_{0}$, $m_{1}$ and it can accurately tell which ciphertext is returned (as it already know what is the ciphertext corresponding to $m_{0}$ from the previous query).\n",
    "- Hence, the deterministic quality of the cipher (and that it uses same key for multiple message/query encryption) coupled with CPA ability of the adversary breaks the semantic security.\n",
    "\n",
    "Bottom line: **Deterministic Encryption cannot be semantically secure under a Chosen Plaintext Attack (CPA).**<br>\n",
    "\n",
    "**What do we require to provide CPA Security?**\n",
    "![](./Images/RequisiteForCPASecurity.png)\n",
    "\n",
    "**Solutions for CPA Security:**\n",
    "- **Randomized Encryption:** The Encryption Algorithm chooses some random string and uses that random string along side the plaintext to generate the ciphertext. This would allow for the generation of different ciphertexts (blocks) for the same plaintexts (blocks). Also, the size of the ciphertext is relatively longer, roughly speaking, $CT-size = PT-size + #random-bits$ (# stands for number of). Note, the random string should be large enough such that we can use it without repetition of the ciphertext for multiple encryptions of the same plaintext.<br><br>\n",
    "\n",
    "- **Nonce-Based Encryption:** Here we use a nonce which is a unique value such that the pair (k, n) which is used to encrypt message m becomes unique and until we keep changing the nonce for encrypting even the identical messages with the same key, we will generate a unique ciphertext.\n",
    "![](./Images/NonceBasedEncryption.png)\n",
    "- **Nonce as counter:** Both encryptor and decryptor uses a counter for keeping state from mssg to mssg and this counter can be used as a nonce as the counter will be a unique value for each mssg and would be synced at both ends, therefore could be used as a nonce (no explicit nonce would be required). It's a stateful method.\n",
    "\n",
    "- **Random Nonce:** Here nonce is a random variable from a Nonce Space N, which should be large enough such that there is a really low (or negligible) probability of a nonce being repeated in a given key's lifetime. This is a stateless method.\n",
    "\n",
    "General definition of Nonce: Nonce is a unique value that doesn't repeat. It does not have to be random.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discovering the CPA Secure Ciphers [There are 2 prominent Constructions to achieve CPA Security]**\n",
    "\n",
    "#### Cipher Block Chaining(CBC) Mode\n",
    "Recommended Watch: [Cipher Block Chaining](https://www.coursera.org/learn/crypto/lecture/wlIX8/modes-of-operation-many-time-key-cbc)\n",
    "\n",
    ">**Cipher block chaining (CBC)** is a mode of operation for a block cipher (one in which a sequence of bits are encrypted as a single unit or block with a cipher key applied to the entire block). Cipher block chaining uses what is known as an initialization vector (IV) of a certain length. One of its key characteristics is that it uses a chaining mechanism that causes the decryption of a block of ciphertext to depend on all the preceding ciphertext blocks. As a result, the entire validity of all preceding blocks is contained in the immediately previous ciphertext block. A single bit error in a ciphertext block affects the decryption of all subsequent blocks. Rearrangement of the order of the ciphertext blocks causes decryption to become corrupted. Basically, in cipher block chaining, each plaintext block is XORed (see XOR) with the immediately previous ciphertext block, and then encrypted.\n",
    "\n",
    "Note: CBC cannot be parallelized as it is inherently sequential.\n",
    "\n",
    "**How $AES_{CBC}$ is CPA secure (Semantically secure under CPA)?**<br>\n",
    "Identical ciphertext blocks can only result if the same plaintext block is encrypted using both the same key and the initialization vector, and if the ciphertext block order is not changed. It has the advantage over the Electronic Code Book mode in that the XOR'ing process hides plaintext patterns. Ideally, the initialization vector should be different for any two messages encrypted with the same key.\n",
    "\n",
    "**Construction 1: CBC with rand IV**\n",
    "![](./Images/CBC-1.png \"CBC Construction with rand IV\")\n",
    "\n",
    "The Flow:<br>\n",
    "$E_{CBC}$ is the our AES encryption scheme using the CBC mode of operation. When it's asked to encrypt a message m, the first thing it's going to do is it's going to choose a random IV (Initialization) that's exactly one block of the block cipher. So IV is one cypher block. So in the case of AES the IV would be 16 bytes (128 bits). And then we're gonna run through the algorithm here: \n",
    "\n",
    "The IV basically that we chose is gonna be XORed to the first plain text block. And then the result is gonna be encrypted using the AES block cipher and output the first block of the ciphertext. And now comes the chaining part where we actually use the first block of the ciphertext to kind of mask the second block of the plaintext. So we XOR the two together and the encryption of that becomes the second ciphertext block. And so on, and so on, and so forth. So this is cIpher block chaining, you can see that each cipher block is chained and XORed into the next plaintext block, and the final ciphertext is going to be essentially the initial IV that we chose along with all the ciphertext blocks. \n",
    "\n",
    "**Initialization Vector:** IV stands for Initialization Vector. And we're going to be seeing that term used quite a bit, every time we need to pick something at random at the beginning of the encryption scheme typically we'll call that an IV for initialization vector. So you notice that the **ciphertext is a little bit longer than the plaintext** because we had to include this IV in the ciphertexts which basically captures the randomness that was used during encryption.\n",
    "\n",
    "**CBC Construction 1[Decryption]:**\n",
    "![](./Images/CBC-1Decrypt.png)\n",
    "\n",
    "**CBC - CPA Analysis:**\n",
    "So the following theorem is going to show that in fact CBC mode encryption with a random IV is in fact semantically secure under a chosen plaintext attack.\n",
    "![](./Images/CBC-CPA-Analysis.png)\n",
    "So let's take it more precisely, basically if we start with a PRP, in other words, our block cipher E, that is defined over a space X, then we are gonna to end up with a encryption algorithm $E_{CBC}$ that takes messages of length L and outputs ciphertexts of length L+1. And then suppose we have an adversary that makes q chosen plaintext queries. \n",
    "\n",
    "Then we can state the following security fact, that for every such adversary that's attacking $E_{CBC}$, to exist an adversary that's attacking the PRP, the block cipher, with the following relation between the two algorithms: the advantage of algorithm A against the encryption scheme is less than the advantage of algorithm B against the original PRP plus some noise term. So lets  interpret this theorem, so what this means is that essentially since E is a secure PRP $Adv_{PRP}$[B, E] is negligible, and our goal is to say that adversary A's advantage is also negligible. However, here we are prevented from saying that because we got this extra error term. This is often called an error term and to argue that CBC is secure we have to make sure that the error term is also negligible. Because if both of these terms on the right are negligible, there sum is negligible and therefore the advantage of A against $E_{CBC}$ would also be negligible.\n",
    "\n",
    "So this says that in fact for $E_{CBC}$ to be secure it has better be the case that $q^{2}$.$l^{2}$ is much, much, much smaller than the value X, where L is simply the length of the messages that we're encrypting (so L could be like say a 1000, which means that we are encrypting messages that are at most 1000 AES blocks) and q is the number of ciphertexts that the adversary gets to see under the CPA attack, but in real life what q is, is basically the number of times that we have used the key K to encrypt messages.\n",
    "\n",
    "Example:\n",
    "![](./Images/CBC-CPA-Ex.png)\n",
    "Note: Using the given Adv formulation, we are able to precisely calculate after how many encryptions [and therefore after how many bytes of encryption], here in AES-128 it's $2^{48}$blocks, we must change the key.\n",
    "\n",
    "Warning: CBC where attacker can predict the IV is not CPA-secure!!. Hence, it's crucial that the IV be random and not predictable.\n",
    "\n",
    "**Construction 1': Nonce Based CBC**\n",
    "\n",
    "![](./Images/NonceBasedCBC.png)\n",
    "\n",
    "Description:\n",
    "This is a nonce based version of the CBC where the IV is replaced by a nonce (if the nonce is already known to the recipient, ex: counter nonce, then we don't need to include the nonce explicitly in the ciphertext, so ciphertext is exactly the same as the plaintext). \n",
    "\n",
    "If the nonce is random then we don't need the below explained extra step (we can use it directly to XOR with the initial plaintext block).\n",
    "\n",
    "However, it's perfectly fine to use a non random unique nonce, however, it's absolutely crucial to know that if we do this then we would have to take an **extra step** before using the nonce in the CBC chain, that is: **to first encrypt the nonce using a key $k_{1}$** (which is different from the key, k, that is used in the rest of the mechanism) **so that the output is going to be a random IV which is then used in the CBC chain.** So, this extra step is extremely crucial without CBC mode encryption with nonce wouldn't be CPA secure. <br>\n",
    "Note: Key $k_{1}$ could not be equal to key k, as that would also not be CPA secure.\n",
    "\n",
    "Example of a Cyrto API [AES-CBC with rand IV]:\n",
    "![](./Images/ExampleCryptoAPI.png)\n",
    "\n",
    "### Implementation of AES (CBC with random IV) using PyCrypto API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the key [16, 24, 32byte long (here each char is 1 byte)]: Awesome Crypto!!\n",
      "Enter the IV [corresponding to the size of the key]: This is 16-B IV!\n",
      "Please enter the message to be encrypted: Here is a basic implementation of the Advanced Encryption Standard.\n",
      "\n",
      "Encrypting...\n",
      "Ciphertext: b'\\x7f\\x08\\xa0\\x10\\xd1l\\xa3\\xe5\\xc7x\\x98\\xe1\\xf1\\xf5\\x90H'b'\\x8f\\xd3 g\\x80\\xca\\r\\x11\\xb6\\x9d9\\xd1\\xfc\\xa5t\\xd7'b\"h\\x88\\xef\\xf1S\\x8a\\xea\\x8f.\\xcb/\\xc3h\\xff'\\x1d\"b'\\xd2\\xbc\\x80=S\\xda#\\x8dI\\x0e\\xa2\\xeb\\x1b\\xd5F\\x8a'b'\\x1b\\xf6\\x1f\\x9dSn^\\xf1\\x9b\\x0ei\\x19&\\x80\\x0f\\x1d'\n",
      "\n",
      "Decrypting...\n",
      "Plaintext: Here is a basic implementation of the Advanced Encryption Standard.\n"
     ]
    }
   ],
   "source": [
    "from Crypto.Cipher import AES\n",
    "import random, string\n",
    "\n",
    "def split_txt(text, splitter):\n",
    "    \"Constructs the splitted_text [Block-size division]\"\n",
    "     \n",
    "    if len(text)%splitter == 0:\n",
    "        extras = 0\n",
    "        splitted_text = [text[start: start+splitter] for start in range(0, len(text), splitter)]\n",
    "    else:\n",
    "        extras = splitter - len(text)%splitter\n",
    "        text = text + random_generator(extras)\n",
    "        splitted_text = [text[start: start+splitter] for start in range(0, len(text), splitter)]\n",
    "    return splitted_text, extras\n",
    "\n",
    "def random_generator(n): \n",
    "    \"Generates n random characters for padding\"\n",
    "        \n",
    "    return ''.join(random.choice(string.ascii_letters) for x in range(n))\n",
    "\n",
    "\n",
    "def encryption(key, IV):\n",
    "    \"AES Encryption Scheme\"\n",
    "    \n",
    "    block_size = len(key)\n",
    "    obj = AES.new(key , AES.MODE_CBC, IV)\n",
    "    message = input('Please enter the message to be encrypted: ')\n",
    "    print('\\nEncrypting...')\n",
    "    splitted_text, extras = split_txt(message, block_size)\n",
    "    ciphertexts = []\n",
    "    for text in splitted_text:\n",
    "        ciphertexts.append((obj.encrypt(text)))\n",
    "    return ciphertexts,extras\n",
    "\n",
    "def decryption(key, IV, ciphertexts, extras):\n",
    "    \"AES Decryption Scheme\"\n",
    "    \n",
    "    print('Decrypting...')\n",
    "    obj2 = AES.new(key, AES.MODE_CBC, IV)\n",
    "    original_mssgs = []\n",
    "    for index in range(len(ciphertexts)):\n",
    "            original_mssgs.append(obj2.decrypt(ciphertexts[index]))\n",
    "\n",
    "    original_mssgs = list(map(lambda x: x.decode(\"utf-8\"), original_mssgs))\n",
    "    original_mssgs[-1] = original_mssgs[-1][:-extras]\n",
    "    return ''.join(original_mssgs)\n",
    "\n",
    "def AES_fxn():\n",
    "    key = input('Enter the key [16, 24, 32byte long (here each char is 1 byte)]: ')\n",
    "    IV  =  input('Enter the IV [corresponding to the size of the key]: ')\n",
    "    assert len(key) in [16, 24, 32], \"AES key must be either 16, 24, or 32 bytes long\"\n",
    "    assert len(IV)  in [16, 24, 32], \"AES IV must be of the same size as the key\"\n",
    "    \n",
    "    ciphertexts, extras = encryption(key, IV)\n",
    "    print('Ciphertext: {}\\n'.format(\"\".join(map(str, ciphertexts))))\n",
    "    original_mssg = decryption(key, IV, ciphertexts, extras)\n",
    "    print('Plaintext: {}'.format(original_mssg))\n",
    "    \n",
    "AES_fxn()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Counter (CTR) Mode\n",
    "\n",
    "CTR mode is method to achieve CPA security, it is actually superior to CBC and is also referred to as randomized counter mode. Unlike CBC, randomized counter mode uses a secure PRF. It doesn't need a block cypher (PRP). It's enough for counter mode to just use a PRF because we're never going to be inverting this function F. So we're going to let F be the secure PRF and it acts on N byte blocks. Again if we use AES, N will be 128.\n",
    "\n",
    "**Construction 2: Random Counter Mode**\n",
    "![](./Images/CounterMode.png)\n",
    "\n",
    "Work Flow:\n",
    "The way the encryption algorithm works in counter mode is it starts off by choosing a random IV, that's 128 bytes random IV in the case of AES, and the essentially we start counting. From this random IV, so you notice the first encryption is of IV then IV+1 up to IV+L. So we generate this random pad. We XOR the result with the message, and that gives us the cipher text. And, as usual, you notice that the IV here is included along with the cipher text.<br>\n",
    "\n",
    "So that, in fact, the cipher text is a little longer than the original plain text. And the point, of course, is that, encryption algorithm chooses a new IV for every message. And so even if I encrypt the same message twice, I'm gonna get different resulting cipher texts. One thing to notice that this mode is completely paralyzable, unlike CBC. CBC was sequential. Hence, if you have three AES engines encryption basically will work three times as fast. So that's the beauty of counter mode. \n",
    "\n",
    "**Construction 2': Nonce Counter Mode**\n",
    "![](./Images/CounterMode-2.png)\n",
    "\n",
    "Description:<br>\n",
    "Counter mode also has a corresponding nonce based counter mode. Where the IV is not truly random, but rather, is just a nonce which could be a counter. And the way you would implement nonce based counter mode is:\n",
    "- you would take the 128 bits block that used in AES. And then you would split it in two. \n",
    "- You would use the left 64 bits as the nonce. \n",
    "- And then once you specify the nonce, the lower order, 64 bits, would be doing the counting inside of the counter modes encryption. \n",
    "- So nonce goes on the left, and the counter mode encryption counter goes on the right. \n",
    "\n",
    "And it's perfectly fine if this nonce is unpredictable. The only restriction is that you encrypt at most $2^{64}$ blocks using one particular nonce. The danger is that you don't want the right side counter to reset to zero (that's what will happen after $2^{64}$ block encryption), then, you will have two blocks that are encrypted using the same one time pad. Therefore, we should change the block, after $2^{64}$ blocks, to avoid two time pading.\n",
    "\n",
    "**Counter mode - CPA Analysis**\n",
    "![](./Images/Counter-CPA-Analysis.png)\n",
    "\n",
    "Description: Everything is same as that of CBC Analysis, with just the following exceptions:\n",
    "- In counter mode, we use a secure PRF instead of a secure PRP.\n",
    "- Counter mode is secure as long as $q^{2}l$ is << |X|, which is better than that of CBC ($q^{2}l^{2}$ << |X|). Which means that we can encrypt more blocks using AES in counter mode as compared to AES in CBC.\n",
    "\n",
    "\n",
    "Example:\n",
    "![](./Images/Counter-CPA-Ex.png)\n",
    "Note: We can encrypt $2^{64}$ blocks in counter mode without the requirement of changing the key which is much better that $2^{48}$ blocks in CBC.\n",
    "\n",
    "#### Counter Mode vs Cipher Block Chaining\n",
    "![](./Images/CounterVsCBC.png)\n",
    "\n",
    "A quick comparison of counter mode and CBC unveils that **in every single aspect, counter mode is superior to CBC** with parallelizability and ability to encrypt more blocks with the same key being the major advantages of counter mode. And that's actually why most modern encryption schemes actually are starting to migrate to counter mode, and abandon CBC. Even though CBC is still quite widely used.\n",
    "\n",
    "\n",
    "<br>\n",
    "### Summarizing the Block Ciphers\n",
    "![](./Images/BlockCipherSummary.png)\n",
    "\n",
    "The security notions discussed up to here only provides security against eavesdropping(**provides confidentiality**) but not against tampering. And **because neither one is designed to defend against tampering, neither one provides data integrity. And we're going to see this as a real problem. As a result, in fact, these modes actually should never, ever be used. You should only be using these modes in addition to an integrity mechanism.** \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAC (Message Authentication Code)\n",
    "Corresponding Watch: [MAC](https://www.coursera.org/learn/crypto/lecture/iVGR5/message-authentication-codes)\n",
    "\n",
    "A Message Authentication Code (MAC) is a cryptographic primitive used to:\n",
    "- Provide **Data Integrity** by allowing verifiers (who also possess the secret key) to detect any changes to the message content.\n",
    "- **Authenticate** a message, in other words, to confirm that the message came from the stated sender (its authenticity).\n",
    "\n",
    "Note: MAC do not provide, standalone, confidentiality services.\n",
    "\n",
    "Here we have, Alice and Bob. They have a shared key, K, which is not known to the attacker, but known to both of them. And there's a public message M that Alice wants to send to Bob, such that an attacker along the way cannot modify this message on its way to Bob. \n",
    "![](./Images/MAC.png)\n",
    "[S: Signing Algoritm, V: Verification Algorithm, K: Key Space, M: Message Space and T: Tag Space]\n",
    "\n",
    "The Flow:<br>\n",
    "The way Alice does it, is by using what's called a MAC signing algorithm, we'll denote it by S, where the MAC signing algorithm takes as input the key and the message, and produces a very short tag. The tag could be like 90 bits or 100 bits, or so on. Even though the message is gigabytes long, the tag is actually very, very short. Then, she appends the tag to the message and sends the combination of the two to Bob. Bob receives the message and the tag, and then he runs what's called a MAC verification algorithm on this tag. So the MAC verification algorithm takes as input to the key, the message, and the tag and it says basically yes or no, depending on whether the message is valid or whether it's been tampered with. \n",
    "\n",
    "So more precisely, **what is a MAC? **\n",
    ">Well, MAC basically consists of two algorithms, a **Signing algorithm** and a **Verification algorithm**. As usual, they're defined over a key space, a message space, and a tag space. And as we said, it's a pair of algorithms. So the signing algorithm will output a tag in the tag space using the shared key, and the verification algorithm, basically given the key, the messages and the tag, will output yes or no. \n",
    "\n",
    "And there are these consistency requirements, such that for every K in the key space and for every message in the message space, it so happens that if I sign a message using a particular key, and then I verify the tag using the same key, I shall get yes in response. So this is the standard consistency requirement which is the analog of the one that we saw for encryption.\n",
    "\n",
    "**Common Mistake:**<br>\n",
    "There's a common mistake that people make, where they try to **provide integrity without actually a shared key**. So here's an example. So consider CRC. CRC stands for cyclic redundancy check. Alice basically uses a CRC algorithm which is keyless. Doesn't take any key, to generate a tag. And then she appends this tag to the message, she sends it over to Bob. Bob will still verify the tag is equal to CRC(m). And if so the verification algorithm will say yes, and no otherwise.\n",
    "\n",
    "![](./Images/IntegrityRequireSKey.png)\n",
    "**Integrity mechanism with Secret Key = Authenticated Integrity [Source/Entity + Message Integrity]**, whereas keyless Integrity mechanism results only in message integrity.\n",
    "\n",
    "So the problem with this is it's very easy for an attacker to defeat a keyless integrity mechanism. In CRC, an attacker can very easily modify the message and fool Bob into thinking that the new message is a valid one. The way the attacker will do it is he'll simply block the message and the tag. And then he'll produce his own message, say m', and compute CRC on m', and then send the concatenation of the two over to Bob. Bob will run the verification algorithm, verification will work properly because in fact the tag is a valid CRC for the received message. And as a result, Bob would think that this message came from Alice but in fact its been completely modified by the attacker and had nothing to do with the original message that Alice sent.\n",
    "\n",
    "Bottom Line: **We can use an key-less integrity mechanism, such as CRC, to provide integrity service but that mechanism would not provide, a much necessary, authentication service.**\n",
    "\n",
    "**Secure MACs**<br>\n",
    "What does it take for a MAC to be secure?\n",
    "\n",
    "![](./Images/SecureMAC.png)\n",
    "\n",
    "Note: Chosen Message Attack(CMA) is analog to Chose Plaintext Attack(CPA) with a difference that in CPA, attacker has the ability to post q plaintext queries to the Encryption Scheme and and is given back the ciphertexts. Whereas in CMA, adversary has the ability to feed/query q messages to the MAC Signing algorithm and receives the corresponding tags.\n",
    "\n",
    "![](./Images/SecureMAC-2.png)\n",
    "\n",
    "Though the above snippets for Secure MACs are self explanatory, if an explanation is required then please refer to the corresponding watch mentioned above.\n",
    "\n",
    "\n",
    "**Building Secure MACs**\n",
    "\n",
    "Any Secure PRF directly gives us a Secure MAC. \n",
    "![](./Images/S-PRFgivesS-MAC.png)\n",
    "Description:<br>\n",
    "**Given a secure PRF we can construct a secure MAC simply by defining the signature on the message m as the value of the PRF at the point m.** The only caveat is that the output(Y) of the PRF F has to be large. For example, it could be 80 bits or 128 bits, and that would generate a secure MAC. Why? (Explained Below!)\n",
    "\n",
    "Note: The domains K, X and Y in Secure PRF (F), above, corresponds to Key Space(K), Message Space(M) and Tag Space(T) in the MAC. And the MAC is psuedorandom because the size of the key, used to operate on the message, delimits the Message Space.\n",
    "\n",
    "![](./Images/SecurityThm4S-MAC.png)\n",
    "Description:<br>\n",
    "Given that we use a secure PRF ($Adv_{PRF}$ = negligible) to build our MAC, the whole aspect of security gets loaded on to the size of Y (|Y|) which is the PRF representation of the size of Tag. So, our MAC is secure as long as the |T| is sufficiently large.<br>\n",
    "Hence, if the size of Tag is large enough to make 1/|Y| term negligible the then the $Adv_{MAC}$ = $Adv_{PRF}$(neg) + 1/|Y|(neg) = negligible.\n",
    "\n",
    "Key Note: \n",
    ">**Tags can't be too short.** They have to have some length to them. And in fact, the typical tag length would be, 64, 96, or 128 bits. Here let's for example use the tags that are 96 bits long. If you try to guess the tag for a message when the tag is 96 bits the probability of guessing it correctly is 1/$2^{96}$ . So the adversary's advantage would just be 1/$2^{96}$ which is negligible. \n",
    "\n",
    "Property of Secure PRF based MACs: \n",
    "![](./Images/TruncateMACs.png)\n",
    "Suppose we have a Secure PRF (F) then a truncated version of F would also be a secure PRF.<br>\n",
    "Hence, for a MAC constructed using the Secure PRF F outputting n-bits, we can have a truncated MAC outputting w-bits(therefore the output tag would be of more reasonable size) which  would still be secure as long as |w| is large enough.\n",
    "\n",
    "**Our 1st PRF based MAC:**<br>\n",
    "So now that we know that any secure PRF is also a secure MAC, we already have our first example i.e. AES. In particular, we know that AES, or at least we believe that AES is a secure PRF. Therefore, the AES cipher essentially gives us a MAC that can match messages that are exactly sixteen bytes(128 bits). So, that's our first example of a MAC. However, this AES MAC is for small inputs (16-bytes). \n",
    "\n",
    "**The question of MAC for large Messages:**<br>\n",
    "Now the question is: If we have a PRF for small inputs like AES that only acts on sixteen bytes, can we build a MAC for big messages that can act on gigabytes of data? Basically given a small MAC can we build a big MAC out of it. In other words, **given a MAC for small messages and we build a MAC for large messages?** \n",
    "\n",
    "There are these two prominent constructions (however, we are going to discuss 4 constructions as we proceed), which provides solution to the above question, used in practice (for building secure MACs):\n",
    "- **CBC-MAC**: It is an AES-Based MAC used primarily in the Banking Industry, for ex, in Automated Clearing House (ACH) which banks use to clear cheques with one another.\n",
    "- **HMAC**: It's a MAC from a Hash function and is used on the Internet by protocols such as SSL, IPsec, SSH etc.<br>\n",
    "\n",
    "(They both convert a small-PRF into a big-PRF, in other words, converts a MAC for small messages into a MAC for large messages)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CBC-MAC and NMAC\n",
    "Corresponding watch: [CBC-MAC](https://www.coursera.org/learn/crypto/lecture/QYT6i/cbc-mac-and-nmac)\n",
    "\n",
    "The Goal:\n",
    "![](./Images/MACs&PRFs.png)\n",
    "Note: We are going to denote by X, the set {0,1}$^{n}$ where n is the block size for the underlying secure PRF. So, since we're always going to be thinking of AES as the underlying PRF, we can think of n as essentially 128 bits. \n",
    "\n",
    "#### CBC-MAC\n",
    "\n",
    "![](./Images/CBC-MAC.png)\n",
    "Note: Each F in the blue box is the PRP (small-PRF: can produce MAC for small messages), and the entire setup is our new PRF $F_{ECBC}$ (big-PRF: can produce MAC for large messages)\n",
    "\n",
    "The Concept:\n",
    ">So CBC uses a PRF that takes messages in the set X {0,1}$^{n}$ and outputs messages in the same set X (i.e. an invertible PRF aka PRP). And what we're going to be building is a PRF that basically takes pairs of keys and it takes very long messages, in fact arbitrarily long messages, and it outputs tags in {0,1}$^{n}$ (a small tag for arbitrary length message). So that's our goal. <br> \n",
    "Now whats that X to the less than or equal to L? The point here is that in fact CBC MAC can take very long messages of up to L blocks (where L can be huge, million to even billions). Thereby we are trying to achieve that goal: given a MAC for small messages(AES), we build a MAC for large messages (CBC).\n",
    "\n",
    "Work Flow:\n",
    "1. We start by taking our message and breaking it into blocks, each block is as long as a block of the underlying function F, and then essentially we run through the CBC chain except that we don't output intermediate values. \n",
    "2. So, we basically encrypt the first block and then feed the results into the XOR with the second block and then feed that into F again, and we do that again and again and again.\n",
    "3. Finally we get a value which is called the raw CBC output, this output is still not a secure MAC. Therefore, we do one more, critical, encryption step. \n",
    "4. This final encryption step is actually done using an independent key, K1 (remember $F_{ECBC}$ takes a pair of keys: $K^{2}$). That's different and chosen independently of the key K, and finally the output gives us the tag (which is secure). \n",
    "\n",
    "In this case the tag would be n bits long (if AES is the underlying PRF, so n would be 128 bits), but, as mentioned in the previous earlier, it's fine to truncate the tag to w bits as long as $1/2^{w}$ is negligible.\n",
    "\n",
    "#### NMAC\n",
    "\n",
    "So another class of construction for converting a small PRF(our good small AES) into a large PRF is called NMAC, for Nested MAC.\n",
    "![](./Images/NMAC.png)\n",
    "\n",
    "Note: Each F in the blue box is the PRP (small-PRF: can produce MAC for small messages), and the entire setup is our new PRF $F_{NMAC}$  (big-PRF: can produce MAC for large messages)\n",
    "\n",
    "The Concept:\n",
    ">NMAC starts from PRF that, as before, takes inputs in X, but outputs elements in the key space K. And remember that for CBC, the output has to be in the set X. Here, the output needs to be in the key space. Therefore, we basically obtain the PRF, which takes pairs of keys as inputs, can process variable length messages up until L blocks (where L can get real big) and outputs an element in the key space.\n",
    "\n",
    "Work Flow:\n",
    "1. We take our message, and we break it into blocks. Each block is, again, as big as the block length of the underlying PRF (here, AES hence 128 bits). \n",
    "2. And now we take our key and feed into the function F. And the message block is given as the data input into the function F. What comes out is the key for the next block of NMAC. \n",
    "3. So now we have a new key for the next evaluation of the PRF. And the data for the next evaluation is the next message block and so on and so forth until we reach the final output.\n",
    "4. The final output is gonna be an element in K. If we stop here, the function that we obtain is called a cascade function. So, cascade will output an element in K. However, that is not a secure MAC. \n",
    "5. To get a secure MAC, what we do is we need to map this element t, which is, right now, in K, into the set X. And so, typically, NMAC is used with PRFs where the block length, X, is much bigger than the key length. And so what we do is we simply append fixed pad. Usually, the fixed pad that gets appended to this tag t is referred to as fpad. \n",
    "6. This then becomes an input to the final function which uses an independent key K1 for the last encryption step. And then finally, the last tag is an element of K which is the output of NMAC (finally, we got a secure tag). \n",
    "\n",
    "So remember without the last encryption step, the function is called a cascade. With the last step, which is necessary for security, we actually get a PRF which outputs elements in K, and can process variable length messages that are up to L blocks long.\n",
    "\n",
    "Note: NMAC is the basis for a popular MAC called **HMAC**.\n",
    "\n",
    "Ques: Why raw CBC (of CBC MAC) and Cascade (of NMAC) are insecure MACs?<br>\n",
    "Ans : As they can be subjected to **extension attacks** due their extension property. Explained in detail here, [CBC-MAC and NMAC](https://www.coursera.org/learn/crypto/lecture/QYT6i/cbc-mac-and-nmac), tune in at 7:30. Therefore, those **last encryption steps with independent key K1 are crucial.**\n",
    "\n",
    "**CBC-MAC and NMAC Analysis**\n",
    "\n",
    "![](./Images/CBC&N-MACAnalysis.png)\n",
    "[q: number of messages MACed with key k]<br>\n",
    "\n",
    "![](./Images/CBC&N-MACAnalysisEx.png)\n",
    "If we use the key for MACing blocks more than $2^{48}$ (with AES as underlying PRF) we will start getting collision, i.e., the tags for two different messages would turn out to be the same. \n",
    "\n",
    "Warning: **The Birthday Attack**<br>\n",
    "If we keep using the same key K after MACing q messages where q exceeds |X|$^{1/2}$ for CBC-MAC or |K|$^{1/2}$ for NMAC. We will get collisions, i.e., the the tags for different messages would start to collide. So, if we made this mistake of omitting the final encryption steps and therefore using only the raw CBC or Cascade to encrypt then they are subjected to extension attacks and we can prove that the extensions, from the extension attacks, will collide as well, which will result in birthday attack as depicted below.\n",
    "\n",
    "![](./Images/InsecureMACBirthdayAttack.png)\n",
    "<br>\n",
    "\n",
    "**MAC Padding**\n",
    "\n",
    "The Problem:<br>\n",
    "Till now we have assumed that the message length is a multiple of the block size, but what if the message length is not a multiple of the block size?\n",
    "\n",
    "Solution 1: suggested by ISO<br>\n",
    "The padding function must be one to one. In other words, it should be the case that two distinct messages always map to two distinct padded messages. We shouldn't actually have a collision on the padding function. Another way of saying it is that the padding function must be invertible. That guarantees that the padding function is one to one. So a standard way to do this was proposed by the International Standards Organization ISO.\n",
    "\n",
    "What they suggested is basically, let's append the string 100.. to the end of the message to make the message be a multiple of the block length. Now to see that this padding is invertible, all we do is describe the inversion algorithm which simply is gonna scan the message from right to left, until it hits the first one and then it's gonna remove all the bits to the right of this one, including the one. And you see that once we've removed the pattern this way, we obtain the original message.\n",
    "\n",
    "![](./Images/CBC-ISOPadding.png)\n",
    "\n",
    "Common Mistake: \n",
    "Now there's one corner case that's actually quite important, and that is what do we do if the original message length is already the multiple of a block size? In that case it's really very, very important that we add an extra dummy block. That contains the pad 100... and again, there are many products and standards that have actually made this mistake where they didn't add a dummy block and as a result, the MAC is insecure because there exist an easy existential forgery attack.\n",
    "\n",
    "Solution 2: **CMAC** (NIST Standard)\n",
    "\n",
    "The Concept:<br>\n",
    "There is a very clever idea called CMAC, standardized by NIST, which shows that using a randomized padding function we can avoid having to ever add a dummy block. So CMAC actually uses three keys. And, in fact, sometimes this is called a three key construction. So this first key, K, is used in the CBC, the standard CBC MAC algorithm. And then the keys, K1 and K2, are used just for the padding scheme at the very last block. And in fact in the CMAC standard, the keys K1, K2 are derived from the key K by some sort of a pseudo random generator.\n",
    "\n",
    "![](./Images/CMAC.png)\n",
    "Work Flow:\n",
    "- The way CMAC works is as follows. Well, if the message happens to not be a multiple of a block length, then we append the ISO padding to it. But then we also XOR this last block with a secret key, K1, that the adversary doesn't know. \n",
    "- However, if the message is a multiple of the block length, then of course, we don't append anything to it. But we XOR it with a different key, K2, that, again, the adversary doesn't actually know. \n",
    "\n",
    "So it turns out, just by doing that, it's now **impossible to apply the extension attacks that we could do on the cascade function, and on raw CBC**. Because the poor adversary actually doesn't know what is the last block that went into the function. Hence, **we don't need that last, critical, encryption step in CMAC that we absolutely needed in CBC-MAC and NMAC**.<br><br>\n",
    "Note: CMAC is a federal standard standardized by NIST and if you now, these days, wanted to use a CBC-MAC for anything, you would actually be using CMAC as the standard way to do it.\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### PMAC (Parallel MAC)\n",
    "Corresponding watch: [PMAC](https://www.coursera.org/learn/crypto/lecture/u8xyE/pmac-and-the-carter-wegman-mac)\n",
    "\n",
    "Till now we have talked about the CBC-MAC and NMAC to convert a PRF for small messages into a PRF for much larger messages. Those two constructions were sequential, in the sense that if you had multiple processors you couldn't make the construction work any faster.<br> \n",
    "PMAC stands for Parallel MAC that also converts a small PRF into a large PRF, but does it in a very parallelizable fashion and therefore is very fast given a multiprocessor system.\n",
    "\n",
    "![](./Images/PMAC.png)\n",
    "\n",
    "Work Flow:\n",
    "1. We take our message and we break it into blocks. And then we process each block independently of the other. \n",
    "2. So, the first thing we do, is we evaluate some function P and we XOR the result into the first message block, and then we apply our function F using a key k1. We do the same for each one of the message blocks and notice that we can do it all parallel, all message blocks are processed independently of one another.\n",
    "3. Finally, we collect all these results into some final XOR and then we encrypt one more time to get the final tag value.\n",
    "\n",
    "Note: For a technical reason, actually on the very last one, we actually don't need to apply the PRF F, but as said, this is just for technical reason, we are going to ignore that for now.\n",
    "\n",
    "**What's that P function for?**\n",
    "\n",
    "The problem that PMAC is subjected to without the function P:<br>\n",
    "Imagine, just for a second, that the function P isn't actually there. That is, imagine we actually, directly feed each message block into the PRF without applying any other processing to it. Then the resulting MAC is completely insecure and the reason is essentially no order is enforced between the message blocks. In particular, if I swap two message blocks, that doesn't change the value of the final tag. Because the XOR is commutative, the tag will be the same whether we swap the blocks or not. As a result, an attacker can request the tag for a particular message, and then he obtains the tag for a message where two of the blocks are swapped and that counts as an existential forgery.\n",
    "\n",
    "How the function P solves it:<br>\n",
    "So what this function P tries to do is essentially enforce order on these blocks. And notice that the function takes, first of all, a key as input, which is different from the key used for the PRF. And second of all, more importantly, it takes the block number as input. In other words, the value of the function is different for each one of the blocks. And that's actually exactly what's preventing this, blocks swapping attack. So the function P actually, is a very easy to compute function. Essentially given the key and the message block, all it is, is just a multiplication in some finite fields. So it's a very, very simple function to compute. It adds very little to the running time of PMAC. And yet, it's enough in ensure that the PMAC is actually secure.\n",
    "\n",
    "**What about Padding for PMAC?**<br>\n",
    "If the message length is not a multiple of the block length. That is, imagine the last block is shorter than full block length, then PMAC actually uses a padding that's similar to CMAC, so that there is no need for an additional dummy block, ever\n",
    "\n",
    "**PMAC Analysis**\n",
    "![](./Images/PMAC-Analysis.png)\n",
    "\n",
    "PMAC is secure, as long as $qL$ product is less than the square root of the block size |X|. So for AES as the underlying PRF, |X| would be $2^{128}$, and the square root, therefore, would be $2^{64}$. So the MAC would be secure, as long as $q.L$ is less than $2^{64}$. And every time, as it gets closer to that value, of course, we would have to change the key in order to continue MAC-ing more messages securely.\n",
    "\n",
    "An Interesting Property of PMAC:<br>\n",
    "**PMAC is incremental in nature**, i.e., if just a single block (or couple blocks in general) have changed, maybe because only certain parts of the message got changed, and rest of the blocks of the message are intact. Then we don't need to recompute PRF for all other blocks, we can just apply function P and recompute the PRF (specifically PRP, as explained in the corresponding watch) for the changed block(s) alone and perform the final XOR with all other block's PRF outputs(which were already computed) to quickly regenerate the tag. (This save the recomputing, as would have done in CBC-MAC and NMAC because they are sequential).<br>\n",
    "For in-depth explanation regarding this property: tune in to the corresponding watch at 4:05.\n",
    "\n",
    "### One Time MAC\n",
    "\n",
    "It is basically the analog of the one time pad, but in the world of integrity. So let me explain what I mean by that. So imagine we wanna build a MAC that is only used for integrity of a single message. In other words, every time we compute the integrity of a particular message, we also change the key. So that any particular key is used only for integrity of one message. This is referred to as One Time MAC.\n",
    "\n",
    "![](./Images/OneTimeMAC.png)\n",
    "Description:<br>\n",
    "- We can define the security game as basically saying, the attacker's gonna see one message. Therefore, we only allow him to do one chosen message attack(as the key is going to change per message MACing). \n",
    "- So, adversary gets to submit one message query, and he is given the tag corresponding to that one message query. And now his goal is to forge a message tag pair, i.e., to produce one message tag pair that verifies correctly and is different from the pair that he was actually given. \n",
    "- We would say that a one time act is secure, because basically no adversary can win this game. Now the interesting thing is that one time MACs, just like the one time pad can be secure against infinitely powerful adversaries. \n",
    "\n",
    "Catch: The only thing, with One Time MAC is that we would need to use a different key for MACing different messages and as these keys are secret keys, hence, the keys needs to be securely communicated to the recipient's end for verification.\n",
    "\n",
    "A classic example of One Time MAC:\n",
    "![](./Images/OTM-Example.png)\n",
    "Description:<br>\n",
    "The key is a pair of two random integers from [1...q] where q is a large prime number (usually greater than the number of blocks).<br>\n",
    "Basically, we construct a polynomial that corresponds to our message, if there are L blocks in the message then the polynomial would be L degree polynomial, then we evaluate that polynomial at half, K, of the secret key, and add the other half (a) of the secret key to the result, and of course reduce final result modulo q and that's the whole MAC. As a result, even though adversary have seen the value of the MAC on a particular message, he have no way of forging this MAC on some other message. \n",
    "\n",
    "Note: One Time MAC is way faster than PRF based MACs but it's just a one time MAC, hence not two time secure. In other words, if adversary get to see the value of the MAC on two different messages, that actually completely compromises the secret key. And adversary can actually predict a MAC for a third or fourth message of his choice. So then the MAC becomes forgeable.\n",
    "\n",
    "**One Time MAC to Many Time MAC**<br>\n",
    "Why we want to do that? <br>\n",
    "Because One Time MACs are very fast as compared to PRF Based MACs and hence for MACing large messages One Time MAC would be efficient (in terms of time). Now, we can use this great potential of One Time MAC if we can just find a way to get a Many Time MAC(single key for MACing multiple messages) out of it.\n",
    "\n",
    "Carter-Wegman MAC is general construction for a Many Time MACs which are built over a One Time MACs.\n",
    "![](./Images/OTM2MTM.png)\n",
    "\n",
    "The Flow:\n",
    "- Basically what we would do is we would apply the one time MAC to the message m and then we're going to encrypt the results using the PRF. \n",
    "- So how do we encrypt the result? Well, we choose a random r (nonce) and then we compute kind of a one time path from this r by applying the PRF to it.\n",
    "- And finally we XOR the result with the actual one time MAC to get the output tag.<br><br>\n",
    "So the neat thing about this construction is that the fast one time MAC is applied to the long message, which could be gigabytes long. And the slower PRF is only applied to this nonce r, which is then used to encrypt the final results of the MAC. And we can argue that if the MAC that was given to us as a building block is a one time secure MAC, and the PRF is secure, then, in fact, we get a Many Time secure MAC that happens to output 2n bit tags.\n",
    "\n",
    "We're gonna see Carter-Wegman MACs later on at authenticated encryption. And, in fact, one of the NIST standard methods for doing encryption with integrity, uses a Carter-Wegman MAC for providing integrity. Carter-Wegman MAC is a good example of a randomized MAC where this nonce r is chosen afresh every time the tag is computed. And so for example if we try to compute a tag for the same message twice each time you'll choose a different r and as a result you'll get different tags both the time.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAC from Collision Resistant Hash-Functions (The Rise of the HMAC)\n",
    "\n",
    "Note: In order to understand HMAC we would first need to understand Collision Resistant Hash functions and ways to construct them. Once done, we can explore one of the most popular MAC of the all, the HMAC.\n",
    "\n",
    "**Hash Function:** A hash function is any function that can be used to map data of arbitrary size to data of a fixed size. The values returned by a hash function are called hash values, hash codes, digests, or simply hashes.<br>\n",
    "\n",
    "![](./Images/CollisionResistance.png)\n",
    "\n",
    "**What does it mean for a hash function to be collision resistant?**<br> \n",
    "We have a hash function from some message space M to a tag space T, where |M| >>>> |T|. So, the messages could be gigabytes long, but the tags would only be like 160 bits. \n",
    "\n",
    "A collision for the function H could be described as follows: there exist a pair of messages $m_{0}$, $m_{1}$ (in the message space), that happen to be distinct, however, when you apply the function H to them, you end up with the same output(in the tag space), which is referred to as **collision**.\n",
    "\n",
    "Now we say that the function is collision resistant if it's hard to find collisions for this function. Now this should seem a little bit counterintuitive because we know that the output space is tiny compared to the input space. So, by the [pigeonhole principle][], there must be lots and lots and lots of messages that map to the same output. Just because there isn't enough space in the output space to accommodate all the messages without collisions.\n",
    "\n",
    "[pigeonhole principle]: https://en.wikipedia.org/wiki/Pigeonhole_principle\n",
    "\n",
    "So, we know that there are lots of collisions, and the question is, is there an efficient algorithm that finds any such collisions explicitly? So we say the, **the function is collision resistant, if, for all explicit efficient algorithms A, these algorithms are not able to print/find the collision for the function H.**\n",
    "\n",
    "Example:<br>\n",
    "Classic example of a collision resistant hash function is SHA-256 (Secure Hash Algorithm-256) which happens to output 256 bits (called hash or digest) for arbitrary large inputs. For example, it can take gigabytes and gigabytes of data and it will map it all to 256 bits. And yet nobody knows how to find collisions for this particular function. **SHA-256 is commonly used in Blockchain**.\n",
    "\n",
    "**How can we build, trivially, a MAC given a collision resistant hash function?**<br>\n",
    "We aren't trying to build a MAC here, but instead we are trying to build a secure MAC for large messages with collision resistant hash functions as the building block.\n",
    "\n",
    "![](./Images/MACfrmHashFxn.png)\n",
    "Description:\n",
    "- Suppose we have a MAC for short messages (you should be thinking something like AES, which can MAC sixteen byte messages) and then, suppose we have a hash function, a collision resistant hash function from a large message space, that contains gigabyte messages into our small message space (say, into sixteen byte outputs).\n",
    "- Then, basically, we can define a new MAC, let's call it $I^{big}$, which happens to be MACing large messages. And we'll define it simply by applying the small MAC to the output of the hash function. <br>\n",
    "Note: As the hash fxn spits out 16 bytes output for arbitrary len messages, our small MAC, which can MAC 16-bytes messages, can take the output of the hash fxn and MAC it. \n",
    "- And how do we verify a MAC? Well, basically, given a tag we verify it by rehashing the given message and then checking that small MAC(our AES-based MAC) actually verifies under the given tag.\n",
    " \n",
    "Example build:<br>\n",
    ">Let's say we use SHA-256 as our collision resistant hash function. So, SHA-256 outputs 256 bit outputs, which is 32 bytes. Therefore we have to build a small MAC that can MAC these 32 byte outputs from SHA-256. And the way we could do that is basically by applying the sixteen byte AES, plugging it into a two block CBC. **A two block CBC would expand AES from a PRF on sixteen bytes to a PRF on 32 bytes**. And then take the output of SHA-256 and plug it into this two block CBC based on AES. And then we get a very, very simple, MAC which is secure assuming AES is a PRF and SHA-256 is collision resistant.\n",
    "\n",
    "Note: Collision Resistant is crucial for this $I^{big}$ MAC to be secure. What if the Hash function isn't collision resistant? Then an adversary would be able to make an existential forgery as depicted below.\n",
    "\n",
    "![](./Images/InsecureMACfromHash.png)\n",
    "<br>\n",
    "A real world application where Collision Resistance(CR) Hash functions are used for message/file integrity:\n",
    "\n",
    "![](./Images/ApplicationCRHash.png)\n",
    "\n",
    ">**CR Hash functions provides message integrity without the need of a secret key (referred to as public verifiability), however they require a read-only public space** (i.e. these spaces cannot be modified by any adversary). Whereas with MACs we have an exact complement i.e. we need a secret key, but won't require this read only public space. \n",
    "\n",
    "Later on, we will see that with Digital Signatures we will get the best of both worlds, i.e., with **Digital Signatures** we can achieve public verifiability without the need for read-only space.\n",
    "\n",
    "**General Attack on CR Hash Functions: Generic Birthday Attack**<br>\n",
    "Recommended  Watch: [Generic Birthday Attack](https://www.coursera.org/learn/crypto/lecture/pyR4I/generic-birthday-attack)\n",
    "\n",
    "Overview of **Birthday Paradox**:\n",
    ">In probability theory, the birthday paradox concerns the probability that, in a set of n randomly chosen people, some pair of them will have the same birthday. By the pigeonhole principle, the probability reaches 100% when the number of people reaches 367 (since there are only 366 possible birthdays, including February 29). However, 99.9% probability is reached with just 70 people, and 50% probability with 23 people (it's called a paradox because 23, 70 being such a small number still generates a probability of 50% and 70%, which is paradoxical). These conclusions are based on the assumption that each day of the year (excluding February 29) is equally probable for a birthday, i.e. uniformly distributed.\n",
    "\n",
    "Fact: Under the BDay attack we consider bdays to be uniformly distributed but in reality birthdays aren't equally distributed rather they have a bias towards the month of September, thereby lifting the probability of collisions.\n",
    "\n",
    "Theorem and Proof of the Birthday Paradox:<br>\n",
    "![](./Images/TheBirthdayParadox.png)\n",
    "\n",
    "Note: To profoundly understand birthday paradox and its formulation tune in to the recommended watch at 2:25.\n",
    "\n",
    "General Attack Overview:<br>\n",
    "We saw a general attack on block ciphers which we called **exhaustive search**. And that attack **forced the key size for a block cipher to be 128 bits or more**. Similarly, on collision resistance there is a general attack called the **birthday attack** which **forces the output of collision resistant hash functions to be more than a certain bound**. \n",
    "\n",
    "Following is the algorithm for the Birthday Attack, collisions could be found within 2 iterations due to the birthday paradox.\n",
    "![](./Images/BirthdayAttackAlgo.png)\n",
    "\n",
    "Shown below are the CR Hash functions with their digest size and based on the birthday attack their generic attack time(in which a collision can be found).\n",
    "\n",
    "![](./Images/SampleCRHashFxn.png)\n",
    "\n",
    "With **increase in the digest size that these CR Hash functions produce, we compromise the hashing speed** and therefore we need to, depending on the context, balance between the performance and security trade-off.\n",
    "\n",
    "Note: Attack time below $2^{90}$ aren't considered safe, and therefore, although there is no collision found for SHA-1 till date but is not considered a safe algorithm anymore, because collisions can be found for it in very near future. Hence, don't use SHA-1 for integrity purposes, it's better to use SHA-256.\n",
    "\n",
    "While using Quantum Computers, we can find collisions in cube root time of the digest(output) length.\n",
    "![](./Images/QuantumFinder.png)\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Collision Resistant Hash Functions\n",
    "\n",
    "![](./Images/Goal-CRHashFxn.png)\n",
    "We're gonna construct these collision resistant hash functions, in two steps:\n",
    ">1. The first step is to show that if you give me a collision resistant hash function for short messages, we can extend it and build a collision resistant hash function for much, much, much longer messages. \n",
    "2. In the second step, we'll actually build collision-resistant Hash functions for short messages [that we used in the first step]. \n",
    "\n",
    "#### Step 1: Merkle-Damgard Paradigm \n",
    "It is basically a construction to achieve the first step of constructing the collision resistant hash functions. The construction is actually very general and in fact all collision-resistant hash functions follow this paradigm.\n",
    "\n",
    "![](./Images/Merkle-DamgardParadigm.png)\n",
    "How it works:\n",
    "- We have our function h which we're gonna assume is a collision-resistant hash function for small sized inputs all known as the **compression function**. <br><br>\n",
    "- So the way we're gonna use this little function h is we're gonna take a big message M and break this message in to blocks. And then we use a fixed value called the IV(Initialization Vector), which acts the first chaining variable $H_{0}$. Here in this case the IV is fixed forever. And it's basically embedded in the code and in the standards (the fixed size is equal to the length of the hash function's digest domain). <br><br> \n",
    "- Then we apply the small compression function h to the first message block along with this IV. What comes out of that is what's called a chaining variable that's gonna be fed into the next compression function which compresses the next block along with the previous chaining variable and out comes the next chaining variable, and the next message block is compressed, and so on and so forth until we reach the final message block.<br><br>\n",
    "- Then at the final message block, the one special thing that we do, is that we must append a padding block (PB), after we append the padding block we again compress the last chaining variable with the last message block, and the output of that is the actual output of the hash function i.e. the digest/tag.\n",
    "\n",
    "To summarize, we basically use these small hash functions (who are able to compress/hash only small messages), called compression functions, to build a large hash function (that can hash really long messages).\n",
    "\n",
    "**Why that Padding Block(PB)?**<br>\n",
    "The padding block is actually very important. Well it's a sequence of 1000 that denotes the end of the actual message block. And then the most important part of it is that we encode the message length in this padding block. And the message length is basically fixed to be 64 bits. So, **in all the SHA hash functions the maximum message length is $2^{64} - 1$** such that the message length fits into a 64 bit block. An this upper bound of $2^{64} - 1$ bit on the message length is actually sufficiently long to handle all of the messages that we're ever gonna throw at it.\n",
    "\n",
    "Ques: What do we do if the last block really is a multiple of the compression function block length? Where are we gonna fit the padding block?<br>\n",
    "Ans: Basically if there's no space for the padding block in the last block of the message, then we're gonna add another dummy block (of the compression function block length) and stick the padding block in there. And of course put the 1000.. in the right place. Okay so the point is that it's very, very important that the padding block contains the message length as we'll see later.\n",
    "\n",
    "**The Theorem that made Merkle-Damgard popular**\n",
    "\n",
    ">As mentioned above, all standard hash functions follow this paradigm for constructing a collision resistant hash function from a compression function. The reason that this paradigm is so popular is because of the following theorem, which says basically that: **If the little compression function is collision resistant, then the big Merkle-Damgard hash function is also collision resistant.** In other words, if we're going to build collision resistant functions for large inputs, all we have to do is just build compression functions that are collision resistant. \n",
    "\n",
    "So, given below is the proof for this theorem. It's a elegant proof and not too difficult. The way we're gonna prove it is using the contrapositive, that is, if you can find me a collision on the big hash function then we're gonna deduce a collision on the little compression function. Therefore, if little h is a collision resistant, so will be the big H.\n",
    "\n",
    "![](./Images/MD-Theorem.png)\n",
    "![](./Images/MD-Theorem-cont.png)\n",
    "Note: For in depth explanation of the theorem, please refer to [The Merkle-Damgard Paradigm](https://www.coursera.org/learn/crypto/lecture/Hfnu9/the-merkle-damgard-paradigm) at 4:32.\n",
    "\n",
    "#### Step 2: Constructing secure compression/small-hash function\n",
    "\n",
    "So we're going to see a couple of constructions. And so the first question that comes to mind is well, can we build compression functions from primitives that we already have? In particular, we spent a lot of work to build block ciphers and the question is can we build compression functions from block ciphers? And the answer is yes.\n",
    "\n",
    "**Compression function from Block Ciphers**\n",
    "\n",
    "Assume we have a certain block cipher E that operates on n bits blocks, so the input is n bits, output is n bits. And then there's this classic construction called a **Davies-Meyer** compression function construction (there are many other block cipher based compression function constructions but Davies-Meyer is the prominent one). \n",
    "\n",
    "![](./Images/Davies-Meyer.png)\n",
    "The way it works is:\n",
    ">Given the message block and the chaining variable, all it do is encrypt the chaining variable using the message block as the key. And then it do one more XOR with the chaining variable H to produce the output. So this might seem a little bizarre, because remember the message block is something that's completely under the control of the adversary. He's trying to find the collision so he can choose the message blocks however he wants. And yet we're using this message block as a key into a block cipher. But nevertheless, we can argue that this construction, at least when E is what's called an ideal cipher, we can argue that this construction is in fact as collision resistant as possible.\n",
    "\n",
    "Note: **The best possible collision resistance that a Hash function could ever achieve is $O(2^{n/2})$ as per the Generic Birthday Attack (where n represents the tag/digest length)**. Hence, the what the above theorem (and its provable) is trying to say is, given that E is an ideal block cipher and Davies-Meyer using message as the key to the cipher, still finding a collision would be of the order $O(2^{n/2})$, which is best collision resistance possible.\n",
    "\n",
    "Warning: If we drop the final XOR of the output of the Encryption function with the chaining variable H in the Davies-Meyer construction then the compression function will, provably, not be collision resistant. So, that XOR b/w the output from E and chaining variable H is very crucial.\n",
    "\n",
    "**Case Study: SHA-256** <br>\n",
    "Now, basically, we have all the ingredients to describe the SHA-256 hash function.\n",
    "\n",
    "![](./Images/CaseStudy-SHA256.png)\n",
    "- SHA-256 is a Merkel-Damgard construction, exactly as the one that we saw before. \n",
    "- It uses a Davies-Mayer compression function. And so the only question is, what's the underlying block cipher for Davies-Mayer? - The block cipher is called SHACAL-2. We will just see its parameters. \n",
    "    - It uses a 512 bit key. And remember the key is taken from the message block in Davies-Mayer. So, this is really what the  size of the message block is i.e. SHA-256 will process its input message 512 bits at a time. \n",
    "    - It uses a 256-bit block size for messages and these are the chaining variable in Davies-Mayer, therefore SHA-256 produces a 256-bit digest.\n",
    "    \n",
    "**Provable Compression Functions**\n",
    "\n",
    "It turns out there's another class, besides the block cipher class, of compression functions that's built using hard problems from number theory. We call these compression functions **provable because if you can find the collision on this compression function then you're going to be able to solve a very hard number theoretic problem which is believed to be intractable**. And as a result, if the number theory problem is intractable, the resulting compression function is provably a collision resistant.\n",
    "\n",
    "Given below is an example of a provable compression function.\n",
    "![](./Images/ProvableCompressionFunc.png)\n",
    "Note: Why do we don't use these compression functions? Due to the fact that they give very slow performance as compared to block cipher based compression functions.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HMAC (a MAC from SHA-256)\n",
    "Corresponding Watch: [HMAC](https://www.coursera.org/learn/crypto/lecture/OjMrT/hmac)\n",
    "\n",
    "The fundamental question that we are trying to address here is: Can we use a Hash function(large) to build a MAC?\n",
    "\n",
    "Suppose we have a Merkle-Damgard hash function (say SHA-256), it hashes large messages into small digests and we want to convert that directly into a Mac. The first thing that comes to mind is well why don't we just hash the concatenation of the MAC key as long with the message that we're trying to MAC? It turns out that this is completely insecure. Why is this is insecure? The answer is the standard extension attack.\n",
    "\n",
    "![](./Images/MDExtensionAttack.png)\n",
    "Description:<br>\n",
    "Realize that if adversary gets the tag T = H(m) of a particular message, in other words he gets the value at the blue point. It's very easy for the attacker to just add another block (m' = blocks of m + w block), and then compute one last stage of the compression function H (with Tag T as the chaining variable and w as the final message block). And now he'll be able to get a valid tag (as we are using this output of Merkle-Damgard as tag) for the new message m' (which is original message concatenated the padding block, concatenated the w block that he added himself) and as a result this is an existential forgery. \n",
    "\n",
    "Then how do we construct MAC out of Hash?<br>\n",
    ">There's a **standardized method to convert a collision resistant hash function to a MAC and that method is called HMAC**. In particular, we could use the SHA-256 hash function to build this MAC. The output is going to be 256 bits and in fact HMAC is believed to be a pseudo-random function, so out of SHA-256 we build a pseudo-random function that outputs 256 bit outputs. \n",
    "\n",
    "![](./Images/StandardMethod-HMAC.png)\n",
    "[ || represents prepending ]\n",
    "\n",
    "The Flow:<br>\n",
    "- First we take our key k and we concatenate what's we call an internal pad to it, an ipad to it. This makes it into one block of the Merkle-Damguard construction, so for example this would be 512 bits in the case of SHA256 (as it uses SHACAL-2). <br><br>\n",
    "- We prepend(||) this to the message m (i.e. the k XOR ipad block is prepended to the m blocks) and then we do the complete hashing process. Now this by itself we just said is completely insecure. <br><br>\n",
    "- However, what HMAC does in addition, it takes the output, which is 256 bits, it prepends to that the key again XOR with, what's called the outer pad, the opad. This also becomes 512 bits. It's one block. And then it hashes the combination of these two to finally obtain the resulting tag on the message m. \n",
    "\n",
    "Note: The ipad and the opad are fixed 512-bits constants that never changes.\n",
    "\n",
    "![](./Images/HMACinPicture.png)\n",
    "HMAC is very identical to NMAC (see corresponding watch for explanation), the only difference is that keys k1 and k2 in NMAC were independent whereas in HMAC are dependent.\n",
    "\n",
    "Following are the properties of HMAC:\n",
    "![](./Images/HMAC-Properties.png)\n",
    "\n",
    "#### Time Attacks on MAC verification\n",
    "\n",
    "Lets look at a general attack that affected and still affects many implementations of MAC algorithms. And there's a nice lesson to be learned from an attack like this.\n",
    "\n",
    "We'll look at a particular implementation of HMAC verification. This happens to be an implementation from the Keyczar library, that happens to be written in Python. So given below is a snippet of the simplified version of the code that's used to verify a tag generated by HMAC. \n",
    "![](./Images/WeaknessInImplementation.png)\n",
    "\n",
    "The inputs are as follows: the key, the message, and the tag bytes. The way it verify it is, it re-compute the HMAC on the message and then compares the resulting sixteen bytes to the actual given signature bites. So this looks perfectly fine. In fact, anyone might implement it like this. And, in fact, many people have implemented it like this.\n",
    "\n",
    ">The problem is, that if you look at how the comparison is done, the comparison, as you might expect, is done byte by byte. There's a loop inside of the Python interpreter that loops over all sixteen bytes. And it so happens that the first time it finds an inequality, the loop terminates and says the strings are not equal. And the fact that the comparator exits when the first inequality is found introduces a significant timing attack on this library. . \n",
    "\n",
    "Let's see how an attack can be done against the above verification implementation.\n",
    "![](./Images/VerificationTimingAttacks.png)\n",
    "Description:<br>\n",
    "- What the attacker is gonna do is to submit many message tag queries, where the message is always the same but with a tag, he's gonna experiment with lots and lots and lots of different tags.<br><br>\n",
    "- So in the first query, what he's gonna do is just submit a random tag along with the target message. And he's gonna measure how long the server took to respond.<br><br>\n",
    "- With the next query that he's gonna submit, he's gonna try all possible first bytes for the tags. So, the remaining bytes of the tags that he submits are just arbitrary, doesn't really matter what they are. But for the first byte, what he'll do is he'll submit a tag starting with a byte value zero. And then he's gonna see whether the server took a little bit longer to verify the tag than before. If the server took exactly the same amount of time to verify the tag as in step one, then he's gonna try again, this time with (first)byte's value one. If still the server responded very quickly, he's going to try with byte value two and so on.<br><br>\n",
    "- Until finally, let's say, when the byte sets of as 3 the server takes a little bit longer to respond. What that means is actually when it did the comparison between the correct MAC and the MAC submitted by the attacker. The two matched on the 1st byte, and the rejection happened on the second bytes. Aha. So now the attacker knows that the first byte of the tag is set to 3 and now he can mount exactly the same attack on the second byte and similarly for all the remaining bytes of the tag.\n",
    "\n",
    "This way the attacker can use this implementation weakness and commit a side channel attack (here timing attack) to achieves the goal of existential forgery.\n",
    "\n",
    "Following are the Defenses against timing verification attack:\n",
    "\n",
    "Defense 1\n",
    "![](./Images/Defense1-VTA.png)\n",
    "Description:<br>\n",
    "What we do is implement our own comparator. And it will always take the same amount of time to compare the two strings. So in particular, this uses the zip function in Python, which will, essentially, if you are giving it two sixteen byte strings, it will create sixteen pairs of bytes. So it'll just create a, a list of sixteen elements, where each element is a pair of bytes. One taken from the left and one taken from the right. And then you loop through this list of pairs. You compute the XOR of the first pair, and the OR into the result. Then you compute the XOR of the second pair, and you OR that into the result. And you note that, if at any point in this loop, two bytes happen to be not equal, then the XOR will evaluate to something that's non zero and when we OR'ed (result = result | ord(x)^ord(y)) it into the result. The result will also become non-zero, and then we'll return false, at the end of the comparison. So, the comparison this way will always take the same time.\n",
    "\n",
    "However, this can be quite problematic, because compilers tries to be too helpful here. So an optimized compiler might look at this code and say, hey, wait a minute. I can actually improve this code by making the four loop end. As soon as an incompatible set of bytes is discovered.\n",
    "\n",
    "Defense 2\n",
    "![](./Images/Defense2-VTA.png)\n",
    "Description:<br>\n",
    "The way we do the comparison is we first of all, compute the correct MAC on the message. But then instead of directly comparing the MAC and the signature bytes from adversary, what we're gonna do is we're gonna hash one more time. So we compute a hash here of the MAC. We compute a hash of the signature bytes. Of course, if these two happen to be the same, then the resulting HMACs will also be the same, so the comparison will actually succeed. But the point is now, if signed bytes happen to equal MAC on say first 3 bytes, but not on the remaining bytes. Then, when we do this additional hash layer, it's likely that the two resulting values are completely different. And as a result, the byte by byte comparator will just output on the first iteration. The point here is that the adversary doesn't actually know what strings are being compared. And as a result, he can't mount a timing attack that we discussed earlier.\n",
    "\n",
    "The Ultimate Lesson: \n",
    ">Realize that people who even are experts at implementing crypto libraries, get this stuff wrong (as seen with Keyczar). And even the right code that works perfectly fine and yet is completely vulnerable to a timing attack that completely undo all security of the system. So **the lesson here is, of course, you should not be inventing your own crypto but you shouldn't even be implementing your own crypto** because most likely it'll be vulnerable to the side channel attacks. Just use a standard library like OpenSSL etc.\n",
    "\n",
    "![](./Images/UltimateLesson.png)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Authenticated Encryption\n",
    "\n",
    "In this section, we're going to see how to combine these confidentiality and integrity mechanisms to obtain encryption schemes that are secure against a much, much stronger adversary, namely an adversary that can tamper with traffic while it's in the network, inject its own packets, block certain packets, and so on.\n",
    "\n",
    "Goal: And our goal is basically to ensure that even against such powerful adversaries, we maintain confidentiality. In other words, the adversary can't learn what the plain text is and the adversary can't even modify the cipher text. \n",
    "![](./Images/AuthEncryp-Recap.png)\n",
    "\n",
    "**Passive vs Active Adversary**\n",
    ">Passive Adversary: In crypto, we tend to think of a passive adversary (Eve) as someone who is able to listen to all communications sent between two parties, (Alice and Bob). So, you create a security goal based on the \"power\" of your adversary. If all that Eve is doing is listening on communications, then Alice and Bob need to ensure that Eve cannot understand whatever it is she reads (hence achieve confidentiality via CPA-security).<br><br>\n",
    "Active Adversary: Intuitively, active adversary is an adversary which is has the ability to interact actively with the communicating parties or to tamper with the communication data over the medium, besides just eavesdropping or sniffing over the communication. \n",
    "\n",
    "Note: \n",
    "- In general, Eve is name assigned to a Passive attacker and Mallory to an Active attacker.\n",
    "- We create a security goal based on the \"power\" of the adversary (Threat Model).\n",
    "\n",
    "#### Why Authenticated Encryption is so important? (Active Attacks on CPA-Secure Encryptions)\n",
    "\n",
    "We'll understand this via an example of adversaries that can tamper with traffic and as a result completely break security of CPA-secure encryption. This will show you that, without providing integrity, confidentiality can also be destroyed. In other words, the two must go together, integrity and confidentiality, if we're going to achieve security against active adversaries. So let's look at an example from the world of networking. \n",
    "\n",
    "![](./Images/SampleTamperingAttack.png)\n",
    "Description:<br>\n",
    "Let's look at TCP/IP. We are going to use a highly simplified version of TCP/IP. Here we have two machines communicating with one another. A user sits at one machine, and the other machine is a server. Now, the server, of course, has a TCP/IP stack that's receiving packets. And then, based on the destination field in those packets, it forwards the packets to the appropriate place/port. So here we have, for example, two processes listening to these packets. A web server and another user (we'll call him Bob). The web server listens on port 80, and Bob listens on the port 25. \n",
    "\n",
    "When a packet arrives, the TCP/IP stack looks at the destination port. In case, it would be destination port 80, and as a result, the stack forwards the packets over to the web server. If the destination port said port 25, the TCP/IP stack would forward the packet over to Bob, who's listening on port 25.\n",
    "\n",
    "Now, a fairly well known security protocol called IPsec, encrypts these IP packets between the sender and the recipient(server). So here, the sender and the recipients basically have a shared key. And when the sender sends IP packets, those IP packets are encrypted using the secret key K. Now when a packet arrives at the destination, and I mean it arrives at the server, the TCP/IP stack will go ahead and decrypt the packet, and then look at the destination port and send it to the appropriate place decrypted. \n",
    "\n",
    "![](./Images/ReadingSomeone'sData.png)\n",
    "\n",
    "Imagine the attacker intercepts a certain packet that's intended for the web server. In other words, it's an encrypted packet intended for port 80. So what Bob (who is playing the adversary here) is going to do is he's gonna intercept this packet and prevent the packet from reaching the server as it is, and instead, he's going to modify the packet (i.e. change the destination port value). So now the destination port is going to read like port 25. This is done on the cipher text and we're going to see how to do that. When this packet now arrives at the server, the destination port says 25, the server will decrypt the packet, see that the destination is 25 and forward the data over to Bob. So, simply by changing the destination port, Bob was able to read data that was not intended for himself.\n",
    "\n",
    "**How can adversary switch the port address on the ciphertext?**<br>\n",
    "So, if the data is encrypted, say, using a CBC encryption with a random IV, remember this is a CPA-secure scheme. Nevertheless, if this is the case then it's trivial for the attacker to change the cipher text. So that now he can obtain new cipher text where the destination port is 25 instead of 80. The only thing that's gonna change is just the IV field. In fact, everything else is gonna remain the same. By simply modifying the IV field the attacker would be able to switch the destination port number. This would be done as follows:\n",
    "\n",
    "![](./Images/ModifyingPortAddress.png)\n",
    "\n",
    "The way adversary decrypts CBC encrypted data is essentially the first plain text block is simply decryption of the first cipher text block XORed with IV, that is, **m [ 0 ] = D ( k , c [ 0 ] ) XOR IV** and this equation is going to read 80 (when first block is representing the destination port) now to if he simply XOR this equation with a message size block that represents value 80 then that would make the first block's value zero and now if he further XOR this with a message size block that represents value 25, then that would make the first block's value to be 25. Following would be the equation **m[ 0 ] = D ( k , c [ 0 ] ) XOR IV XOR (..80..) XOR (..25..)**, where (..xx..)represents a block with value corresponding to xx in binary representation. Hence, the destination port now has the value of 25 and the server on receiving the packet will decrypt it, check the the port value, and send to the adversary (Bob) who listening at port number 25.\n",
    "\n",
    "Note: There are different types of Active attacks that adversary can do, if we only use security schemes that provide confidentiality, CPA-security, without integrity (and that would be result in confidentiality of no use, as it would get compromised).\n",
    "\n",
    "![](./Images/LessonFromAttack-AuthEncryp.png)\n",
    "<br>\n",
    "\n",
    "----\n",
    "<br>\n",
    "\n",
    "### Authenticated Encryption: Definition\n",
    "\n",
    "Authenticated encryption is a cipher where as usual the encryption algorithm takes a key, a message and optionally a nonce and outputs a cipher text. The decryption algorithm as usual outputs a message. However, here the decryption algorithm is allowed to output a special symbol called bottom (inverted T). When the decryption algorithm outputs the symbol bottom, basically it says that the cipher text is invalid and should be ignored. The only requirement is that this bottom is not in the message space so that in fact it is a unique symbol that indicates that the cipher text should be rejected. \n",
    "![](./Images/AuthenticatedEncryption.png)\n",
    "Now what does it mean for an authenticated encryption system to be secure? Well the system has to satisfy two properties:\n",
    "- It has to be **semantically secure** under a chosen plaintext attack just as before. \n",
    "- But now there's a second property which says that the system also has to satisfy what's called **cipher text integrity**. What that means is that even though the attacker gets to see a number of cipher texts, it should not be able to produce another cipher text that decrypts properly. In other words, that decrypts to something other than bottom.\n",
    "\n",
    "More precisely, let's look at the ciphertext integrity game:\n",
    "\n",
    "![](./Images/EncryptionWithCiphertxtIntegrity.png)\n",
    "Description:<br>\n",
    "- So here, (E,D) is a cipher with message space M. As usual, the challenger begins by choosing a random key K. And the adversary can submit messages of his choice, and receive the encryptions of those messages. So here, $c_{1}$ is the encryption of $m_{1}$, where $m_{1}$ was chosen by the adversary. And the adversary can do this repeatedly. Therefore, he submits many more messages up until $m_{q}$ and obtains the encryption of all those messages. \n",
    "- Hence, the adversary obtained q ciphertexts for messages of his choice. Then his goal is to produce some new cipher text that's valid. So we'll say that the adversary wins the game if basically this new cipher text that the adversary created decrypts correctly, in other words decrypts to something other than bottom (inverse T). \n",
    "- As usual we defined the adversary's advantage in the cipher text integrity game as the probability that the challenger outputs one at the end of the game and we'll say that the cipher has cipher text integrity if in fact for all efficient adversaries the advantage in winning this game is negligible.\n",
    "\n",
    "Following is a bad example of Authenticated Encryption (a CPA secure cipher that doesn't provide authenticated encryption):\n",
    "![](./Images/BadExOfAuthEncryp.png)\n",
    "The CBC with a random IV does not provide authenticated encryption because it's very easy for the adversary to win the cipher text integrity game. The adversary simply submits a random cipher text and since the decryption algorithm for CBC encryption never outputs bottom, it always outputs some message, the adversary just easily wins the game. Any old random cipher text will decrypt to something other than bottom and therefore the adversary directly wins the cipher-text integrity game. So this is just a trivial example of a CPA secure cipher that does not provide authenticated encryption.\n",
    "\n",
    "**Implications of Authenticated Encryption**:\n",
    "\n",
    "**Implication 1: Authenticity**\n",
    "\n",
    "![](./Images/Implication1-AE.png)\n",
    "\n",
    "The first implication is Authenticity, which means that, basically, an attacker cannot fool the recipient, Bob, into thinking that Alice sent a certain message that she didn't actually send. What it means is: \n",
    "- Here, the attacker basically gets to interact with Alice, and get her to encrypt arbitrary messages of his choice. So this is a chosen plain text attack. And then the attacker's goal is to produce some cipher text that was not actually created by Alice. - Because the attacker can't win the cipher text integrity game, he can't do this. What this means is, when Bob receives the cipher text that decrypts correctly under the decryption algorithm, he knows that the message must have come from someone who knows the secret key K. In particular, if Alice is the only one who knows K, then he knows the cipher text really did come from Alice, and it's not some modification that was sent by the attacker. \n",
    "\n",
    "Caveat to Authenticity:<br>\n",
    "The only caveat to that is that authenticated encryption doesn't defend against replay attacks. In particular, the attacker could've intercepted some cipher text from Alice to Bob. And could have replayed it and both cipher text would look valid to Bob. So for example, Alice might send a message to Bob saying transfer 100 dollars to Charlie. Then Charlie (playing an adversary) could replay that cipher text and as a result, Bob would transfer another 100 dollars to Charlie. So in fact, any encryption protocol has to defend against replay attacks and this is not something that's directly prevented by authenticated encryption. \n",
    "\n",
    "**Implication 2: Security against CCA (Chosen Ciphetext Attack)**\n",
    "![](./Images/Implication2-AE.png)\n",
    "\n",
    "The second implication of authenticated encryption is that it defends against a very powerful type of adversary, namely an adversary that can mount what's called a chosen cipher text attack. \n",
    "\n",
    "#### Chosen Ciphertext Attacks (and Security)\n",
    "Corresponding Watch: [Chosen Ciphertext Attacks](https://www.coursera.org/learn/crypto/lecture/MKepS/chosen-ciphertext-attacks)\n",
    "\n",
    "Following depicts the Threat model (powers and goals of the adversary) for Chosen ciphertext security.\n",
    "![](./Images/CCA-ThreatModel.png)\n",
    "\n",
    "**Chosen Ciphertext Security Model:**\n",
    "\n",
    "Lets define the Chosen ciphertext security model more precisely. So, as usual, we have a cipher (E, D). And we're gonna define two experiments, EXP(0) and EXP(1). The challenger is gonna start off by choosing a random key. And now the adversary is gonna submit queries to this challenger. <br> \n",
    "Every query can be one of two types:\n",
    "- It can be a chosen plain text query(CPA-query), or \n",
    "- It can be a chosen cipher text query(CCA-query). \n",
    "\n",
    "![](./Images/ChosenCiphertxtSecurityModel.png)\n",
    "\n",
    "CPA Query:<br>\n",
    ">In a chosen plain text query, as we already know, the adversary submits two messages, $m_{0}$ and $m_{1}$. They have to be the same length. And the adversary receives the encryption of either $m_{0}$ if we're in EXP(0), or $m_{0}$, if we're in EXP(1). \n",
    "\n",
    "CCA Query:<br>\n",
    ">This is where the adversary submits an arbitrary cipher text of his choice and what he gets back is the decryption of that cipher text (such scenarios do take place in real-world). So you notice the adversary is allowed to decrypt arbitrary cipher texts of his choice. The only restriction is that the ciphertext is not one of the ciphertexts (referred to as challenge ciphertexts) that were obtained as a result of a CPA query. And of course this wouldn't be fair otherwise, because the attacker can simply take one cipher text that was obtained from a CPA query. That's gonna to be either the encryption of $m_{0}$ or the encryption of $m_{1}$. If he could submit a CCA query for that particular ciphertext, he will in response either obtain $m_{0}$ or $m_{1}$, and then he'll know whether he is in EXP(0) or EXP(1) and that would breach the CPA-security. \n",
    "\n",
    "Adversary's goal is to determine whether he's in EXP(0), or in EXP(1). Remember that this is an extremely powerful adversary. One that can decrypt any cipher text of his choice other than the challenge cipher text (and can obviously get messages of his choice encrypted and getting back the challenge ciphertexts). And still, he can't distinguish whether he is in EXP(0), or in EXP(1). \n",
    "\n",
    "**CCA Secure Ciphers**<br>\n",
    ">So, we say that the cipher is CCA secure, chosen cipher text secure, if the adversary behaves the same in EXP(0) as it does in EXP(1) i.e. the cipher(E) is CCA secure if, for all efficient Adversaries A, the $Advantage_{CCA}$ of A over the E is negligible. And $Advantage_{CCA}$ will be negligible if the probability that adversary outputs 1 in EXP(0) (wrongly identifying that the exp gave the ciphertext for $m_{1}$ whereas the output was for $m_{0}$) is same as the probability that he outputs 1(correctly identifying) in EXP(1). Basically, he isn't able to distinguish the two experiments.\n",
    "\n",
    "![](./Images/CCA-Secure.png)\n",
    "\n",
    "CBC, and similarly other CPA-secure ciphers, aren't CCA-Secure <br>\n",
    "Lets see why? \n",
    "- The adversary's gonna start by submitting two distinct messages, $m_{0}$ and $m_{1}$. And let's just pretend that these messages are one block messages. And what he's gonna get back is the CBC encryption of either $m_{0}$ or $m_{0}$. Notice that the cipher text only has one block, because the plain texts were only one block long. Now what is the attacker gonna do?<br><br> \n",
    "- Well, attacker is gonna modify this cipher text c that he was given into c' simply by changing the IV. So, he just takes the IV and XORs it with one. That's it. This gives a new cipher text, c', which is different from c and as a result it's perfectly valid for the adversary to submit c' (as it's not a challenge ciphertext) as a chosen ciphertext query. So he asks the challenger please decrypt this c' for me. <br><br>\n",
    "- The challenger, because c' is not equal to c, must decrypt c'. And now let's see, what happens when he decrypts c prime? Well, what's the decryption of c', you probably remember from earlier, that if we XOR the IV by one, that simply XORs the plaintext by one. So now that adversary received $m_{0}$ XOR 1, or $m_{1}$ XOR 1, therefore now he can perfectly tell whether he's in EXP(0) or EXP(1). So the advantage of this adversary is basically one, because he can very easily tell which experiment he's in. And as a result he can win the chosen cipher text security game.\n",
    "\n",
    "**How do we design crypto-systems that are CCA secure? Ans: Authenticated Encryption**\n",
    "\n",
    "The theorem, given below, basically says, if you give me a cipher that provides authenticated encryption then the cipher can withstand chosen cipher text attacks. And more precisely, the theorem says the following: if we have an adversary that issues q queries (at most, q CPA queries and q chosen cipher text queries), then there are two efficient adversaries, B1 and B2, that satisfy the given inequality. \n",
    "![](./Images/AuthEncrypIsCCASecure.png)\n",
    "Since the scheme has authenticated encryption, we know that $Adv_{CPA}$ is negligible because it's CPA secure. And we know that $Adv_{CI}$ is negligible because the encryption scheme has Ciphertext Integrity. And as a result, since both terms are negligible we know that adversary's advantage, $Adv_{CCA}$, in winning the CCA game is also negligible.\n",
    "\n",
    "Proof: The proof of the above theorem is pretty simple. Lets look at it:\n",
    "![](./Images/AE-CCAProof.png)\n",
    "\n",
    "Description<br>\n",
    "- Here, on the left, we have two copies of the CCA game. The above would be EXP(0). And the bottom one represents EXP(0).<br><br> \n",
    "- You can see the adversary's issuing CPA queries, and he's issuing CCA queries, and at the end he outputs, you know, a certain guess b prime, and our goal is to show that this b prime is indistinguishable in both cases. In other words, probability that b prime is equal to one in the top, left, game is the same as the probability that b prime is equal to one in the bottom, left, game. <br><br>\n",
    "- Assume that we change/upgrade the challenger a little bit, so that instead of actually outputting the decryption of CCA queries, the challenger is just gonna always output bottom(inverted T). In picture, we changes the top left challenger to top right. Therefore, every time the adversary submits a CCA query, the challenger says bottom. And these two, top-left and right, games are indistinguishable. In other words, the adversary can't distinguish these two games, for the simple reason that, because the scheme has Ciphertext Integrity, the adversary simply cannot create a ciphertext that's not a challenge ciphertext that decrypts to anything other than bottom. And since the scheme has cipher-text integrity, these left and right games are indistinguishable.<br><br>\n",
    "- The same thing exactly applies on the bottom (left and right games), where we can simply replace the chosen cipher-text responses by just always saying bottom, thereby upgrading bottom left to bottom right. But now, since the chosen cipher text queries always respond in the same way, they're not giving the adversary any information. So he might as well just remove these queries, cause they don't contribute any information to the adversary and is only left with CPA-security aspect thing to win the game.\n",
    "\n",
    "![](./Images/AE-CCAProof-2.png)\n",
    "- Now, once we remove these queries, the resulting upgraded games should look fairly familiar. The top right game, and the bottom right game are basically the two games that come up in the definition of CPA security. And as a result, because the scheme is CPA secure, we know that the adversary can't distinguish the top from the bottom.\n",
    "\n",
    "Hence, Authenticated Encryption schemes are CCA-Secure.\n",
    "\n",
    "Limitations of Authenticated Encryption:\n",
    "- does not prevent replay attacks\n",
    "- does not account for side channels (timing) attacks.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Authenticated Encryption: Standard Constructions\n",
    "\n",
    "Since we already have CPA secured encryption, and we have secure MACs, the natural question is whether we can combine the two somehow, in order to get authenticated encryption and that's exactly what we're gonna do.\n",
    "\n",
    "History of Authenticated Encryption:\n",
    "\n",
    "![](./Images/AuthEncryp-History.png)\n",
    "\n",
    "Authenticated encryption was introduced in the year 2000, in two independent papers. But before then, many crytpo libraries provided an API that separately supported CPA secure encryption, and MAC-ing. \n",
    "- So there was one function for implementing CPA secure encryption (providing confidentiality). For example, CBC with a random IV. \n",
    "- And another function for implementing a MAC (providing integrity). \n",
    "\n",
    "And then every developer that wanted to implement encryption, had to, himself, call separately the CPA secure encryption scheme and the MAC scheme. In particular, every developer had to invent his own way of combining Encryption and MAC-ing to provide some sort of authenticated encryption. But since the goals of combining encryption and MAC-ing wasn't well understood since authenticated encryption hasn't yet been defined, it wasn't really clear which combinations of encryption and MAC-ing are correct and which aren't. And so, every project as said had to invent its own combination. And in fact, not all combinations were correct. And the most common mistake in software projects were basically incorrectly combining the encryption and integrity mechanisms.\n",
    "\n",
    "**Different Ways of Combining Encryption and MAC to achieve Authenticated Encryption**\n",
    "\n",
    "Given below are three examples (ways of combining). In all three examples, there's a separate key for encryption, and a separate key for MACing. These two keys are independent of one another, and both are generated at session setup time. And we're gonna see how to generate these two keys later down the road.\n",
    "\n",
    "![](./Images/CombiningMAC&Enc.png)\n",
    "\n",
    "1. First example is the SSL protocol. So the way SSL combines encryption and MAC in the hope of achieving authenticated encryption is the following: basically you take the plain text, m, and then you compute a MAC on the plain text, m. So you use your MAC key, $k_{I}$, to compute tag for this message m. And then you can concatenate the tag to the message and then you encrypt the concatenation of the message and the tag and what comes out is the actual final ciphertext.<br><br>\n",
    "\n",
    "2. The second option is what IPsec does. So here, you take the message. The first thing you do is you encrypt the message. And then, you compute a tag on the resulting cipher text. So you notice the tag itself is computed on the resulting cipher text. <br><br>\n",
    "\n",
    "3. Third option is what the SSH protocol does. So here, the SSH takes the message, and encrypts it using a CPA secure encryption scheme. And then, to it, it concatenates a tag of the message. The difference between IPsec and SSH, is that in IPsec, the tag is computed over the cipher text, whereas, in SSH, the tag is computed over the message.\n",
    "\n",
    "And so these are three completely different ways of combining encryption and MAC. And the question is, which one of these is secure (as we mentioned that not all combinations are secure)?\n",
    "\n",
    "**Analyzing Combinations for CCA-Security**\n",
    "\n",
    "The SSH Method <br>\n",
    "Approach: **Encrypt-and-MAC**<br>\n",
    "Status: Insecure, don't use it.<br>\n",
    "Description:<br>\n",
    "In the SSH method you notice that the tag is computed on the message and then concatenated in the clear to the ciphertext. Now this is actually quite a problem because MACs themselves are not designed to provide confidentiality. MACs are only designed for integrity. And in fact, there's nothing wrong with a MAC that as part of the tag outputs a few bits of the plain text. That would be a perfectly fine tag. And yet if we did that, that would completely break CPA security here, because some bits of the message are leaked in the cipher text. And so the SSH approach, even though the specifics of SSH are fine and the protocol itself is not compromised by this specific combination, generally it's advisable not to use this approach. Simply because the output of the MAC signing algorithm might leak bits of the message. \n",
    "\n",
    "The SSL Method<br>\n",
    "Approach: **MAC-then-Encrypt**<br>\n",
    "Status: Partially Secure, can be used with certainty of providing Authenticated Encryption when Encryption scheme is rand-CTR mode or rand-CBC <br>\n",
    "Description:<br>\n",
    "As it turns out, for the SSL approach, there actually are kind of pathological examples, where you combine CPA secure encryption system with a secure MAC. And the result is vulnerable to a chosen cipher text attack, so that it does not actually provide authenticated encryption. And basically, the reason that could happen, is that there's some sort of a bad interaction between the encryption scheme and the MAC algorithm. Such that, in fact, there will be a chosen cipher text attack.\n",
    "\n",
    "The IPsec Method<br>\n",
    "Approach: **Encrypt-then-MAC**<br>\n",
    "Status: Completely Secure, recommended way to achieve authenticated encryption <br>\n",
    "Description:<br>\n",
    "The recommended method actually is the IPsec method because it turns out no matter what CPA secure system and MAC key you use the combination is always gonna provide authenticated encryption. We'll very, very briefly see why. Basically what happens is once we encrypt the message, well the message contents now is hidden inside the cipher text and now when we compute a tag of the cipher text basically we're locking, this tag locks the cipher text and makes sure no one can produce a different cipher text that would look valid. And as a result this approach ensures that any modifications to the cipher text will be detected by the decrypter simply because the MAC isn't gonna verify.\n",
    "\n",
    "![](./Images/AE-Theorems.png)\n",
    "\n",
    "Bottom Line: So if you're designing a new project the recommendation now is to always use Encrypt-then-MAC (IPsec method) because that is secure no matter which CPA secure encryption and secure MAC algorithm you're combining. \n",
    "\n",
    "**Authenticated Encryption: Standards**<br>\n",
    "Once the concept of authenticated encryption became more popular, a number of standardized approaches for combining encryption and MAC turned up. So we are going to see three of these standards, namely GCM, CCM and EAX. Two of these were standardized by NIST and they are called Galois Counter Mode(GCM) and CBC Counter Mode(CCM) .\n",
    "\n",
    "![](./Images/AE-Standards.png)\n",
    "Description: <br>\n",
    "1. **Galois Counter Mode(GCM)**: GCM basically uses counter mode encryption, so a randomized counter mode with a Carter-Wegman MAC, so a very fact Carter-Wegman MAC. And the way the Carter-Wegman MAC works in GCM is it's basically a hash function of the message that's being MACed. And then the result is encrypted using a PRF. Now this hash function in GCM is already quite fast to the point where the bulk of the running time of GCM is dominated by the counter mode encryption and it's even made more so in that Intel introduces a special instruction PCLMULQDQ specifically designed for the purpose of making the hash function in GCM run as fast as possible.<br><br>\n",
    "\n",
    "2. **CBC Counter Mode(CCM)**: CCM is another NIST standard. It uses a CBC MAC and then counter mode encryption. So this mechanism uses MAC, then encrypt, like SSL does. So this is actually not the recommended way of doing things, but because counter mode encryption is used this is actually a perfectly fine encryption mechanism. <br>\n",
    "One thing about CCM is that everything is based on AES. You notice, it's using AES for the CBC MAC, and it's using AES for the counter mode encryption. And as a result, CCM can be implemented with relatively little code. Cause all you need is an AES engine and nothing else. And because of this, CCM actually was adopted by the Wi-Fi alliance, and in fact, you're probably using CCM on a daily basis if you're using encrypted Wi-Fi 802.11i then you're basically using CCM to encrypt traffic between your laptop and the access point.<br><br>\n",
    "\n",
    "3. **EAX:** EAX uses counter mode encryption, and then CMAC. So, again you notice encrypt-then-MAC and that's another fine mode to use.\n",
    "\n",
    "Note: \n",
    "- All these modes are nonce-based. In other words, they don't use any randomness but they do take as input a nonce and the nonce has to be unique per key i.e. the pair (key, nonce) should never ever, ever repeat. But the nonce itself need not be random, so it's perfectly fine to use a counter as a nonce. \n",
    "- And the other important point is that, in fact, all these modes are what's called **Authenticated Encryption with Associated Data**. \n",
    "\n",
    "\n",
    "What's Authenticated Encryption with Associated Data (AEAD)?\n",
    " \n",
    ">This is an extension of authenticated encryption, that comes up very often in networking protocols. So the idea between AEAD is that, in fact, the message that's provided to the encryption mode is not intended to be fully encrypted. Only part of the message is intended to be encrypted, but all of the message is intended to be authenticated. \n",
    "\n",
    "To get more clarity on AEAD, let's understand it with an example:\n",
    "\n",
    "A good example of this is a network packet. Think of a IP packet where there's a header and then there's a payload. And typically the header is not gonna be encrypted. For example, the header might contain the destination of the packet, but then the header had better not be encrypted otherwise routers along the way wouldn't know where to route the packet. And so, typically the header is sent in the clear, but the payload, of course, is always encrypted.\n",
    "\n",
    "But what you'd like to do is have the header be authenticated. Not encrypted but authenticated. So this is exactly what these AEAD modes do. They will authenticate the header and then encrypt the payload. But the header and the payload are bound together in the authentication so they can't actually be separated. So this is not difficult to do. What happens is in these three modes GCM, CCM, and EAX, basically the MAC is applied to the entire data. But the encryption is only applied to the part of the data that needs to be encrypted.\n",
    "\n",
    "An example API for Authenticated Encryption Standard (GCM):\n",
    "![](./Images/AE-ExampleAPI.png)\n",
    "<br>\n",
    "\n",
    "----\n",
    "<br>\n",
    "\n",
    "**Detour: Rewinding and Clarifying an obscure Notion of MAC Security**\n",
    "\n",
    "The obscure notion in the definition of secure MAC:<br>\n",
    "Recall, one of the requirements that followed from our definition of secure MACs meant that given a message-MAC pair on a message m, the attacker cannot produce another tag on the same message m. In other words, even though the attacker already has a tag for the message m, he shouldn't be able to produce a new tag for the same message m. And it's really not clear, why does that matter? Who cares, if the adversary already has a tag on the message m, who cares if he can produce another tag? \n",
    "\n",
    "Well, it turns out if the MAC didn't have this property. In other words, **given a message-tag pair you can produce another MAC on the same message, then that MAC would result in an insecure Encrypt-then-MAC mode**. And so if we want our encrypt-then-MAC to have cipher text integrity, it's crucial that our MAC security would imply this strong notion of security, which, of course, it does because we defined it correctly.\n",
    "\n",
    "![](./Images/MACSecurity-Explanation.png)\n",
    "\n",
    "So let's see what would go wrong, if, in fact, it was easy to produce this type of tag forgery: \n",
    "- The adversary's gonnna start by sending two messages, $m_{0}$ and $m_{1}$ . And he's gonna receive, as usual, the encryption of one of them, either the encryption of $m_{0}$  or the encryption of $m_{1}$ . <br><br>\n",
    "- Since we're using Encrypt-then-MAC, the adversary receives the cipher text we'll call it $c_{0}$  and a MAC on the cipher text $c_{0}$ . Well now we said that given the MAC on a message the adversary can produce another MAC on the same message. So what he's gonna do is he's gonna produce another MAC(tag) on the message $c_{0}$ . Now he has a new cipher text c' = ($c_{0}$ ,T'), which is a perfectly valid cipher text because T' is a valid MAC of $c_{0}$ . Therefore, the adversary now can submit a chosen cipher text query on c' and this is a valid chosen cipher text query because it's different from c. It's a new cipher text.<br><br> \n",
    "- The poor challenger now is forced to decrypt this cipher text c', so he's going to send back the decryption of c'. It's a valid cipher text therefore the decryption of c' is the message $m_{b}$  but now the attacker just learned the value of b because he can test whether $m_{b}$  is equal to $m_{0}$  or to $m_{1}$ . <br><br>\n",
    "- As a result he can just output the correct b and he gets advantage 1 in defeating the scheme. \n",
    "\n",
    "Therefore, if our MAC security did not imply this, unforgeable tag property here, then there would be a Chosen Ciphertext Attack on Encrypt-then-MAC. And therefore, it would not be secure. So the fact that we define MAC security correctly means that encrypt-then-MAC really does provide authenticated encryption. And throughout all the MACs that we discussed actually do satisfy this strong notion of unforgeability. \n",
    "<br>\n",
    "\n",
    "----\n",
    "\n",
    "### A direct Authenticated Encryption construction from PRP: OCB\n",
    "\n",
    "**Prior to formalization of Authenticate Encryption:**<br>\n",
    "Before the concept of authenticated encryption was introduced everyone was just combining MACs and encryption in various ways in the hope of achieving some authenticated encryption. \n",
    "\n",
    "**Post Authenticated Encryption formalization:**\n",
    "\n",
    "After the notion of authenticated encryption became formalized and rigorous, people kind of started scratching their heads and said, hey, wait a minute, maybe we can achieve authenticated encryption more efficiently than by combining a MAC and an encryption scheme. \n",
    "\n",
    "In fact, if you think about how this combination of MAC and encryption works, let's say we combine counter mode with CMAC, then for every block of plaintext, you first of all have to use your block cipher for counter mode, and then you have to use to your block cipher again, for the CBC-MAC. **This means that if you're combining CPA secure encryption with a MAC, for every block of plaintext, you have to evaluate your block cipher twice, once for the MAC and once for the encryption scheme**. \n",
    "\n",
    "So the natural question was, can we construct an authenticated encryption scheme directly from a PRP, such that we would have to only evaluate the PRP once per block? <br>\n",
    "And it turns out the answer is yes, and there's this beautiful construction called **OCB**, that pretty much does everything you want, and is much faster than constructions that are separately built from an encryption and a MAC. \n",
    "\n",
    "![](./Images/AE-OCB.png)\n",
    "High Level Explanation:<br>\n",
    "- Here we have our input plain text, at the top. Notice that, first of all, OCB is parallelizable, completely parallelizable. So every block can be encrypted separately of every other block. <br><br>\n",
    "- The other thing to notice is that, you only evaluate your block cipher once per plain text block. And then you evaluate it one more time at the end to build your authentication tag and then the overhead of OCB beyond just a block cipher is minimal.<br><br>\n",
    "- All you have to do is evaluate a certain very simple function P. The nonce goes into the P you notice, the key goes into this P and then there is a block counter that goes into this P. So you just evaluate this function P, twice for every block and you XOR the result before and after encryption using the block cipher and that's it. That's all you have to do and then you get a very fast and efficient authenticated encryption scheme built from a block cipher. \n",
    "\n",
    "Why OCB isn't used?<br>\n",
    "So, if OCB is so much better than everything you've seen so far, all these three standards CCM, GCM and EAX why isn't OCB being used or why isn't OCB the standard? And the answer is a little sad. The primary answer that OCB is not being used is actually because of various patents. \n",
    "\n",
    "**Performance Analysis of various AE Constructions**\n",
    "\n",
    "![](./Images/AE-ConstructionsPerformance.png)\n",
    "Note: The one's that are written with light gray shade, should never ever be used, as they don't provide CCA Security or security against an active attacker.\n",
    "\n",
    "- GCM basically uses a very fast hash. And then it uses counter mode for actual encryption. And you can see that the overhead of GCM over counter mode is relatively small.\n",
    "- CCM and EAX both use a block cipher based encryption and a block cipher based MAC. And as a result they're about twice as slow as counter modes.\n",
    "- OCB is actually the fastest of these, primarily because it only use the block cipher once per message block.\n",
    "\n",
    "**Finally, which AE construction should preferably be used?**<br>\n",
    "Based on these performance numbers, you would think that GCM is exactly the right mode to always use. But it turns out if you're on the space constrained hardware, GCM is not ideal. Primarily because its implementation requires larger code than the other two modes. However, Intel specifically added instructions to speed up GCM mode. And as a result, implementing GCM on an Intel architecture takes very little code. But on other hardware platforms, say in smart cards or other constrained environments, the code size for implementing GCM would be considerably larger than for the other two modes. But if code size is not a constraint then GCM is the right mode to use. \n",
    "\n",
    "Authenticated Encryption in Real World: [Case Study: Transport Layer Security 1.2](https://www.coursera.org/learn/crypto/lecture/WZUsh/case-study-tls-1-2)<br>\n",
    "A case study for understanding how Transport Layer Security (TLS) implemented Authenticated Encryption.\n",
    "\n",
    "Attacks on Authenticated Encryption: \n",
    "- [CBC Padding Attacks](https://www.coursera.org/learn/crypto/lecture/8s23o/cbc-padding-attacks)<br>\n",
    "Overview: In this we looked at a Padding Oracle attack that completely breaks an authenticated encryption system. This attack convinces us that we shouldn't implement authenticated encryption on our own cause you might end up exposing yourself to a padding oracle attack or a timing attack or any other such attack. Instead you should be using standards like GCM or any other of the standardized authenticated encryption modes as implemented in many crypto libraries. \n",
    "- [Attack on Non-Atomic Decryption](https://www.coursera.org/learn/crypto/lecture/mtJS8/attacking-non-atomic-decryption)<br>\n",
    "Overview:It displays an attack on AE scheme where decryption operation is non-atomic. In other words, the decryption algorithm doesn't take a whole packet as input, and respond with a whole plain text as output, or with the word reject. Instead, the decryption algorithm partially decrypts the cipher text, namely to obtain the length field, and then it waits to recover as many bytes as needed and then it completes the decryption process. So these nonatomic decryption operations are fairly dangerous, and generally, they should be avoided.\n",
    "\n",
    "Bottom Line: \n",
    "> When you want to encrypt messages you have to use an authenticated encryption mode and the recommended way to do it is to use one of the standards, namely one of these three modes for providing authenticated encryption. **Don't implement the encryption scheme yourself. In other words don't implement Encrypt-then-MAC yourself. Just use one of these three standards(GCM, CCM, EAX). Many crypto libraries now provide standard API's for these three modes and these are the one's you should be using and nothing else**.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Odds and Ends\n",
    "We're almost done with our learning of symmetric encryption. There are just a couple of odds and ends(miscellaneous articles) that we must discuss before we move on to the asymmetric encryption.\n",
    "\n",
    "#### Odds and Ends 1: How to derive keys\n",
    "\n",
    "How we derive many keys from one key? Actually, this comes up all the time in practice, so we need to make sure we know how to do this correctly. So what's the setting that we're looking at? <br>\n",
    "Well, imagine we have a certain source key that's generated by one of, a number of methods. Imagine the source key is generated by a hardware random number generator or perhaps is generated by a key exchange protocol which we're going to discuss later. But anyhow, there are a number of ways in which a source key might be generated between Alice and Bob, such that the attacker doesn't know what the source key is. \n",
    "\n",
    "![](./Images/DerivingManyKfrom1.png)\n",
    "\n",
    "But now, in many cases, we actually need many keys to secure a session, not just one single source key. For example, if you remember, in TLS there were unidirectional keys and we needed keys in each direction. And in fact, in each direction, we needed multiple keys. We needed a MAC key, we needed an encryption key. We need an IV, and so on. Similarly nonce based encryption, there were multiple keys that were being used, and so on. And so, the question is, how do we use the one source key that we just derived, either from a hardware process or by key exchange, and generate a bunch of keys from it that we could then use to secure our session?\n",
    "\n",
    "The way that's done, is using a mechanism called a **Key Derivation Function, KDF**. Lets explore how KDF's are constructed. We will look at KDF constructions under 2 different context, when:\n",
    "1. Source Key, SK, is uniform.\n",
    "2. Source Key is not uniform.\n",
    "\n",
    "**KDF construction when SK is Uniform**\n",
    "![](./Images/KDF-UniformSK.png)\n",
    "Flow of Generation:\n",
    "- Suppose we have a secure PRF, that happens to have key space K and that it so happens that our source key SK is uniform in the key K. In this case, the source key is, in fact, a uniform random key for the secure PRF F. And we can use it directly to generate keys, all the keys that we need to secure the session. \n",
    "- So given such a case, the KDF is really simple. The key derivation function would just work as follows:\n",
    "    - It would take as input the source key. \n",
    "    - It would take an input, a parameter referred to as context.\n",
    "    - Also it's gonna take a length input. \n",
    "    - And then what it will do is it will basically evaluate the PRF on zero. Then it will evaluate the PRF on one. Then it will evaluate the PRF on two, up to L. \n",
    "    - Then, basically, you would use as many bits of the output as you would need to generate all the keys for the session. So, if you need unidirectional keys you would generate, one key in each direction where each key might include an encryption key and a MAC key. And so, you would basically generate as many bits as you need and then finally cut off the output at the time when you've generated enough keys to secure your session. \n",
    "    \n",
    "So this is a fairly straight forward mechanism it's basically using the secure PRF as a pseudo random generator.\n",
    "\n",
    "Why that CTX(context) input variable, what is its purpose?<br>\n",
    "The context string is basically a unique string that identifies the application. So in fact you might have multiple applications on the same system that's trying to establish multiple secure keys. Maybe you have SSH running as one process, you have a web server running as another process, IPsec as a third process and all three need to have secret keys generated. And this context variable basically tries to separate the three of them.\n",
    "\n",
    "Note: The context string is actually important, and it does need to be specific to the application, so that each application gets its own distinct session keys, even if multiple applications happen to sample the same SK.\n",
    "\n",
    "\n",
    "**KDF construction when SK isn't Uniform**\n",
    "\n",
    "If the source key is not a uniform key for the pseudo random function then we can no longer assume that the output of the pseudo random function is indistinguishable from random. In fact, if we just use the KDF that we just described then the output might not look random to the adversary and then he might be able to anticipate some of the session keys that we'll be using and thereby break the session. So then we have a problem. Now why would this source key not be uniform?\n",
    "\n",
    "![](./Images/NonUniformSK.png)\n",
    "\n",
    "Well there are many reasons why source key isn't uniform. For example:\n",
    "- If you use a key exchange protocol, it so happens typically that key exchange protocols will generate a high entropy key. But the high entropy key is gonna be distributed in some subspace of the key space. So it's not going to be a uniform string. It will be uniform in some subset of a larger set, And we'll see examples of that as soon as we talk about key exchange protocols. And so KDFs have to kind of accommodate for the fact that key exchange protocols actually don't generate uniform bit strings.\n",
    "- The other problem is, that, in fact, the hardware random number generator you're using might actually produce biased outputs. We don't wanna rely on the non bias of the hardware random number generator. And so all we want to assume is that it generates a high entropy string, but one that might be biased. In which case, we have to somehow clean this bias.\n",
    "\n",
    "And so this introduces the **Extract then Expand paradigm for building KDFs**. Under extract-then-expand paradigm, the first step of the KDF is to extract a pseudo random key from the actual source key.\n",
    "\n",
    "![](./Images/ExtractThenExpand.png)\n",
    "\n",
    "- So in the graph above you can think about it like this. There is the horizontal axis, representing different values of SK and the vertical axis is basically the probability of each one of these values, and you can see that this is a kind of a bumpy function which would say that the source key is not uniformly distributed in the key space. \n",
    "- What we do in this case is we use what's called an extractor. So an **extractor is something that takes a bumpy distribution and makes it into a uniform distribution over the key space**. In our case we're actually just gonna be using what are called **computational extractors, namely extractors that don't necessarily produce uniform distribution at the end but they generated distribution that's indistinguishable from uniform**. \n",
    "\n",
    "Hence, we first Extract(pseudo-random key) and then Expand(expand the pseudo-random key).\n",
    "\n",
    "The Story of **Salt**:<br>\n",
    "Extractors typically take as input something called a salt, and a salt just like in a salad, it kind of adds flavor to things, what it does is basically kind of jumbles things around, so that no matter what the input distribution is, the output distribution is still going to be indistinguishable from random.\n",
    "\n",
    "So a salt basically, what is it? It's a non-secret string, so it's publicly known. It doesn't matter if the adversary knows what the salt is, and it's fixed forever. The only point is that when you chose it, you chose one at random. And then the hope is that the funny distribution that you're trying to extract from kinda doesn't inherently depends on the salt that you chose and hence as a result using your salt, you will actually get a distribution that looks indistinguishable from random. In some sense the salt is only there to **defend against adversarially bad distributions that might mess up our extractor**.\n",
    "\n",
    "Holistic View:\n",
    "> Given a uniform SK, which is rare, we can directly construct a KDF, using a pseudo-random function. And if the SK isn't uniform, which happens to be commonplace, we can first, using a computational extractor, extract a pseudo-random key from a, converted, uniform distribution and then once we have a pseudo-random key we already know how to expand it into as many keys as we need using a pseudo-random function. Therefore, Extracting and then Expanding.\n",
    "\n",
    "**HDKF**<br>\n",
    "So the standardized way of doing this is called **HKDF. This is a KDF, a key derivation function, that's built from HMAC**. And here HMAC is used both as the PRF for expanding and an extractor for extracting the initial pseudo-random key.\n",
    "![](./Images/HKDF.png)\n",
    "\n",
    "How HDKF works:\n",
    "- So in the extract step, we're gonna use our salt which is a public value just happened to be generated at random at the beginning of time. \n",
    "- And we use this salt as the HMAC key and the source key we're gonna use as the HMAC data. \n",
    "- So we're kind of using a public value as a key. And nevertheless, one can argue that HMAC has extraction properties, such that, when we apply HMAC, the resulting key is going to look indistinguishable from random, assuming that the source key actually has enough entropy to it. \n",
    "- And now that we have the pseudo random key we're simply going to use HMAC as a PRF to generate a session key of you know as many bits as we need for the session keys.\n",
    "\n",
    "Remember:<br>\n",
    "Once you obtain a source key SK, either from hardware or from a key exchange protocol, the way you convert it into session keys is not by using that sample directly. You would never ever use a source key directly as a session key in a protocol. What you would do is you will run the source key through a KDF. And the KDF would give you all the keys and output that you need, for the random keys to be used in your protocol. And a typical KDF to use is HKDF, which is actually getting quite a bit of traction out there. \n",
    "\n",
    "**Password-Based KDF(PBKDF)**\n",
    "\n",
    "A very common question is how do you extract keys from passwords? The problem here is that passwords have relatively low entropy estimated on the order of twenty bits of entropy, say. And as a result, there is simply not enough entropy to generate session keys out of a password. And yet we still need to do it very frequently. We still need to derive encryption keys and MACs and so on out of passwords, so the question is how to do it? \n",
    "\n",
    "Attack Warning: The first thing is, for this kind of purpose, don't use HKDF. That's not what it's designed for. What will happen is that the derived keys will actually be vulnerable to something called a dictionary attack, which we're gonna talk about much later when we see user authentication.\n",
    "\n",
    "![](./Images/PBKDF.png)\n",
    "\n",
    "Solution to extracting keys from passwords is: Password-Based KDF.  So, the way PBKDFs defend against this low entropy problem that results in a dictionary attack is by two means:\n",
    "- First of all, as before they use a salt, a public, random value that's fixed forever. But in addition, they also use what's called a slow hash function. And the standard approach to deriving keys from passwords is called PKCS#5, and in particular, the version we'll describe is what's called PBKDF1. And this mechanism is implemented in most crypto libraries so you shouldn't have to implement this yourself. <br><br>\n",
    "- All you would do is you would call a function. You would give the password in as input, and you would get a key as output.<br><br> \n",
    "- But you should be aware of course that this key is not going to have high entropy so in fact it will be guessable. What these PBKDFs try to do is make the guessing problem as hard as possible. So the way they do this is: <br><br>\n",
    "     - Firstly, they basically hash the concatenation of the password and the salt. And the hash itself is designed to be a very slow hash function. And the way we build a slow hash function is by taking one particular hash function, say, SHA-256, and we iterate it many, many times, c times. So you can imagine perhaps even a million times. <br><br>\n",
    "     - And what do I mean by iterating it? So, well, we take the password and the salt. And we put them inside as input to the hash function. And then we apply the hash function and we get an output, and then we apply the hash function again on the output and we get another output. And we do this again and again and again maybe a thousand times or a million times depending on how fast your processors are and then finally we get the final output that we actually output as the key output of this KDF.\n",
    "     \n",
    "What is the point of Iterating?\n",
    "\n",
    "Iterating a hash function 10,000 times or even a million times is going to take very little time on a modern CPU, and as a result, it doesn't really affect the user's experience. And maybe that could even take a tenth of a second and the user wouldn't even notice it. However for the attacker, all he can do is he can try all the passwords in the dictionary, because we know people tend to pick passwords in dictionaries, and so he could just try them one by one, remember the SALT is public, so he knows what the SALT is. And so he can just try this hash one by one. However because the hash function is slow, each attempt is gonna take him a tenth of second. So if he needs to run through a dictionary, with a 200 billion passwords in it, because the hash function is slow, this is gonna take quite a while. And by doing that, we slow down the dictionary attack, and we make it harder for the attacker to get our session keys. Not impossible, just harder.\n",
    "\n",
    "TLDR: \n",
    ">Use PBKDF for deriving keys from passwords. Because the passwords have low entropy hence keys derived from it are guessable and to counter it, PBKDF primarily uses slow hash functions which makes the dictionary attack harder.\n",
    "\n",
    "----\n",
    "\n",
    "#### Odds and Ends 2: Deterministic Encryption\n",
    "\n",
    "Corresponding Watch: [Deterministic Encryption](https://www.coursera.org/learn/crypto/lecture/8oHZd/deterministic-encryption)\n",
    "\n",
    "All this long we've been evading deterministic mechanisms and sticking with randomized(pseudo-random) mechanisms. So why do we ever need a deterministic encryption scheme?\n",
    "\n",
    "![](./Images/Need4DetEncryp.png)\n",
    "\n",
    "Deterministic Encryption is just a consistence encryption scheme that will always output the same cipher text given a particular message.<br>\n",
    "So let's see where this comes up in practice and in particular the case of look-ups into an encrypted database:\n",
    "\n",
    "Assume the settings are as follows: we have a server that is going to store information inside of an encrypted database. We'll be storing records into the encrypted database with each record having an index field and a data field. The first thing that server is gonna do is, it's going to encrypt the record (where index is encrypted with key $k_{1}$ and data with  key $k_{2}$) and send this encrypted record for storage on the database.\n",
    "\n",
    "Now, if encryption is deterministic, the nice thing about that is that, at a later time, when the server wants to retrieve a record from the database, all he needs to do is send to the database an encryption of the index that the server is interested in. So here, it would send an encryption of the index, Alice. That again, becomes encrypted, and the resulting cipher text is identical to the cipher text that was generated when the record was first written to the database. And the database can then, find the record that has this encrypted index in it, and then send the result back to the server. The nice thing about this is that now the database is completely in the dark as to what data is stored in the database and it doesn't even know what records are being retrieved by the server since all it sees are basically requests for encrypted entities.\n",
    "\n",
    "**The Problem with Deterministic Encryption**\n",
    "\n",
    "The problem is that an attacker can look at different cipher text and if he sees the same cipher text twice he knows that the underlying encrypted messages must also be the same. So in other words, by looking at cipher text, he can learn something about the corresponding plain text, therefore making deterministic encryption CPA-insecure, because every time he sees the same cipher text twice, he knows that the underlying messages are equal. In practice, this leads to significant attacks, and particularly when the message space is small.\n",
    "\n",
    "![](./Images/DetEnc-Prob.png)\n",
    "The CPA-security game:\n",
    "- The game starts by the adversary sending two messages, $m_{0}$ and $m_{0}$. Remember that, in this game, the adversary is always going to be given the encryption of the left message or the encryption of the right message. In this case, since he used the same message in both cases, both on the left and on the right, he's simply gonna get the encryption of the message $m_{0}$.<br><br>\n",
    "- In the next step, he's gonna send the messages $m_{0}$, $m_{1}$. And now he's either gonna get the encryption of $m_{0}$, or the encryption of $m_{1}$. And his goal is to tell which one he got. But because the encryption is deterministic, this is very easy for him to do. <br><br>\n",
    "    - All he has to do is just test whether c is equal to $c_{0}$. And if c is equal to $c_{0}$, then he knows that he got the encryption of $m_{0}$. \n",
    "    - If c is not equal to $c_{0}$, he knows that he got the encryption of $m_{1}$. So he can output zero. If c is equal to $c_{0}$ and output one, if c is not equal to $c_{0}$ and his advantage in this in this particular game would be one, which means that he attacker completely defeats chosen plain text security. \n",
    " \n",
    "The Question: what do we do? <br>\n",
    "Solution: Restrict the type of messages that can be encrypted under a single key. So, the idea is to say that suppose the encryptor never ever, ever encrypts the same message twice under a single/same key. In other words the message key pair is always different and never repeats. So that for every single encryption, either the message changes, or the key changes, but, or both change. But it can't be that we encrypt the same message twice under the same key.\n",
    "\n",
    "Keeping the Solution in context, we can define what can be referred to as **Deterministic CPA security**.\n",
    "\n",
    "![](./Images/DetCPASecure.png)\n",
    "\n",
    "The Deterministic CPA-security game:\n",
    "\n",
    "- The attacker issues queries, so you can see these queries consist of pairs of messages, $m_{0}$ and $m_{1}$. They, as usual they have to be the same length and for each query the attacker either gets the encryption of $m_{0}$ or the encryption of $m_{1}$ and the attacker can do this again and again. He can do this Q times, and at the end of the game he's supposed to say whether he got the encryptions of the left messages or the encryptions of the right messages. \n",
    "- So that is the standard chosen plain text attack game, but now there's one extra caveat. Which is to say that, when the bit b is equal to zero,i.e. we are in EXP(0) then the attacker always sees the encryption of the left messages but with the restriction that the left messages must all be distinct. In other words, he will never get to see the encryption of the same message twice, because these left messages must always be distinct. \n",
    "- Similarly, we require that all the right messages are also distinct. And so that, again, if b happens to be equal to one, i.e. we are in EXP(1), the attacker will never see two messages encrypted under the same key.\n",
    "\n",
    "So this requirement that all these messages are distinct, basically captures this use case that the encryptor will never encrypt the same message multiple times using one particular key. And as a result, the attacker simply can't ask for, the encryption of the same message multiple times using the same key as he did in the previous CPA-security game (where attacker asked for encryption of $m_{0}$ twice while the bit b was 0 (indicating EXP(0)). Therefore, **with just this extra caveat, that messages under a same key must be distinct (encryptor won't encrypt same message multiple times under one key), we can make ciphers that are semantically secure under this Determinstic-CPA Security**.\n",
    "\n",
    "A Common Mistake:<br>\n",
    "This a common mistake that's used in practice. There are many products that should be using a cipher that's deterministic CPA secure, but instead, they just use CBC with a fixed IV and assume that's a secure mechanism. Therefore, you should remember that:\n",
    "- CBC with fixed IV isn' Determinitic-CPA Secure.\n",
    "- Counter mode with fixed IV isn't Deterministic-CPA Secure.\n",
    "\n",
    "(For Explanation: Tune in to Corresponding watch at 9:45)\n",
    "\n",
    "Therefore, you should never use these two for Deterministic Encryption, as it can lead to significant attacks in practice. Then which constructions should be used?\n",
    "\n",
    "**Deterministic Encryption Constructions**<br>\n",
    "Corresponding Watch: [Deterministic Encryption Constructions](https://www.coursera.org/learn/crypto/lecture/hM7f2/deterministic-encryption-siv-and-wide-prp)\n",
    "\n",
    "An Overview of Deterministic Encryption:\n",
    "![](./Images/DetEnc-Overview.png)\n",
    "\n",
    "There are these two prominent constructions that are used to provide Deterministic-CPA Secure Encryption:\n",
    "\n",
    "**Construction 1: Synthetic IV (SIV)**\n",
    "\n",
    "Setting: <br>\n",
    "We have a general CPA secure encryption system that takes as inputs a key, a message and we are gonna denote by r, explicitly, the randomness that's used by the encryption algorithm. Remember that a CPA secure system that doesn't use nonce has to be randomized and so we're explicitly gonna write down this variable r to denote the random string that's used by the encryption algorithm as it's doing the encryption. For example if we're using randomized counter mode, r would be the random IV that's used by randomized counter mode. And of course c is the resulting ciphertext. \n",
    "\n",
    "In addition, we're also going to need a pseudo random function, f, what it does is it takes our arbitrary messages in the message space and outputs a string, r, that can be used as randomness for the CPA secure encryption scheme. So, the little, r, over there, in the CPA secure Encryption, is actually a member of the big R set. \n",
    "\n",
    "![](./Images/SIV.png)\n",
    "Working:\n",
    "- It's going to use two keys k1 and k2 to encrypt the message m.\n",
    "- The first thing is to apply the pseudo random function f to the message m to derive randomness, r, for the CPA secure encryption scheme E. <br>Note: **Since this construction is used, typically, with rand Counter mode as the CPA secure encryption scheme, therefore this derived r acts as the IV in Counter mode and hence the name Synthetic IV** (that's my perception).\n",
    "- Then it's going to encrypt the message m using the randomness that it just derived. This is going to give us a cipher text c. \n",
    "\n",
    "How SIV is deterministic?\n",
    "\n",
    "SIV basically works by first deriving the randomness from the message being encrypted, and then it uses this derived randomness to actually encrypt the message to obtain the cipher text. The point here is to make sure that the encryption scheme is deterministic, so if we encrypt the same message multiple times, every time we should obtain the same cipher text. And indeed every time, we'll obtain the same randomness, r, and as a result, every time we'll obtain the same cipher text c. \n",
    "\n",
    "How SIV is Semantically Secure under Deterministic CPA?\n",
    "\n",
    "It's fairly easy to show that this encryption scheme really is semantically secure under the deterministic chosen plaintext attack. The reason that's so is because we apply the pseudo random function F to distinct messages, in compliance with the Deterministic CPA Security requirement. Well if we apply F to distinct messages then the random string that F generates is going to look like just truly random strings. A different random string for every message. And as a result the CPA secure encryption scheme E is always applied using truly random strings. And that's exactly the situation where it is CPA secure. So because these r's are just random indistinguishable from brand new strings, the resulting system is in fact gonna be CPA secure. \n",
    "\n",
    "Note:  SIV is actually well suited for messages that are more than one AES block. In fact, for short messages, we're gonna see a slightly different encryption scheme that's actually better suited for these short messages.\n",
    "\n",
    "\n",
    "**Deterministic Authenticated Encryption**<br>\n",
    "\n",
    "The really cool thing about SIV is that, actually, we get cipher text integrity for free. In fact we don't have to use a special Mac if we want to add integrity. In a sense SIV already has a built in integrity mechanism. Therefore, now our goal was to build what's called **Deterministic Authenticated Encryption (DAE) which basically means Deterministic CPA security with Ciphertext Integrity**. Remember Ciphertext Integrity means that the attacker gets to ask for the encryptions of messages of his choice and then he shouldn't be able to produce another cipher text that decrypts to a valid message.\n",
    "![](./Images/SIV-EnsuringCI.png)\n",
    "\n",
    "How SIV automatically gives a cipher text integrity without the need for an embedded MAC or anything else?<br>\n",
    "In particular, we'll look at a special case of SIV when the underlying encryption scheme is randomized Counter Mode. We'll call this **SIV-CTR to denote SIV where we're using Randomized Counter Mode as the CPA-Secure Encryption scheme**.\n",
    "\n",
    "The way SIV-CTR encryption works is:\n",
    "- we take our message, and then we apply a PRF to it. And that derives (hence, synthetic IV) an IV. And then that IV is going to be used to encrypt the message using randomized counter mode.\n",
    "- So in particular, we're gonna use this PRF $F_{CTR}$ for randomized counter mode and essentially evaluate this $F_{CTR}$ at IV, IV + 1 up to IV + L. And, then, we XOR that with the message. And that gives us the final ciphertext.So, this is SIV-CTR.\n",
    "\n",
    "Note: In SIV-CTR randomness r would just be the random IV which would actually be outputted along with the cipher text. So this means that the ciphertext is a little bit longer than the plaintext as it contains the random IV aswell.\n",
    "\n",
    "![](./Images/SIV-DAE.png)\n",
    "Now, let's see how decryption is gonna work:\n",
    "- During decryption we're gonna add one more check, and that's going to provide Ciphertext Integrity. \n",
    "- We take our input ciphertext that contains the IV and the cipher text. Well, the first thing we're going to do is we're going to decrypt the cipher text using the given IV, and that will give us candidate plain text.\n",
    "- Now we're gonna reapply the PRF F from the definition of SIV to this message (with the same key obviously). Now if a message is valid, we should be getting the same IV that was supplied as part of the ciphertext. If we get a different IV, then we know that this message is not a valid message and we simply reject the cipher text. \n",
    "\n",
    "Hence, it's a very simple kinda built in check to make sure that the cipher text is valid, right. We simply check that after decryption if we re-derive the IV we would actually get the correct IV. And if not we reject the message. Therefore, SIV-CTR is an Deterministic Authenticated Encryption scheme.\n",
    "\n",
    "**Construction 2: Deterministic Encryption from PRP**\n",
    "\n",
    "If the messages are very short, they're less than sixteen bytes (say the index values stored in the database happens to be shorter than 16bytes), then there's a better way to do it then SIV, and that's the method that is actually trivial becuase all we're going do is we're gonna use a PRP directly.\n",
    "\n",
    "![](./Images/DEfromPRP.png)\n",
    "Description:<br>\n",
    "Suppose (E, D) is a secure PRP. We can claim that if we use E directly, that already gives us Deterministic CPA security (no Ciphertext Integrity though). So lets see why:\n",
    "- Suppose F is a truly random invertible function from X to X. As we know, a PRP is indistinguishable from a truly random invertible function, so let's pretend that we actually do have a truly random invertible function f. \n",
    "- Now in EXP(0) what the attacker is gonna see, while he submits a bunch of messages (messages on the left), is basically the evaluation of f on the messages on the left that he supplied. Well, in the deterministic CPA game, all these messages are distinct, and so all he's gonna get back are just q distinct random values in X. \n",
    "- Similarly for EXP(1), he gets to see the encryptions of messages on the right. Well, again, all these messages are all distinct so all he gets to see are just q random distinct values in X. \n",
    "- Well these two distributions, in EXP(0) and EXP(1), therefore are identical. Basically, in both cases what he gets to see are just q distinct random values in X. And as a result, he can't distinguish experiment zero from experiment one. And since he can't do this for a truly random function, he also can't do this for the PRP.\n",
    "\n",
    "So that explains, how directly encrypting with a PRP already gives us a Deterministic CPA-Secure mechanism (mechanism that is semantically secure under Deterministic CPA Security).\n",
    "\n",
    "That says that if all we wanna do is encrypt short messages, say, less than sixteen bytes, then all we need to do is to directly encrypt them using AES and the result will, in fact, be deterministic CPA secure. So, if your indices/UserID are less than sixteen bytes directly using AES to encrypt them and storing in the Database is a fine thing to do. \n",
    "\n",
    "Note: PRP-based Deterministic CPA-Secure construction do not provide any integrity on themselves. We'll see how to add integrity in just a while.\n",
    "\n",
    "**EME: Constructing a Wide block PRP**<br>\n",
    "\n",
    "What do we do if we have longer than sixteen byte messages? Well, one option is to use SIV. But what if we actually wanted to use this PRP construction for longer messages. So, Can we construct PRP's that have message spaces that are bigger than just sixteen bytes? \n",
    "\n",
    "And the answer is YES. In the past we constructed PRFs on that had large message spaces from PRFs that had small message spaces. Here, we're going to construct PRPs with large message spaces, called Wide PRPs, from PRPs that have small message spaces. So, here's how we do it. Suppose (E, D) is a secure PRP that operates on N bit blocks. There's a standard mode called EME that actually will construct a PRP that operates on N bit blocks, where N is much, much bigger than little n. This would allow us to do deterministic encryption on much larger messages than just sixteen bytes.\n",
    "\n",
    "![](./Images/EME-WidePRP.png)\n",
    "For Explanation of EME: tune in to [Deterministic Encryption](https://www.coursera.org/learn/crypto/lecture/hM7f2/deterministic-encryption-siv-and-wide-prp) at 12:30.\n",
    "\n",
    "Note: Here, we aren't bother that much about understanding EME mode as it is not a preferable way for deterministically encrypting longer message, for that we use SIV as a well implemented SIV can be upto 2 times faster than the EME mode.\n",
    "\n",
    "**Adding Ciphertext Integrity to PRP-based Deterministic Encryption construction**\n",
    "\n",
    "![](./Images/PRPbasedDAE.png)\n",
    "\n",
    "Basically what we're going to do is, we'll take our message and we're going to append a bunch of zeros to this message and then we're going to apply the PRP and that's it, the output is going to be our ciphertext. Now, when we decrypt, we're going to look at these least significant bits of the resulting plaintext and if they're not equal to zero, we're just going to reject the cipher text. And if they are equal to zero, we're going to output the message as valid. So that's it, that's the whole system, very, very simple. Simply append zeros during encryption, and then check that the zeros are there when you decrypt. And that would give us a PRP-based DAE.\n",
    "\n",
    "Does it really provide DAE?<br>\n",
    "This very simple mechanism actually provides deterministic authenticated encryption, assuming, of course, that you've appended enough zeros. And in particular, if you append n zeros, such that $1/2^{n}$ becomes negligible (as zero has 1/2 probability in set {0, 1}$^1$, so for the set{0, 1}$^n$, having n zeros would have probability of $1/2^{n}$ and therefore as n grows larger the probability becomes negligible). And if so, then, in fact, this direct PRP based encryption, in fact, provides deterministic authenticated encryption. It is fairly simple to prove that by appending zeros we can actually get a PRP-based DAE. \n",
    "\n",
    "Following is the proof:\n",
    "\n",
    "![](./Images/Proof-PRPbasedDAE.png)\n",
    "\n",
    "Description:<br>\n",
    "\n",
    "Well, we already argued that the system is CPA secure, so all we have to argue is that it provides Ciphertext Integrity. So, let's look at the cipher text game:\n",
    "- The adversary is gonna choose let's say a truly random permutation. So a truly random, invertible function, on the input space. In this case the input space is the message space and the n zero bits. <br><br>\n",
    "- Now what does the adversary get to do? Well he gets to submit q messages, and then he receives the encryption of those q messages. Mainly he receives the PRP at his chosen points concatenated with n zeros. Therefore, in case of a random permutation, he simply gets to see, the value of this permutation at q points of his choice, but only concatenated with n zeros.<br><br> \n",
    "- And now what's his goal in the ciphertext integrity game? Well, his goal is to produce some new cipher text that's different from the cipher text that he was given, that's gonna decrypt properly. Well, what does it mean that it decrypts properly? It means that if, when we apply, Pi inverse To the cipher text c, it had better be the case that the n least significant bytes of c are all zeros. <br><br>\n",
    "- Now the question is how likely is that to happen? Well, so let's think about this. So basically we have a truly random permutation and the adversary got to see the value of this permutation as q points. How likely is he to produce a new point that, when inverted, happens to have n zeros as the least significant bits? What we're doing here is basically we're evaluating the permutation Pi inverse at the point c. And since Pi inverse is a random permutation, how likely is it to have its n least significant bits be equal to zero? <br><br>\n",
    "- So it isn't hard to see that the answer is with the probability is at most, $1/2^{n}$ . Because, again, basically, the permutation is gonna output a random element inside of, X times {0, 1}$^n$. And that element is gonna end with n zeros, but basically with the probability $1/2^{n}$.<br><br>\n",
    "- Result, the adversary wins the game with negligible probability because the value, $1/2^{n}$, is going to be negligible given that we use appropriate number of zeros (say 80).\n",
    "\n",
    "Bottom line:\n",
    "\n",
    "We are going to append zeros, say 80, with the message and then send it through PRP to generate ciphertext. So any ciphertext that decrypts to plaintext with 80 zeros at end is considered valid. Therefore, for an adversary to win the Ciphertext Integrity game, he would have to forge a ciphertext that would decrypt correctly into a plainttext which have 80 zeros in the end, in other words, least 80 significant bits must be zeros, and as each bit could be 1 or 0 with 1/2 probability, hence, forging a ciphertext that decrypt into a plaintext with 80 least significant bits being zeros has a probability  $1/2^{80}$, which is negligible. Hence the attacker won't be able to commit an existential forgery which implies Ciphertext Integrity.\n",
    "\n",
    "----\n",
    "\n",
    "#### Odds and Ends 3: Disk and Credit Card Encryption\n",
    "\n",
    "**Tweakable Encryption**<br>\n",
    "Corresponding Watch: [Tweakable Encryption](https://www.coursera.org/learn/crypto/lecture/YpC3s/tweakable-encryption)\n",
    "\n",
    "Tweakable Encryption is yet another form of encryption. We are going to see tweakable encryption using disk encryption as an application and we'll see this encryption is yet another application for deterministic encryption. \n",
    "\n",
    "The Disk Encryption Problem:<br>\n",
    "So the disk encryption problem is that we wanna encrypt sectors on disks. Say each sector is four kilobytes long. And the problem is that there's no space to expand. In other words, if the sector size is four kilobytes, the cipher text size also has to exactly four kilobytes because there's nowhere to write the extra bits if the cipher text was bigger than the plain text. And so our goal is basically to build a non-expansive encryption where the cipher text size is identical, exactly equal to the plain text size. \n",
    "\n",
    "So what does it mean that encryption can't expand?\n",
    ">Well, technically, we're saying basically the message space is equal to the cipher text space, so if the message/plaintext space would be four-kilobyte messages then the ciphertext space would need to be four-kilobyte. In this case, clearly we have to use deterministic encryption, because if encryption was randomized, there would be no place to store the randomness. And similarly, we have no room for integrity because we can't expand a ciphertext and add any integrity bits. So the most we can achieve is deterministic CPA security and that's gonna be our goal. \n",
    "\n",
    "![](./Images/DiskEncryption-Lemma.png)\n",
    "It turns out, there's a really simple lemma which basically says, that if you give me a deterministically CPA secure cipher, where the message space is equal to the cipher text base, so no expansion. Then in fact, the cipher is a PRP. So really all we're saying here is if we want no expansion at all, our only option for encrypting is using a PRP.\n",
    "\n",
    "Following shows how we might encrypt the disk using a PRP:\n",
    "![](./Images/DiskEnc-PRP.png)\n",
    "The standard problem (aka Leakage problem) while encrypting with PRP under the same key:\n",
    "\n",
    "If we encrypted every sector using a PRP under the same key, we could have run into our standard problem with a deterministic encryption, namely if sector one and sector three happen to have the same plain text, then the encrypted sector 1 would be equal to the encrypted sector 3 and the attacker would learn, information being leaked, that the corresponding plain texts are the same. Now this actually is a real problem. For example, if some of your sectors are empty, you know they're all set to zero, then in fact, the crypted sectors would be identical, and as a result, the attacker would know exactly which sectors on your disk are empty and which sectors are not.\n",
    "\n",
    "Solution: Use PRP with different keys for encrypting different sectors:\n",
    "![](./Images/DiskEnc-PRPdiffKeys.png)\n",
    "\n",
    "But even in this case we have a little information leakage:\n",
    "\n",
    "If the user happened to change even a single bit in sector 1. Then that sector gets encrypted into a different ciphertext i.e. even if one bit of the plaint changes, the sector will just be mapped to a completely new random output. However, if the user then undoes the change and reverts back to the original sector (to the original plaintext), then the encrypted sector will revert back to its, previous, original state. And the attacker can tell that a change was made and then reverted, so there is still a little bit of information leakage but that type of information leakage is really nothing we can do without really sacrificing performance so we are just going to ignore that and deem that acceptable. \n",
    "\n",
    "The next problem: How to manage so many keys?\n",
    "\n",
    "Now you realize our discs are actually getting pretty big and there are lots of sectors so this would mean we are generating lots and lots of keys here. But of course we don't have to store all these keys, we can simply generate these keys using a pseudorandom function (PRF). So the way this would work is we would have a master key which we would call k, and then the sector number which we are going to denote by t, and we put them into our PRF and the result of that encryption would be the particular sector key which I'll denote by $k_{t}$ . Now the reason this is secure is again because the PRF is indistinguishable from a random function which means that basically if we apply a random function to the sector numbers one, two, three, four up to L they basically get mapped to completely random elements in the key space and as a result we're encrypting every sector using a new random independent key.\n",
    "\n",
    "So this is a fine construction, however, again, for every sector we would have to apply this PRF. And so the natural question is, can we do even better? And this introduces this concept of a Tweakable Block Cipher.\n",
    "\n",
    "**Tweakable Block Ciphers**<br>\n",
    "In the concept of tweakable block cipher, what we really want, is basically, to have one master key. And with this one master key we want to derive many, many, many PRPs. \n",
    "![](./Images/TweakableBlockCiphers.png)\n",
    "- In a tweakable block cipher the encryption and decryption algorithm basically as usual take the key as input(the master key randomly chosen from key space K, in other words a random variable from K), but with that they take an extra parameter, tweak, as an input. The capital T is what is called the tweak space. \n",
    "- And of course the encryptor and decryptor take the data as input from set X and then produces outputs in the set X. \n",
    "- The property says that for every tweak in the tweak space and a random key, basically if we fix the key and tweak we end up with an invertible function, a one to one function on the space X, and because the key is random the function is in fact indistinguishable from random. In other words, for every setting of the tweak, we basically get an independent PRP from X to X. \n",
    "\n",
    "The application for this is now we're going to use the sector number as the tweak. And as a result, every sector is gonna get its own independent PRP.\n",
    "\n",
    "Lets more precisely define what's a **Secure Tweakable Block Cipher**:\n",
    "![](./Images/SecureTweakableBlockCipher.png)\n",
    "Description:<br>\n",
    "\n",
    "- In a Tweakable Block Cipher there's a key (random variable from key space K), a tweak space T and an input space X. <br><br>\n",
    "- And as usual, we define our two experiments. In EXP(1), what's gonna happen is we're gonna choose a truly random set of permutations, so not just one permutation. We're gonna choose as many permutations as there are tweaks. So you'll notice this is why we raised Perms[X] to the size of of the tweak space |T|. If the size of the tweak space is five, this says that we're choosing five truly random permutations on the set X. <br><br>\n",
    "- In EXP(0), we're just gonna choose a random key and we're gonna define our set of permutations as the ones defined by the tweaks in the tweak space. <br><br>\n",
    "- The adversary basically gets to submit a tweak and an x, and it gets to see the value of the permutation defined by the tweak $t_{1}$, evaluated at the point $x_{1}$. Then he gets to see the value of the permutation defined by the $t_{2}$ and valued it at point $x_{2}$. And so on and so forth. <br><br>\n",
    "- The goal of the adversary is to say whether he interacted with truly random permutations or pseudo-random permutations. And if he can't do it we say that this tweakable block cipher is secure.<br><br> \n",
    "- The difference b/w tweakable and a regular block ciphers is, in a regular block cipher, adversary only get to interact with one permutation and then it goes to tell whether you're interacting pseudo random permutation or truly random permutation. Here the adversary get to interact with T random permutations and again it goes to tell whether the T random permutations are truly random or pseudo random. <br><br>\n",
    "- So as usual, if adversary can't distinguish, if the adversary behaves the same in both experiments, we say that this PRP is a secure, tweakable PRP. \n",
    "\n",
    "There are 2 constructions for a Secure Tweakable Block Cipher:\n",
    "- Trivial Construction\n",
    "- XTS Tweakable Block Cipher\n",
    "\n",
    "Trivial Construction:\n",
    "![](./Images/TrivialTBC.png)\n",
    "\n",
    "In the trivial example, what we do, we're gonna assume that the key space is equal to the input space. So think of AES, for example, where the key space is 128 bits, the data space is 128 bits, and of course, the output is 128 bits. And then the way that we define the tweakable blocks is there's a key, a tweak, and data as input. Basically we encrypt the tweak using our master key and then we encrypt the data using the resulting random key (generated from the encryption of the tweak using the master key). \n",
    "\n",
    "Pitfall: If we wanted to encrypt n blocks with this trivial tweakable block cypher, this would require 2n evaluations of the block cypher, n evaluations to encrypt the given tweaks and then, n more evaluations to encrypt the actual given data. So now the question is can we do better? And the answer is YES, via XTS.\n",
    "\n",
    "**XTS Tweakable Block Cipher**\n",
    "\n",
    "![](./Images/XTS-TBC.png)\n",
    "\n",
    "XTS Setup:\n",
    "- We start off with a regular block cipher that operates on n bit blocks. So not a tweakable block cipher, just a regular block cipher. \n",
    "- Now our XTS tweakable block cipher $E_{tweak}$  is going to take two keys as input and the tweak and we're going to assume this tweak is made up of two values, (t, i) where t is going to be some tweak value (sector number in disk encryption) and i is going to be some index (block number in disk encryption).\n",
    "- X is gonna be an input, n bit string, which we're gonna apply the XTS tweakable block cipher to. \n",
    "\n",
    "XTS Working: \n",
    "- The first thing we're gonna do is we're gonna encrypt the left half of the tweak, namely t, using the key $k_{2}$ and we're gonna call the result N. \n",
    "- Next we XOR the message m (this is the supplied x to XTR) with some padding function, P, applied to this value N that we just derived, at the index i. And this padding function is extremely fast. We can pretty much ignore it in the running time. \n",
    "- The next thing we do is we're gonna encrypt the output from the previous step, using the key $k_{1}$. \n",
    "- And then we're gonna XOR again, using the same padding function. And the result, is gonna be the cypher text which we will denote by c. \n",
    "\n",
    "So again as said, the function p is some very, very simple function, it's just some multiplication in a finite field. So the running time is really dominated by the running time of the block cipher E. And that's it, that's XTS. \n",
    "\n",
    "The Evaluation Advantage of XTS:<br>\n",
    "If we wanted to encrypt n blocks, all we do is we compute the value N once. And then for the indices one, two, three, four, basically we just need to evaluate the PRP E once per block. So we will need to encrypt end blocks using the tweaks t1, t2, t3, t4 and so on. We would just need n+1 evaluations of the block cipher E. So it's twice as fast as the trivial construction. \n",
    "\n",
    "Note: It is really important to encrypt the tweak t and then use the output N in the padding function. If the tweak is used directly in the padding function then the attacker would be able to beat this construction with the advantage 1, i.e., XTS won't remain a secure tweakable block cipher.\n",
    "\n",
    "\n",
    "**Disk Encryption using XTS**\n",
    "\n",
    "![](./Images/DEusingXTS.png)\n",
    "\n",
    "The way XTS is used for disk encryption. What we do is, we look at sector number t and we break it into blocks, 16 bytes blocks. And then block number 1 gets encrypted with a tweak (t,1), block number 2 gets encrypted with a tweak (t,2), and so on and so forth. And so every block gets it's own PRP and the whole sector, as a result, is encrypted using a collection of PRP's.\n",
    "\n",
    "Note: XTR provides block level PRPs, and not sector level PRPs. So, in fact, it's not true that each sector gets encrypted with it's own PRP. It's just each block gets encrypted with it's own PRP and hence each sector gets encrypted by a collection of PRPs. Therefore, XTS mode actually provides the deterministic CPA encryption at the block level, at the sixteen bytes level. And this mode actually is fairly popular in disk encryption products.\n",
    "\n",
    "![](./Images/TweakableEncryption-Summary.png)\n",
    "\n",
    "Note: We looked at the EME construction under the Deterministic Encryption segment, which provided a PRP for much larger blocks. And in fact, EME is a tweakable mode of operation. So if you need PRPs for larger blocks or tweakable PRPs for larger blocks, then you can use EME. But you notice there EME, you have to apply the block size for twice per in per block. And as a result, it's twice as low as XTS and is not very often used. \n",
    "\n",
    "----\n",
    "\n",
    "**Format Preserving Encryption**<br>\n",
    "Corresponding Watch: [Format Preserving Encryption](https://www.coursera.org/learn/crypto/lecture/aFRSZ/format-preserving-encryption)\n",
    "\n",
    "Format-preserving encryption (FPE), refers to encrypting in such a way that the output (the ciphertext) is in the same format as the input (the plaintext). We will be looking at Credit Card Encryption as the motivation for FPE. In Credit Card Encryption we need to encrypt a 16-digit credit card number so that the ciphertext is another 16-digit number (and this is practical requirement, as we'll see).\n",
    "\n",
    "Credit Card Overview:<br>\n",
    "A typical credit card number is sixteen digits, broken into four blocks of four digits each. The first six digits are what's called the BIN number, which represent the issuer ID. For example, all credit cards issued by VISA always start with the digit four; all credit cards issued by MasterCard start with digits 51 to 55, and so on and so forth. The next nine digits are actually the account number that is specific to the particular customer and the last digit is a check sum that's computed from the previous fifteen digits. So there are about 20,000 BIN numbers and so if you do the calculation it turns out there are approx $2^{42}$ possible credit card numbers which corresponds to about 42 bits of information that you need to encode if you want to represent a credit card number compactly. \n",
    "\n",
    "![](./Images/CreditCardEncryption.png)\n",
    "\n",
    "The fundamental Problem with Encrypting Credit Cards:<br>\n",
    "\n",
    "Suppose we wanted to encrypt credit card numbers, so that when the user swipes the credit card number at the point of sale(POS) or the merchant's cash register. So, POS encrypts the credit card number using a key k and it's encrypted all the way until it goes to the acquiring bank or maybe even beyond that, maybe even all the way when it goes to Visa. Now, the problem is that these credit card numbers actually pass through many, many, many processing points. All of them expect to get basically something that looks like a credit card number.\n",
    "\n",
    "So if we simply wanted to encrypt something at at one end point, and decrypt it at the other end point, it's actually not that easy because if all we did was encrypt it using AES, even if we just used deterministic AES, the output of the encrypted credit card number would be 128 bit block. Sixteen bytes that would be, that would need to be sent from one system to the next, until it reaches its destination. But each one of these processors, then, would have to be changed, because they're all expecting to get credit card numbers. And so the question is, can we encrypt at the cash register, such that the resulting encryption itself looks like a credit card number. And as a result, none of these intermediate systems would have to be changed. Only the endpoints would have to be changed. And in doing so we would actually obtain **end-to-end encryption** without actually having to change a lot of software along the way. \n",
    "\n",
    "And the solution to this problem is: Format Preserving Encryption!\n",
    "\n",
    "What precisely, and abstractly, does it mean to have a Format Preserving Encryption in mathematical terms:\n",
    "\n",
    "![](./Images/FPE.png)\n",
    "\n",
    "We basically want to build a pseudo random permutation PRP on the set {0,.,s-1} for any given s. So for the set of credit card numbers, s would be roughly $2^{42}$. And our goal is to build a PRP that acts exactly on the interval, zero to s-1. \n",
    "\n",
    "So, what we're given as input is some PRF, say, something like AES, that acts on much larger blocks (sixteen byte blocks). Therefore we're trying to, in some sense, shrink the domain of the PRF to make it fit the data that we're given. And the question is basically how to do that?\n",
    "\n",
    "Once we have such a construction we can easily use it to encrypt credit card numbers. What we would do is given  a credit card number, we would encode it such that now it's represented as a number between 0 and the total number of credit card numbers. Then we would apply our PRP so we would encrypt this credit card number, using construction number two from the deterministic encryption segment. And then we would map the final number back to be a regular, to look like valid credit card number and then send this along the way. So this is, this is again non expanding encryption. The best we can do, as we said before is to encrypt using a PRP except again the technical challenge is we need a PRP that acts on this particular set from zero to s-1 for this prespecified value s.\n",
    "\n",
    "So we are going to build a Format Preserving Encryption in 2 steps:\n",
    "\n",
    "![](./Images/ShrinkThePRP.png)\n",
    "\n",
    "- The construction that we basically gonna use is called the Luby-Rackoff construction. What we need is a PRF F' that acts on blocks of size t/2. So imagine for example in the credit card case, t would be 42 because, $2^{42}$ as we said is the closest power of 2 that's bigger than s(the total number of credit cards). Therefore we would need a PRF now that acts on 21-bit inputs. \n",
    "\n",
    "- One way to do that is simply to take the AES block cipher, treat it as a PRF on 128-bit inputs, and then simply truncate the output to the least significant 21 bits. Okay, so we were given a 21 bit value. We would append zeros to it so that we get 128 bits as a result. We would apply AES to that and then we would truncate back to 21 bits.\n",
    "\n",
    "- So now, we've converted our AES block cipher into a PRF on t over two bits, say, on 21 bits. But what we really want is a PRP. Therefore, what we'll do is we'll plug our new PRF, F', directly into the Luby-Rackoff construction. If you remember, this is basically a Feistel construction. Luby-Rackoff used three rounds, and we know that this converts a secure PRF into a secure PRP on twice the block size. In other words, we started from a secure PRF on 21 bits, and that will give us, and Luby-Rackoff will give us a secure PRF on 42 bits, which is what we wanted. \n",
    "\n",
    "Note: The error parameters in the Luby-Rackoff construction are not as good as they could be. And, in fact, a better thing to do is to use seven rounds of Feistel. So in other words, we'll do this seven times; every time we'll use a different key. And then there's a nice result, shown by Patarin, that shows that the seven-round construction basically has as good an error terms as possible.\n",
    "\n",
    "But the construction in step 1 is not good enough. We actually want to get a PRP on the set zero to s-1. So step two will take us down from {0,1}$^t$, to the actual set zero to s-1 that we're interested in. \n",
    "![](./Images/Step2Shrink.png)\n",
    "Encryption:\n",
    "- Basically we're given input x in the set {0,.,s-1}. Now going to iterate the following procedure again and again:<br><br>\n",
    "    - So first of all we map x into this temporary variable y i.e we encrypt the input x and put the result into y. \n",
    "    - If y is inside of our target set, we stop and we output y. If not, we iterate this again and again and again and again and again until finally y falls into our target set and then we output that value.\n",
    "<br><br>    \n",
    "- In picture, how this works is: we start from a point in our target set (blue region). And now we apply the, the function E and we might be mapped into this point outside our target set (peach region), so we're not gonna stop. We will keep applying the function E again and again until we map somewhere into the target region again, and then we stop, and that's our output. So that's how we map points between from 0 to s-1, to other points in 0 to s-1.\n",
    "\n",
    "Decryption:\n",
    "-  It should be pretty clear that this is invertible. Therefore, during decryption process (at the other end), all we need to do is decrypt and walk, kind of, in the opposite direction. So we keep on decrypting, until finally, we fall back into the set, 0 to s-1 . And that gives me the inverse of the point that we wanted to. So this is, in fact, a PRP.\n",
    "\n",
    "Note: FPE is indeed a secure PRF (same security as Luby-Rackoff construction) however it doesn't provide any integrity.\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Key Exchange\n",
    "\n",
    "### Basic Key Exchange 1: Problem Statement\n",
    "\n",
    "Now that we know how two users can protect data using a shared secret key, the next question is how did these two users generate a shared secret key to begin with? This question will take us into the world of public key cryptography.\n",
    "\n",
    "#### Trusted 3rd Parties\n",
    "\n",
    "Imagine that there a n users in the world. And the question is, how do these users manage these secret keys that they're gonna use to communicate with one another? \n",
    "\n",
    "![](./Images/KeyManage-Prob.png)\n",
    "For example, let's assume n equals four, i.e., there are four users in the world. One option is that basically every pair of users will share a shared secret key. The problem with this approach is that now there are many, many shared keys that users have to manage. And in particular, every user has to store order of n keys if he's gonna talk to n other parties in this world. So the question is can we do any better than storing n keys per user? And the answer is yes. And one way to do that is what's called an **Online Trusted 3rd party (TTP)**.\n",
    "\n",
    "![](./Images/KeyManageSol-TTP.png)\n",
    "\n",
    "The way we are going to use the trusted third party is every user will now share a single secret key with this trusted third party. And here are Alice and Bob, let's call their secret keys $k_{A}$ and $k_{B}$ that they are going to share with the TTP. Now the nice thing about this design is that now every user only has to remember one secret key. \n",
    "\n",
    "The question is now, what happens when Alice wants to talk to Bob? Somehow the two of them have to engage in a certain protocol, such that at the end of this protocol they will have a shared secret key, say $k_{AB}$, that the attacker wouldn't be able to know. \n",
    "\n",
    "How do Alice and Bob generate this shared secret key $k_{AB}$?\n",
    "![](./Images/GeneratingKeys-ToyProtocol.png)\n",
    "Working of the Protocol:\n",
    "- Alice is going to start by sending a message to the trusted third party saying, hey I want to communicate with Bob and therefore need a secret key that she's going to share with Bob. <br><br>\n",
    "- What the trusted third party will do is it will actually go ahead and choose a random secret key, $k_{AB}$. So the trusted third party is the one who's gonna generate their shared secret key. <br><br>\n",
    "- TTP gonna send one message back to Alice. This message consists of, of two parts:<br><br>\n",
    "    - The first part of the message is an encryption using Alice's secret key $k_{A}$ (TTP has secret keys of its users), of the concatenation of message \"this key is supposed to be used between parties Alice and Bob\" and the secret key $k_{AB}$.<br><br>\n",
    "    - The other part of the message that the TTP sends to Alice is what's called a ticket. And this ticket is basically a message that's encrypted for Bob. So in other words, the ticket is gonna be an encryption under the key $k_{B}$ of, again, the concatenation of message that \"this key is supposed to be used between Alice and Bob\"  and the secret key, $k_{AB}$.<br><br>\n",
    "- So, Alice recieved a message from TTP which basically contains 2 parts (message for Alice and a ticket). Now, when Alice want to initiate a communication with Bob, simply she will decrypt her part of message and get the shared/session key $k_{AB}$. Alice will also send the ticket to Bob which he will decrypt using his secret key and will get the session key $k_{AB}$. Now they can use this key $k_{AB}$ to encrypt their conversation and communicate securely.\n",
    "\n",
    "\n",
    "Note: The encryption system E that is actually being used by the TTP is CPA secure cipher such that it can provide confidentiality. This protocol is only going to be secure against eavesdropping. It's not gonna be secure against more tampering or active attacks. \n",
    "\n",
    "Question: Why is this protocol secure? Even if we only consider eavesdropping adversaries.<br>\n",
    "![](./Images/Security-ToyProtocol.png)\n",
    "\n",
    "What does an eavesdropper see in this protocol? Basically he sees these two cipher texts. He sees the cipher text that's encrypted for Alice. And then he sees the ticket that's encrypted for Bob. And in fact he might see many instances of these messages, in particular if Alice and Bob continuously exchange keys in this way he's gonna see many messages of this type and our goal is to prove that he has no information about the exchanged key $k_{AB}$. So proof follows directly from the CPA security of the cipher (E D) because the eavesdropper can't really distinguish between encryptions of the secret key $k_{AB}$ from encryption of just random junk. That's the definition of CPA security and as a result, he can't distinguish the key $k_{AB}$ from, you know, random junk which means that he learns nothing about $k_{AB}$. \n",
    "\n",
    "Note: TTP is called the Trusted Third Party because, essentially, it knows all the session keys that have been generated in the system. Nevertheless the beauty of this mechanism is that it only uses symmetric key cryptography, nothing beyond what we've already seen and as a result it is very fast and efficient. The only issue is that you have to use this online trusted party and it's not immediately clear if for example we wanted to use this in the world wide web who would function as this online trusted third party. However, in a corporate setting this might actually make sense if you have a single company with a single point of trust it might make sense to actually designate a machine as a trusted third party. A mechanism similar to this is the basis of the Kerberos system.  \n",
    "\n",
    "Pitfalls of this Concept:\n",
    "- TTP is needed for every single key exchange. So, basically Alice and Bob simply cannot do key change unless the TTP is online and available to help them do that. \n",
    "- TTP knows all the session keys. So if somehow the TTP is corrupt, or maybe it's broken into, then an attacker can very easily steal all the secret keys that have been exchanged between every user of this system. \n",
    "\n",
    "Also, because TTP protocol do not provide integrity services therefore it's completely insecure against Active attackers, that is, it's CCA-insecure. A sample attack is shown below.\n",
    "![](./Images/ToyProtocol-CCAInsecure.png)\n",
    "Attacker records all the ciphertexts from Alice in a given session with the merchant Bob. And as there is no integrity mechanism, therefore, when the attacker simply replays the session, in other words sends the recorded ciphertexts from Alice back, the merchant Bob would get fooled into thinking that Alice ordered yet another copy of book.\n",
    "\n",
    "![](./Images/StartPoint-PublicKeyCrypto.png)\n",
    "\n",
    "#### Merkle Puzzles\n",
    "\n",
    "The fundamental question now is: Can we do key exchange without a need of the Trusted Third Party, i.e., the participants of the conversation can somehow be able to exchange keys securely (CPA-secure)?\n",
    "\n",
    "![](./Images/CanKeyEx-Symmetrically.png)\n",
    "So what we want is a protocol such that the participants, Alice and Bob, after sending messages to one another, back and forth somehow end up with having a shared key k that they both know. But an eavesdropper who listens in on this traffic has absolutely no idea what this secret key k is.\n",
    "\n",
    "Note: As of now, we are focusing only on providing confidentiality and not providing integrity.\n",
    "\n",
    "Ques: Can we do such a TTP-independent key exchange and that too using just the symmetric key cryptography?<br>\n",
    "Ans: Yes! By using Merkle Puzzles (however, they are never used in practice because of their inefficiency)\n",
    "\n",
    "![](./Images/MerklePuzzles.png)\n",
    "\n",
    "The main tool for this protocol is what's called a \"puzzle\". A puzzle is a problem that's difficult to solve, but can be solved with some effort. Lets understand it using an example: \n",
    "- Suppose we have a symmetric cipher that uses keys that are 128 bits long, just think of AES, and what we do is we choose an AES key such that the first 96 bits are all 0 and only the remaining 32 bits are non-zero and are just chosen at random. So, only 32 bits of this 128-bit key are random. The rest are all zeros. \n",
    "- What we do now is we encrypt a fixed plaintext, for example, simply the plaintext \"message\" using this 128-bit key that happens to be mostly, 96, zeros. The result is what we call a \"puzzle\". \n",
    "- The reason its called a puzzle is because it's actually not that hard to find the secret key P simply by trying all $2^{32}$ possibilities. As the first 96 bits are all 0, there are only $2^{32}$ possible keys to try. And for each key we'll try to decrypt this puzzle and see if we get the plaintext \"message\". If so, we know that we've recovered the right solution, P. \n",
    "\n",
    "The way Merkle Puzzle protocol works is as follows:\n",
    "![](./Images/MP-Working.png)\n",
    "\n",
    "- Alice is going to start by generating a large number of puzzles. In particular, she's going to generate $2^{32}$ different puzzles. Now each of these puzzles, the way she generates it is as follows: <br><br>\n",
    "\n",
    "    - What' she'll do is she'll choose a 32-bit random puzzle $P_{i}$ , she does this for i = 1 to $2^{32}$ and then she's going to choose two more values, $x_{i}$ and $k_{i}$ that happen to be 128-bits each and corresponds to each $P_{i}$. <br><br>\n",
    "    \n",
    "    - What she'll then do is she'll use the puzzle $P_{i}$ prepended with 98 zeros as an AES secret key, that is, she'll create 128-bit key where 96 of the bits are set to 0. And only the 32 least significant bits happen to be random i.e. $P_{i}$. So this is a key that only has 32bits of entropy, as there are only $2^{32}$. <br><br>\n",
    "    \n",
    "    - Now the plaintext that she'll encrypt using this key is this message which basically starts off with the word \"Puzzle\". That puzzle is identified by the identifier $x_{i}$, which happens to be 128 bits. And to that we concatenate a value $k_{i}$ which also happens to be 128 bits (and would later act as a key). <br><br>\n",
    "    \n",
    "    - So she does this for all $2^{32}$ puzzles, and as a result she gets $2^{32}$ different puzzles. She then goes ahead and sends these $2^{32}$ puzzles to Bob. <br><br>\n",
    "\n",
    "- So what does Bob do? Well Bob receives this flood of $2^{32}$ different puzzles. He's just going to choose one of them. He doesn't even have to remember any of them. He just randomly lets most of them go by. And he happens to choose one of them.<br><br> \n",
    "- Let's say he chose puzzle number \"j\". Then he spends time $2^{32}$ and solves this puzzle. Well what does it mean to solve this puzzle? He's going to try all possible values of $P_{j}$. <br><br>\n",
    "\n",
    "- He's going to decrypt the puzzle that he chose, and he's going to check whether the first part of the plaintext starts with the word puzzle. And if it does, he knows that he's correctly solved that puzzle, and he basically obtains the data embedded in the puzzle namely, $x_{j}$ and $k_{j}$. Notice $x_{j}$ is this value that identifies the puzzle and $k_{j}$ is going to be a secret that they use. <br><br>\n",
    "\n",
    "- So now Bob has solved the puzzle, he knows that he's solved the puzzle correctly and he obtained this $x_{j}$ and $k_{j}$. What he'll do is he'll send $x_{j}$ back to Alice, just the value of $x_{j}$, and $k_{j}$ he keeps for himself, and keeps it a secret. <br><br>\n",
    "\n",
    "- Then Alice is simply going to lookup in her database of puzzles, she's going to lookup puzzle number $x_{j}$, and then she knows Bob has chosen the key $k_{j}$. Therefore, now they have this shared key $k_{j}$.\n",
    "\n",
    "Following depicts the work(time-complexity) that each party has to do under this protocol:\n",
    "![](./Images/MP-Work.png)\n",
    "Alice work/runtime: O(n), where n is the number of puzzles to build, which as mentioned is $2^{32}$. <br>\n",
    "Bob's work/runtime: O(n), where n is the number of possible values of $P_{j}$ (with j being the puzzle number that he chose) which again is $2^{32}$.\n",
    "\n",
    "Eavesdropper's work: O($n^{2}$). Why?<br>\n",
    "The poor eavesdropper sees these n puzzles go by and then he sees this $x_{j}$ come back. And he doesn't really know which puzzle Bob actually solved. All he sees is this random value inside of the puzzle. And so to break this protocol, the eavesdropper would actually have to solve all puzzles until he finds the right puzzle that has the value $x_{j}$ in it, and then he will recover $k_{j}$. Therefore, he had to solve n puzzles where each puzzle takes time n to solve. And as a result he had to spend time order $n^{2}$.\n",
    "\n",
    "Is this protocol secure?<br>\n",
    "It depends, if Alice prepares $2^{32}$ puzzles, with each being solvable in $2^{32}$ time, it would take the adversary time $2^{64}$ to break, which is not considered safe. But if if Alice prepares $2^{64}$ puzzles, with each being solvable in $2^{64}$ time, then it would take the adversary time $2^{128}$ to break, which is indeed safe.\n",
    "\n",
    "Drawback: Having the participants spend time $2^{64}$ to set up a secure session key is a little bit too much to ask. So this is why this protocol is not particularly used in practice. \n",
    "\n",
    "Nevertheless there's a really nice idea here in this protocol that the participants had to spend linear time, whereas the attacker had to spend quadratic time.  So there's a **\"quadratic gap\"** between the amount of work that the participants had to do, versus what the attacker had to do to break the protocol. So a natural question is, \"Can we actually do better than a quadratic gap, just using symmetric ciphers?\" And the answer really is that this is unknown. We don't know whether a quadratic gap is the best that we can do. \n",
    "\n",
    "![](./Images/ImpossibilityResult.png)\n",
    "\n",
    "Roughly speaking, there is a result that says that, in fact, if we treat the block cipher or the hash function that we use as a black box oracle, in other words all the participants can do is just query the block cipher or query the hash function at certain points and receive the results, if that's all they're allowed to do and they're not allowed to actually use the implementation of the cipher, or the hash function and tweak/improve it in some way, then in fact there is a result that says there will always be an attack that runs in time $n^{2}$. \n",
    "\n",
    ">This suggests that if all you do is use the block cipher as a black box that you query, then whatever symmetric key exchange scheme you come up with, there will always be a quadratic attack on this key exchange and we won't we able to get better, say push the attack to be of cubic, $n^{3}$, order (a cubic gap).\n",
    "\n",
    "However, we will see that with other key exchange mechanisms, like Diffie-Hellman, we would be able to achieve a much efficient exponential gap.\n",
    "\n",
    "Random Oracle [Terminology]: In Cryptography, a random oracle is an oracle (a theoretical black box) that responds to every unique query with a (truly) random response chosen uniformly from its output domain. If a query is repeated it responds the same way every time that query is submitted.\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Key Exchange 2: Two Solutions\n",
    "\n",
    "#### The Diffie-Hellman Protocol\n",
    "\n",
    "Previously: We looked at a key exchange protocol called Merkle puzzles. That's just using block ciphers or hash functions. And we showed that basically the attacker has a quadratic gap compared to the participants. In other words if the participants spent time proportional to n the attacker can break the protocol in time proportional to $n^{2}$. And as a result that protocol is to insecure to be considered practical.\n",
    "\n",
    "But can we do better? Yes! <br> \n",
    "We have to use hard problems that have more structure than just those symmetric primitives. And so instead what we're gonna do is use a little bit of algebra. With the Diffie-Hellman key exchange protocol we would be able to achieve an **exponential gap**, which effectively means that if the participants spend say a time proportional to n then the attacker would only be able to break the protocol in time proportional to $2^{n}$.\n",
    "\n",
    "Note: In this segment we are gonna describe the Diffie-Hellman protocol very concretely and somewhat informally. We're going to come back to Diffie-Hellman later and then we're going to describe the protocol more abstractly and we're going do a much more rigorous security analysis of this protocol. \n",
    "\n",
    "![](./Images/DH-ProtocolInformal.png)\n",
    "The way Diffie-Hellman Protocol works:\n",
    "\n",
    "- First of all, we're gonna fix some really large prime p. Primes that are made up of 600 digits or so. And just for those who like to think in binary, a 600 digit prime roughly corresponds to about 2000 bits. So just writing down the prime takes about two Kb of data.<br><br>\n",
    "\n",
    "- Then we're also gonna fix an integer g that happens to live in the range {1,..,p}. So, these values p and g are parameters of the Diffie-Hellman protocol. They are chosen once and they're fixed forever. <br><br>\n",
    "\n",
    "-  Alice is gonna starts off by choosing some random number a in the range {1,...,p-1}. Then she is gonna compute the number $g^{a}$ modulo p. So she computes this exponention $g^{a}$, and reduces the result via modularing with the prime p. Let's call the result of this value as A. Alice will send this A over to Bob.<br> (And we're actually going to see how to compute this efficiently later, so for now just believe that this computation can be done efficiently) <br><br>\n",
    " \n",
    "- Now Bob is going to do the same thing. He's going to choose a random number b in the range {1,...,p-1}. He's then going to compute $g^{b}$ modulo p and let's call this number B and he's going to send this number B over to Alice. <br><br>\n",
    "\n",
    "- So Alice sends A to Bob. Bob sends B To Alice. And now they claim that they can generate a shared secret key $k_{AB}$. So what would be the shared secret key? Well, it's defined as the value $g^{ab}$ (mod p). \n",
    "\n",
    "How both of them would compute the shared key $k_{AB}$?:\n",
    "- Alice can compute this value because she can take her value B that she received from Bob and raise it to the power of a, $B^{a}$, and what she'll get is $(g^{b})^{a}$. And by the rules of exponentiation, $(g^{b})^{a}$ is equal to  $g^{ab}$.\n",
    "\n",
    "- It turns out that Bob can do something similar, what he does is he takes the value A that he received from Alice and he raises it to his own secret key b and compute $(g^{a})^{b}$, which again, $g^{ab}$, therefore both Alice and Bob will have computed $k_{AB}$. \n",
    "\n",
    "Hence, both Alice and Bob end up with the same secret key $k_{AB}$ that they can use for secure communication.\n",
    "\n",
    "Note: <br>\n",
    "A and B are generally referred to as public numbers/values and a and b as the private numbers/values. And in some context, A and B are called public keys and a, b are called private keys. <br>\n",
    "$K_{AB}$ is referred as the shared secret key.<br>\n",
    "The value p (prime) and g (generator) are referred to as global values because everybody knows what they are.\n",
    "\n",
    "A prominent analogy of Diffie-Hellman protocol:\n",
    "![](./Images/DH-analogy.png)\n",
    "\n",
    "The key property behind Diffie-Hellman:\n",
    ">Martie Hellman and Wig Diffie came up with this protocol back in 1976. They came up with this protocol and this protocol really changed the world. In that it introduced this new age in cryptography where now it's not just about developing block ciphers but it's actually about designing algebraic protocols that have properties like the one we see here. So, notice that what makes this protocol works is basically properties of exponentiation. Namely that,  $(g^{b})^{a}$ is the same as  $(g^{a})^{b}$.\n",
    "\n",
    "The Big Question:<br>\n",
    "Why is this protocol secure? In other words, why is it that an eavesdropper cannot figure out the same shared key using public keys A and B along with the global values p and g?\n",
    "\n",
    "For now, we'll analyze the security briefly and we'll do an in-depth analysis later.\n",
    "![](./Images/Security-DH.png)\n",
    "\n",
    "Given the parameters A, B, p and q, the question is, can the eavesdropper compute $g^{ab}$ with the given four values?<br>\n",
    "Well lets generalize the question a bit, what we can do is we can define the Diffie-Hellman function. So we'll say that the Diffie-Hellman function is defined based on some value g, $DH_{g}$. And the question is given $g^{a}$, and $g^{b}$. Can the adversary compute $g^{ab}$? And what we're asking is how hard is it to compute this function $DH_{g}$ module over very large prime p. So, **the fundamental question we need to answer is how hard is it to solve Diffie-Hellman function?** <br><br>\n",
    "\n",
    "![](./Images/DH-FxnHardness-1.png)\n",
    "\n",
    "Suppose we have a n bit prime number, where n = 2000 for a 600 digit prime. It turns out that the best known algorithm for computing the Diffie–Hellman function, is actually a more general algorithm that computes the discrete log function, which we're gonna talk about later, and is called General Number Field Sieve (GNFS).\n",
    "\n",
    ">But the interesting thing is that GNFS running time is exponential in roughly the $e^\\sqrt[3]{n}$. In other words, the running time is roughly $e^\\sqrt[3]{n}$. So in fact the exact expression for the running time, of this algorithm is much more complicated than this. We are deliberately simplifying it here just to kind of get the point across. The point that we need to emphasize is that in fact, this is not quite an exponential time algorithm. Exponential would be $e^{n}$. This is sometimes called a sub-exponential algorithm because the exponent is really just proportional to the $\\sqrt[3]{n}$, as opposed to linear n. \n",
    "\n",
    "Therefore, GNFS can break the Diffie-Hellman, roughly, in the time of order O($e^\\sqrt[3]{n}$).\n",
    "\n",
    "**Breaking hardness comparison: Block cipher's key size vs Diffie-Hellman's modulus (prime number's bit size)**\n",
    "\n",
    "![](./Images/DH-FxnHardness-2.png)\n",
    "\n",
    "The rough difficulty of breaking down the Diffie-Hellman protocol compared to the difficulty of breaking down a cipher with a appropriate number of key bits is depicted above. For example, if your cipher has 80 bit keys. That would be roughly comparable to using 1,024 bit modulus. In other words breaking a cipher with 80 bit keys takes time roughly $2^{80}$, which means that if you have Diffie-Hellman function with a 1,000 bit modulus breaking it will take time $2^{80}$. Similarly, If your cipher uses 128 bit keys like AES, you should be really using a 3,072 bit modulus, even though nobody really does this. In reality people would use 2,048 bit modulus. \n",
    "\n",
    "And then if your key is very large, like if we're using a 256 bit AES key, then in fact your modulus needs to be very, very large. Now, you can really see the cube root effect here. We doubled the size of our key from 128 to 256 and because of the cube root effect, what that means is we have to increase the size of, of our modulus by a factor of two cubed, namely a factor of eight, which is where this 15,360 comes from.\n",
    "\n",
    "Note:\n",
    ">Given above is a nice table that shows you that if you're gonna be using Diffie-Hellman to exchange a session key. And that session key is gonna be used for a block cipher of a certain key size, this table shows you what modular size you need to use so that the security of the key exchange protocol is comparable to the security of the block cipher you're gonna be using after.<br><br>\n",
    "Example: If two parties are using AES with 128 bit key size for encryption and decryption, then to securely exchange a 128 bit sized secret key using Diffie-Hellman they should use a modulus of the size 3072 bits and as a result breaking Diffie-Hellman would be of the same order as of the AES-128, that is, $2^{128}$.\n",
    "\n",
    "\n",
    "Problem with modulus: <br>\n",
    "Now this last row, where we required a 15,360 bit modulus corresponding to a 256 bit key, should really be disturbing to you. Working with such a large modulus is very problematic. This is actually gonna be quite slow, and so the question is whether there is anything better that we can do?\n",
    "\n",
    "Solution: **Elliptic Curve**<br>\n",
    "The question is can we run the Diffie-Hellman protocol in other settings. And it turns out the answer is yes. In fact we can literally translate the Diffie-Hellman protocol from an arithmetic model of primes to a different type of algebraic object and solving the Diffie-Hellman problem on that other algebraic object is much, much harder (hence the adversary would have to work much harder to break). This other algebraic object is what's called an **Elliptic Curve**.\n",
    "\n",
    ">Computing the Diffie-Hellman function on these elliptic curves is much harder than computing the Diffie-Hellman modulo primes. Because the problem is so much harder, now we can use much smaller objects in particular, you know we'd be using primes that are only of 160 bits for 80 bit keys or only 512 bits for 256 bit keys. So because these module don't grow as fast on elliptic curves, there's generally a transition away, although slow, from using module arithmetic, to using elliptic curves.\n",
    "\n",
    "Real world application of Elliptic Curve Diffie-Hellman Key Exchange:\n",
    "![](./Images/DH-Application.png)\n",
    "Note: Diffie-Hellman is being used all across the web for key exchange very frequently.\n",
    "\n",
    "**Diffie-Hellman and Active Attacks: Man-in-the-Middle**\n",
    "\n",
    "The Diffie-Hellman protocol is just CPA-secure, that is, it provides confidentiality. However, it's completely insecure against active attacks, i.e, it isn't CCA-secure and therefore no integrity. A very prominent active attack on Diffie-Hellman protocol is called Man-in-the-Middle attack which completely breaks it down.\n",
    "\n",
    "Note: Don't worry, we just need to do something more to this protocol to enhance it and make it secure against man in the middle. And again we're gonna come back to Diffie Hellman and make it secure against man in the middle later.\n",
    "\n",
    "![](./Images/DH-MiTM.png)\n",
    "The way MiTM attack works is:\n",
    "\n",
    "- Suppose we have this man in the middle that's trying to eavesdrop on the conversation between Alice and Bob. So, the protocol starts with Alice computing $g^{a}$ sending A over to Bob. The man in the middle is gonna intercept that and he's gonna take the message that Alice sent and he's gonna replace it with his own message A'. So the man in the middle chooses his own a' and what he sends to Bob is actually $g^{a'}$. <br><br>\n",
    "\n",
    "- Now poor Bob doesn't know that the man in the middle actually did anything to this traffic, all he sees is he got the value A'. As far as he knows, that value came from Alice. So what is he gonna do in response? Well, he's gonna send back his value B out which is $g^{b}$ back to Alice. Well again the man in the middle is gonna intercept this B. He's gonna generate his own b' and what he actually sends back to Alice is B' which is $g^{b'}$. <br><br>\n",
    "\n",
    "- What happens now? Well Alice is gonna compute her part of the secret key and she's gonna get $g^{ab'}$. Bob is gonna compute his part of the secret key and he's gonna get $g^{ba'}$. If you notice these are not the same keys. <br><br>\n",
    "\n",
    "- The man in the middle, because he knows both A' and B' he can compute both $g^{ab'}$ and $g^{ba'}$. As a result, now he can basically play this man in the middle and when Alice sends an encrypted message to Bob the man in the middle can simply decrypt this message because he knows the secret key that Alice encrypted message with, re-encrypt it using Bob's key. And then send the message on over to Bob. <br><br>\n",
    "\n",
    "- This way Alice sent the message, Bob received the message. Bob thinks the message is secure. But in fact that message went through the man in the middle. The man in the middle decrypted it, re-encrypted it for Bob. At the same time he was able to completely read it, modify it if he wants to, and so on. So, the protocol becomes completely insecure give n a man in the middle.\n",
    "\n",
    "But as mentioned, we're going to enhance the protocol somehow to defend against men in the middle but it turns out that it's actually not that difficult to enhance and prevent man in the middle attacks. We will do it later down the road.\n",
    "\n",
    "**Interesting Property of Diffie-Hellman: Non-interactive Protocol**\n",
    "\n",
    "![](./Images/DH-NonInteractive.png) \n",
    " \n",
    "Diffie-Hellman protocol can be viewed as a non-interactive protocol. So, what do that mean?\n",
    "\n",
    "Imagine we have a whole bunch of users, say, millions of users. Let's call them Alice, Bob, Charlie, David and so on and so forth. Each one of them is going to choose a random, secret value i.e. their private keys, and then on their Facebook profiles, they're gonna write down, their contribution to the Diffie-Hellman protocol, i.e. their public key values. Alright so everybody just writes down $g^{a}$ , $g^{b}$, $g^{c}$ and so on.\n",
    "\n",
    "Now the interesting thing about this is, if say Alice and Charlie wanna set up a shared key they don't need to communicate at all. Basically Alice would go and read Charlie's public profile. Charlie would go and read Alice's public profile. And now, boom, they immediately have a secret key. Namely, now, Alice knows, $g^{ca}$. Charlie knows $g^{ac}$. And as a result, both of them can compute $K_{AC}$. So, in some sense, once they've posted their contributions to the Diffie-Hellman protocol to their public profiles, they don't need to communicate with each other at all to set up a shared key. They immediately have a shared key and now they can start communicating securely through Facebook with one another. Hence, this is true for everybody on facebook, i.e., as soon as someone visits someone's profile they immediately have a shared key with them and so the conversation, if initiated, would get encrypted using that key (although that's not literally how Facebook uses encryption).\n",
    "\n",
    "**An Open Problem**\n",
    "\n",
    "![](./Images/DH-OpenProb.png)\n",
    "\n",
    "The question is: can we do non-interactive key exchange for more than two parties, that is, can we non-interactively develop a joint shared key?\n",
    "\n",
    "In other words, say we have four parties. All of them post their values to their Facebook profiles. And now we'd like to make it that just by reading Facebook profiles, all of them can set up a joint shared secret key. In other words, Alice reads the public profiles of her three friends, Bob, Charlie and David. And we want that by doing so she rather than computing separate keys with each of them, she can compute a shared key with all 3 of them, i.e., a singe joint key $K_{ABCD}$ which she can use to interact with any and all of them. And similarly if David is going to read the public profile of Charlie, Bob and Alice and already, with some protocol, he has a shared key $K_{ABCD}$ with all four of them. \n",
    "\n",
    "So the question basically is whether we can kind of setup, non-interactively, shared keys for groups that are larger than just two people. For n (number of parties) equals two, this is just a Diffie-Hellman protocol. It turns out, for n equals three, we also know how to do it, there's a known protocol, it's called protocol Joux. It already uses very, very fancy mathematics, much more complicated mathematics than Diffie-Hellman. And for n equals four, five, or anything above this, the problem is completely open.\n",
    "\n",
    "----\n",
    "\n",
    "#### Public-Key Encryption\n",
    "Quick Read: [Public-Key Encryption](https://www.tutorialspoint.com/cryptography/public_key_encryption.htm)<br>\n",
    "Corresponding Watch: [Public Key Encryption](https://www.coursera.org/learn/crypto/lecture/HB4jI/public-key-encryption)\n",
    "\n",
    "Just as in the case of symmetric encryption, there's an encryption algorithm and a decryption algorithm. However, here the encryption algorithm is given one key, which is referred to as public key and the decryption algorithm is given a different key, called secret key. So these two keys are sometimes referred as a key pair. One half of the pair is the public key, and the other half of the pair is the secret key. \n",
    "\n",
    "![](./Images/PKEnc-InPic.png)\n",
    "\n",
    "Now, the way you encrypt this is, as usual, a message would come in, the encryption algorithm would generate a ciphertext which would be the encryption of this message using the given public key. And then when the ciphertext is given to the decryption algorithm, the decryption algorithm basically outputs the message by decrypting the ciphertext using the corresponding public key. So, PK is called the public key, and SK is called the secret key. \n",
    "\n",
    "Note:\n",
    ">In public key cryptography, encryption is done using recipients public key and that ciphertext could only be decrypted using the recipients private key, hence providing confidentiality. We don't do vice versa because if sender uses his private key for encrypting and decryption would be done by using his public key then as the key is public therefore everybody would be able to decrypt it and there would be no confidentiality. Instead the private key is used for signing as we will see in Digital Signature in order to provide integrity.\n",
    "\n",
    "Lets define Public-Key Encryption more precisely:\n",
    "![](./Images/PKEnc-Formally.png)\n",
    "Description:\n",
    "- Public key encryption system is actually made up of three algorithms, G, E, and D. \n",
    "- Algorithm G is what's called the key generation algorithm. When you run algorithm G, it will output two keys, the public key and the secret key. \n",
    "- The encryption algorithm basically, given the public key and a message, will output the corresponding ciphertext.\n",
    "- The decryption algorithm, given the secret key and ciphertext, will output the message or it will output bottom if an error occurred. \n",
    "\n",
    "And as usual, we have the consistency property that says: for any public key and secret key pair that have been outputted by the key generation algorithm, if we encrypt a message using a public key, and then decrypt using the secret key, we should get the original message back.\n",
    "\n",
    "What does it mean for a Public-Key Encryption to be secure?\n",
    "\n",
    "We use the same concept of semantic security that we used before, except the games now are a little bit different. So lets see how we define semantic security for a public key system.\n",
    "![](./Images/PKEnc-SemanSecurity.png)\n",
    "Semantic Security Game:\n",
    "- So here, the challenger is going to run the key generation algorithm to generate a public key and a secret key pair, and he's going to give the public key to the adversary. The challenger keeps the secret key to himself. <br><br>\n",
    "\n",
    "- What the adversary will do is he will take two equal length messages, $m_{0}$ and $m_{1}$ as before. And then the challenger will give him the encryption of either $m_{0}$ or $m_{1}$. As usual, we define two experiments, EXP(0) and EXP(1). In EXP(0), the adversary is given the encryption of $m_{0}$, and in EXP(1), the adversary is given the encryption of $m_{1}$. And then the adversary's goal is to guess which encryption he was given. Was he given the encryption of $m_{0}$, or was he given the encryption of $m_{1}$? <br><br>\n",
    " \n",
    "- Now that we've defined the game, we're gonna say that a public key system, (G, E, D), is semantically secure if the attacker cannot distinguish EXP(0) from EXP(1). In other words, the adversary's probability of outputting one in EXP(0) is about the same as its probability of outputting one in EXP(1), making his advantage is negligible. So again, the attacker can't tell whether he was given the encryption of $m_{0}$ or the encryption of $m_{1}$. <br><br>\n",
    "\n",
    "Therefore, Public-Key Encryption is Semantically Secure and an eavesdropper won't be able to tell anything about the plaintext just by looking at the ciphertext.\n",
    "\n",
    "Note (CPA Security is inherent to Semantically Secure Public-Key Encryption):\n",
    ">One thing to emphasize is that in the case of public key encryption, there's no need to give the attacker the ability to mount a chosen plain text attack. Why is that? Well, in the case of a symmetric key system, the attacker had to request the encryption of messages of his choice. In the case of a public key system, the attacker has the public key and therefore, he by himself can encrypt as many messages as he wants. He doesn't need the challenger's help to create encryptions of messages of his choice. And as a result, in a public key settings, CPA is inherent. There's no reason to give the attacker extra power to mount a chosen plain text attack. And that's why we never discuss chosen plaintext queries in the context of defining semantic security for public key systems. \n",
    "\n",
    "**Relation to symmetric cipher security**\n",
    "![](./Images/PKEnc-SymmetricRelation.png)\n",
    "Description:\n",
    "- When we talked about eavesdropping security for symmetric ciphers, we distinguished between the case where the key is used once, and the case where the key is used multiple times. And, in fact we saw that, there's a clear separation. For example, the onetime pad is secure if the key is used to encrypt a single message, but is completely insecure if the key is used to encrypt multiple messages. <br><br>\n",
    "- And in fact we had two different definitions, if you remember we had a definition for one-time security (Semantic Security), and then we had a separate definition, which was stronger, when the key was used multiple times (CPA-Security). <br><br>\n",
    "- The definition that we have seen for public-key encryption was very similar to the definition of one time security for symmetric ciphers, that is, we talked about Semantic Security.<br><br> \n",
    "- It turns out that for public key encryption, if a system is secure under a onetime key i.e. Semantically Secure then, in a sense, it's also secure for a many time key i.e. CPA-secure.<br><br>\n",
    "- In other words, we don't have to explicitly give the attacker the ability to request encryptions of messages of his choice. Because he could just create those encryptions all by himself. He is given the public key, and therefore he can by himself encrypt any and as many message as he likes.\n",
    "\n",
    "As a result, in fact, the definition of one time security is enough to imply many time security and that's why we refer to the concept as **indistinguishability under a chosen plain text attach (IND-CPA)**.\n",
    "\n",
    "**How to use Public Key Encryption to establish a shared secret?**\n",
    "\n",
    "![](./Images/PKEnc-SecretKeyEstablishment.png)\n",
    "Description:\n",
    "- Alice will start off by generating a random public key - secret key pair for herself, using the key generation algorithm. And then she's going to send to Bob, the public key, pk. And along side she also says, \"hey, this message is from Alice\". \n",
    "\n",
    "- What Bob will do is he will generate a random 128-bit value x and he will send back the encryption of x under Alice's public key along with saying, \"hey, this message is from Bob\".\n",
    "\n",
    "- Alice will receive the ciphertext. She'll decrypt it using her secret key. And that will give her the value x. And now this value x can be used basically as a shared secret between the two of them. \n",
    "\n",
    "Key Exchange: Diffie-Hellman vs Public-Key Encryption:\n",
    "\n",
    "Public-key encryption protocol is very different from the Diffie-Hellman protocol that we saw in the last segment in the sense that here, the parties have to take turns, in the sense that Bob cannot send his message until he receives the message from Alice. In other words, Bob cannot encrypt x to Alice's public key until he receives the public key from Alice. In a Diffie-Hellman protocol, however, the two parties could send their messages at arbitrary times, and there was no ordering enforced on those messages. \n",
    "\n",
    "As a result, we have this nice application of Diffie-Hellman where everybody could post their contributions to, for example, Facebook and then just by looking at Facebook profiles, any pair would already have a shared key without any need for additional communication. In public-key encryption this is not quite true, even if everybody posts their public keys to Facebook, there would still be a need to send this message, encrypted x with public key of the receiver, before a shared key can be established. \n",
    "\n",
    "Bottom line: Diffie-Hellman has this non-interactive key exchange property whereas in public-key encryption there is no such thing.\n",
    "\n",
    "**Security of Public-Key Encryption protocol for Key Exchange**\n",
    "\n",
    "Note: We're only gonna look at eavesdropping security.\n",
    "![](./Images/Security-PKE-KeyEx.png)\n",
    "Description:\n",
    "- The attacker gets to see the public key and the encryption of x under the public key, and what he wants to get is basically this value x. Now we know that the public-key encryption system is semantically secure. What that means is that the attacker cannot distinguish the encryption of x from the encryption of something random. <br><br>\n",
    "\n",
    "- In other words, just given the encryption of x, the attacker can't tell whether its the plaintext is x or just some random junk that was chosen from message space M. Therefore that basically says that, just by looking at messages in this protocol, the value of x is indistinguishable in the attacker's view from a random element in M. And as a result, x can be used as a session key between the two parties. It's just a random value which the attacker cannot actually guess other than by exhaustively searching all possible values of M which would take time of the order $2^{128}$ if message space M is {0, 1}$^{128}$.\n",
    "\n",
    "Even though this protocol is secure against eavesdropping, it's completely insecure against the man-in-the-middle (MiTM) attack.\n",
    "\n",
    "Man in the Middle Attack on Public-Key Encryption Key Exchange Protocol:\n",
    "![](./Images/PKE-MiTM.png)\n",
    "Description:\n",
    "- Here we have Alice generating her public key, secret key pair(pk, sk). At the same time the man in the middle is still going to generate his own public key, secret key pair (pk', sk'). Now when Alice sends her public key over to Bob, the man in the middle will intercept and keep the public key of Alice and instead he'll send his public key pk' to Bob with Alice's message. <br><br>\n",
    "\n",
    "- So now Bob will receives this message. He thinks he got a message from Alice, therefore thinking that pk' is Alice's public key. What he'll send back is, well, he's gonna choose his random x, and he'll send that encryption of x under pk'. The man in the middle is gonna intercept this ciphertext c, and is gonna replace it with something else. So as his goal is to make sure that the key exchange succeeds. In other words, Alice thinks that she got a message from Bob, and yet the man in the middle should know exactly what the exchange secret key is. So what should the man in the middle send to Alice in this case? <br><br>\n",
    "\n",
    "- What the man in the middle will do, is he will decrypt the cipher text c, using his own secret key pk'. And that will reveal x to the man in the middle. And then he's gonna go ahead and encrypt x under Alice's public key pk, send the value back to Alice. Alice will obtain this x and as far as she's concerned, she just did a key exchange with Bob where both of them learned the value x. But the problem, of course, is that the man in the middle knows the value x as well. \n",
    "\n",
    "So this protocol becomes completely insecure once the man in the middle can tamper with messages from Alice to Bob and from Bob to Alice. Therefore, we have to do something to this protocol to make it secure, and we're gonna see how to do that later, after we introduce Digital Signatures.\n",
    "\n",
    "Now as we know that public key encryption key exchange protocol is secure against eavesdropping, the next question is:<br> \n",
    "**How do we construct public key encryption systems?** \n",
    "![](./Images/PKE-HowToConstruct.png)\n",
    "It turns out that these constructions generally rely on Number Theory and some Algebra, and just like the Diffie-Hellman protocol relied on some algebra, and so before we go into these protocols and constructions in more detail, what I'd like to do is kind of take a quick detour. Therefore, we're going to look at the relevant number theoretic background and then we'll come back and talk about these public key constructions and more constructions for key exchange. \n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number Theory\n",
    "\n",
    "In cryptography, we need the concepts from Number Theory in order to construct:\n",
    "- Key exchange protocols\n",
    "- Digital signatures\n",
    "- Public-key Encryption\n",
    "\n",
    "### Number Theory 1: Modular Arithmetic\n",
    "\n",
    "Ultimate Goal(of this section): Have the ability to solve polynomial equations (specifically linear and quadratic).<br>\n",
    "Therefore, in this section, we are going to do a crash course on relevant concepts from Number Theory.\n",
    "\n",
    "#### Basic Modular Arithmetic and Notation\n",
    "Corresponding Watch: [Modular Arithmetic](https://www.coursera.org/learn/crypto/lecture/2YWK8/notation)\n",
    "\n",
    "![](./Images/NT-Notation.png)\n",
    "The Set $Z_{N}$:<br>\n",
    "Z, written like two diagonal lines here with a subscript N, $Z_{N}$  is going to be used to denote the set of zero, one, two, up to N-1, that is, **the set of all the numbers that can exist in the modular N's world are represented by $Z_{N}$, which would simply be the integers from 0 to N-1** .And in fact, this is not just a set of integers, we can do addition and multiplication in this set as long as we always operate modulo of the N to it. Hence, $Z_{N}$ denotes a ring where addition and multiplication are done modulo N. <br>\n",
    "\n",
    "Note: This is very common notation in crypto, although in modern mathematics $Z_{N}$  sometimes denotes something else.\n",
    "\n",
    "Few examples of Modular Arithmetic:\n",
    "![](./Images/NT-ModArith-Ex.png)\n",
    "Arithmetic in Modulo N works just as we would expect them. For example, all the laws that we know about addition and multiplication work equally well in $Z_{N}$.\n",
    "\n",
    "Greatest Common Divisor:\n",
    "![](./Images/NT-GCD.png)\n",
    "An important fact about gcd's is, if we have two integers x and y, there will always exist two other integers, we will call them a and b, such that if we do a.x + b.y what we'll get is the gcd of x and y. In other words **the gcd of x and y is a linear combination of x and y using the integers a and b**.\n",
    "\n",
    "Not only do a and b exist, in fact there's a very simple and efficient algorithm to find these integers. The algorithm is what's called the **Extended Euclidean algorithm**. It's a fairly simple algorithm and given x and y, this algorithm will find a and b in time roughly quadratic in the logarithms of x and y.\n",
    "\n",
    "Read: [Euclidean and Extended Euclidean Algorithm](https://brilliant.org/wiki/extended-euclidean-algorithm/)\n",
    "\n",
    "Modular Inversion:\n",
    "![](./Images/NT-ModInver.png)\n",
    "Simply, the inverse of x in $Z_{N}$ is an element y in $Z_{N}$ such that: \n",
    "- x.y (mod N) = 1, which could also be expressed as\n",
    "- x.y = 1 (mod N), or \n",
    "- x.y = 1 in $Z_{N}$\n",
    "\n",
    "y is denoted by x$^{-1}$ and if it exists than in fact it is unique.\n",
    "\n",
    "Which elements have an inverse in $Z_{N}$? Ans: x in $Z_{N}$ is invertible if and only if x is relatively prime to N.\n",
    "![](./Images/NT-ModInverExist.png)\n",
    "\n",
    "It's actually fairly simple to prove the lemma:\n",
    "- Suppose a gcd of x and N happens to be equal to one. So, that means x is relatively prime to N. \n",
    "- Well, by the property of gcd, as aforementioned, we know that there exists integers a and b. Such that a.x + b.y equal to the gcd of x and y,therefore here we have a.x + b.N = gcd(x, N), which happens to be 1. So, a.x + b.N = 1. \n",
    "- Now we can actually take this equation a.x + b.N = 1 and reduce it to modulo N. So what this means is that we do the following  a.x + b.N (mod N)= 1 (mod N). Now b.N simply falls off as b.N (mod N) is equal to 0. \n",
    "- So we are left with a.x (mod N) = 1 (mod N), which is synonymous to, a.x = 1 in $Z_{N}$ which implies that a = x$^{-1}$.\n",
    "\n",
    "What we just showed is that in fact inverse of x is simply a in $Z_{N}$.\n",
    "\n",
    "What happens if the GCD is greater than 1?<br>\n",
    "Then we want to show that there is no inverse of x in $Z_{N}$. And that's actually very easy to see because in this case, if we claim that a happens to be the inverse of x in $Z_{N}$, well, then let's look at a.x; a.x as we know then should be equal to 1 modulo N which is simply 1. But if we have the GCD(x,N) bigger than 1, then the gcd(a.x,N) would also be bigger than one. But, if the  gcd(a.x,N) is bigger than 1, then it's not possible that a.x is equal to 1 else the gcd would become 1 which is contradictory. Therefore, a.x must also be bigger than 1, hence, a cannot be the inverse of x in $Z_{N}$.\n",
    "\n",
    "Given that we can find if the inverse of x (which is a) exist in $Z_{N}$ or not, how would we be able to compute the inverse a, if it exists (when x is relatively prime to N)?<br>\n",
    ">As we have seen a bit earlier that we can efficiently use Extended Euclidean Algorithm to compute a and b for the equation a.x + b.N = 1 and as we proved just now that a is simply the inverse of x, hence, we can efficiently compute a, the inverse of x, using **Extended Euclidean Algorithm**.\n",
    "\n",
    "Further notation:\n",
    "![](./Images/NT-moreNotation.png)\n",
    "For Primes:<br>\n",
    "We can develop a general definition of Z-star-sub-N/$(Z_{N})^{*}$ for prime p. We know that of the integers from 0 to p-1, all of them are gonna be relatively prime to p, except one integer, namely, the integer 0. Zero is not relatively prime to p, because the GCD(p,0) = 0 and not 1. Therefore, if p is a prime, the set Z-star-sub-p/$(Z_{p})^{*}$, is simply $Z_{p}$ - {0}, which means that everything in $Z_{p}$ is invertible except for 0. So, the size of set $Z_{p}$ is simply p-1.\n",
    "\n",
    "For composites (non-primes):<br>\n",
    "Here we can't have a general definition. Instead we would have to check each element, from the set Z-star-sub-composite/$(Z_{composite})^{*}$, whether it is relatively prime to the composite or not. For ex: Z-star-sub-12/$(Z_{12})^{*}$ only contains the following elements: 1, 5, 7 and 11 (from set $Z_{12}$) as those are the only elements which are relatively prime to 12.\n",
    "\n",
    "Using what we have learned by now under Number Theory, we would be able to solve modular linear equations.\n",
    "![](./Images/NT-ModularLinearEqn.png)\n",
    "\n",
    "#### Fermat's and Euler's Theorem\n",
    "Corresponding Watch: [Fermat and Euler](https://www.coursera.org/learn/crypto/lecture/Z2Tso/fermat-and-euler)\n",
    "\n",
    "**Fermat's Theorem**:\n",
    "Fermat did a number of important theorems. The one that we want to discuss is the following: <br>Suppose we have a prime p. Then in fact for any element x in $(Z_{p})^{*}$, it so happens that if we look at x and raise it to the power of p - 1, we are gonna get 1 in $Z_{P}$. \n",
    "\n",
    "![](./Images/NT-FermatTheorem.png)\n",
    "Finding inverse using Fermat's theorem: <br>\n",
    "Suppose we look at an element z in $(Z_{p})^{*}$. Reminder, p must be a prime. Well, then what do we know? We know that $x^{p-1}$ is equal to one. Well, we can write $x^{p-1}$ as $x$.$x^{p-2}$. So now we know that $x$.$x^{p-2}$ happens to be equal to one. And what that says, is that really the inverse of x modulo p, is simply $x^{p-2}$. So this gives us another algorithm for finding the inverse of x modulo a prime.\n",
    "\n",
    "But this method has two deficiencies compared to Euclid's algorithm: \n",
    "- First of all, it only works modulo primes, whereas, Euclid's algorithm worked modulo composites as well.\n",
    "- And second of all, it turns out this algorithm is actually less efficient. When we talk about how to do modular exponentiations--we're gonna do that later--we'll see that the running time to compute this exponentiation is actually cubic in the size of p. So this will take roughly log cube of p, whereas if you remember, Euclid's algorithm was able to compute the inverse in quadratic time in the representation of p. \n",
    "\n",
    "Application of Fermat's Theorem: Generating large prime numbers.\n",
    "\n",
    "![](./Images/NT-FermatsThmApp.png)\n",
    "\n",
    "We wanted to generate a large random prime, say our prime needed to be 1,000 bits or so. So the prime we're looking for is on the order of $2^{1024}$. <br>\n",
    "Here's a very simple probabilistic algorithm:\n",
    "- We would choose a random integer in the interval that was specified. <br><br>\n",
    "- And then we would test whether this integer satisfies Fermat's theorem. In other words, we would test for example using the base two; we would test whether $2^{p-1}$ equals 1 in $Z_{p}$.<br><br>\n",
    "- If the answer is no, that is if this equality doesn't hold, then we know for sure that the number p that we chose is not a prime. And if that happens, all we do is we go back to step one and we try another prime. And we do this again and again and again, until finally we find an integer that satisfies this condition. And once we find an integer that satisfies this condition, we simply output it and stop. <br><br>\n",
    "- Now it turns out, if a random number passes this test, then it's extremely likely to be a prime but not guaranteed to be a prime. In particular the probability that p is not a prime, false prime, is very small. It's like less than $2^{-60}$ for the range of 1024 bit numbers. \n",
    "\n",
    "How many iterations would it take to find a prime using this probabilistic algorithm?<br>\n",
    "That's actually a classic result; it's called the prime number theorem, which says that, after a few hundred iterations, in fact, we'll find the prime with high probability. \n",
    "\n",
    "Note: This is a very simple algorithm for generating primes. It's actually, by far, not the best algorithm. We have much better algorithms now. And, in fact, once you have a candidate prime, we now have very efficient algorithms that will actually prove beyond a doubt that this candidate prime really is a prime. So we don't even have to rely on probabilistic statements. \n",
    "\n",
    "**The Structure of $(Z_{p})^{*}$**<br>\n",
    "One of the first things Euler showed is that $(Z_{p})^{*}$, where p is prime, is what's called a cyclic group.\n",
    "![](./Images/NT-StructureZP-Star.png)\n",
    "\n",
    "What does it mean that $(Z_{p})^{*}$ is a cyclic group?<br>\n",
    "What it means is that there exists some element $g$ in $(Z_{p})^{*}$, such that if we take $g$ is raise to a bunch of powers say $g^{0}$, $g$, $g^{2}$, $g^{3}$, $g^{4}$ and so on and so forth up until we reach $g^{p-2}$. The powers of $g$ give us all the elements in $(Z_{p})^{*}$. Elements of this type are called generators. So $g$ would be said to be a generator of $(Z_{p})^{*}$. However, not every element of the set $(Z_{p})^{*}$ is a generator as depicted above.\n",
    "\n",
    "Notice there's no point of going beyond $g^{p-2}$, because $g^{p-1}$ by Fermat's theorem is equal to one, so then we will cycle back to one. If we go to $g^{p-1}$, then $g^{p}$ will be equal to $g$, $g^{p+1}$ one will be equal to $g^{2}$, and so on and so forth. So we'll actually get a cycle if we keep raising to higher and higher powers of $g$. So we might as well stop at the power of $g^{p-2}$. \n",
    "\n",
    "Order of g (where g may or may not be a generator):\n",
    "![](./Images/NT-OrderOfg.png)\n",
    "- If g is a generator of $(Z_{p})^{*}$ then the $order_{p}$ g is simply equal to the size of the $(Z_{p})^{*}$, as it generates all the element in the $(Z_{p})^{*}$ and that's the maximum value possible for the $order_{p}$ g.\n",
    "- Otherwise, it's basically the size of $<g>$ or other way to think about it is it's the smallest power a, where a>0, that causes the power of g to be equal to one again, that is, order is equal to the smallest power of a, such that a>0 and $g^{a}$ = 1 in $(Z_{p})^{*}$ .\n",
    "\n",
    "Lagrange's Theorem: <br>\n",
    "Actually this is a very, very special case of lagrange theorem, what we are stating here. But Langrage's theorem basically implies that if you look at the order of g modulo p ($order_{p}$ g), the order is always going to divide p-1. So in our two example we see, $order_{7}$ 3 = 6 and 6 divides 7 - 1, six divides six, and similarly, $order_{7}$ 2 = 3 which divides 7-1, namely again three divides six. This is very general; your order is always going be a factor of p-1.\n",
    "\n",
    "**Euler's Theorem**\n",
    "\n",
    "Now that we understand the structure of $(Z_{p})^{*}$, let's generalize that to composites, and look at the structure of $(Z_{N})^{*}$. So what we will see is the Euler's Theorem which is a direct generalization of Fermat's Theorem.\n",
    "\n",
    "![](./Images/EulersGenFermat.png)\n",
    "\n",
    "Euler defined the following function. So given an integer N, he defined what's called the Euler's phi function, also known as **Euler's totient**. It is basically the size of the set $(Z_{N})^{*}$. For example, $(Z_{12})^{*}$ contains these four elements, one, five, seven, and eleven. And therefore we say that phi $(Z_{N})^{*}$ is simply the number 4. So a puzzle, what is phi of p, where p represents prime? It will basically be the size of $(Z_{p})^{*}$ star. And so, in fact, we said that in the $(Z_{p})^{*}$ star contains all of $Z_{p}$  except for the number zero. And therefore, phi of p for any prime p is gonna be p-1.\n",
    "\n",
    "A special case, which we'll see happening at RSA:<br>\n",
    "**If N happens to be a product of two primes, then phi/totient of N is simply N - P - Q + 1**. Why is that true?<br>\n",
    "So, basically N is the size of $Z_{N}$. And now we need to remove all the elements that are not relatively prime to N. Well how can an element not be relatively prime to N? Because It's gonna be divisible by p or it's gonna be divisible by q. Well how many elements between 0 and N-1 are there that are divisible by p? Well there are exactly q of them. How many elements are there that are divisible by q. Well there are exactly p of them. <br>\n",
    "So we subtract p to get rid of those divisible by q. We subtract q to get rid of those divisible by p. And you notice we subtracted zero twice, because zero is divisible both by p and q. And therefore, we add one just to make sure we subtract zero only once. And so it's not difficult to see that phi(N) is N - P - Q + 1. And another way of writing that is simply **(p-1).(q-1)**. Okay, so this is a fact that we will use later on, when we come back and talk about the RSA system. \n",
    "\n",
    "**Euler phi function to generalize Fermat's Theorem:**<br>\n",
    "So far, this is just defining this phi function of Euler. But now Euler put this phi function to really good use. And what he proved is this amazing fact here that basically says that if you give me any element x in $(Z_{p})^{*}$. In fact, and it so happens that $x^{phi(N)}$ is equal to 1 in $Z_{N}$. So you can see that this is a generalization of Fermat's theorem; in particular, Fermat's theorem only applied to primes. For primes we know that phi(p) is equal to p-1, and then we would get exactly Fermat's theorem which is  $x^{p-1}$ = 1 in $Z_{p}$. The beauty of Euler's theorem is that it applies to composites, and not just primes. Hence he basically generalized Fermat's theorem.\n",
    "\n",
    "#### Modular e'th roots\n",
    "Corresponding Watch: [Modular e'th roots](https://www.coursera.org/learn/crypto/lecture/fjRVO/modular-e-th-roots)\n",
    "\n",
    "Now we know how to solve linear equations simply by using an inversion algorithm to compute an inverse and then multiplying the result by -b. So the question is what about higher degree polynomials and in particular we are interested in solving, polynomials modulo primes. So solving polynomials in $Z_{p}$, but polynomials particularly of the form $x^{2}$ - $c$ or $y^{3}$ - $c$ or $z^{37}$ - $c$ , all in $Z_{p}$.\n",
    "![](./Images/NT-HowModularRoot.png)\n",
    "So solving the above polynomials, for example, $x^{2}$ - $c$ involves computing the square root of $c$. Solving $y^{3}$ - $c$  polynomial involves computing the cube root of $c$. Solving $z^{37}$ - $c$ polynomial involves computing the thirty-seventh root of $c$. \n",
    "\n",
    "![](./Images/NT-ModEthRoot.png)\n",
    "Let p be a prime, and let's say that c is some element in $Z_{p}$.<br>\n",
    "We'll say an x in $Z_{p}$ that satisfies $x^{e}$ = $c$ in $Z_{p}$ then such an x is called the modular e-th root of $c$.<br>\n",
    "Ex: \n",
    "- For $7^{1/3}$, 7 is our c and we want to find it's 3-rd/cube root hence e = 3, i.e. some x in $Z_{11}$ such that $x^{3}$ = 7 in $Z_{11}$. \n",
    "- So, we need to find an x in $Z_{11}$ such that $x^{3}$ = 7. For x = 6, we have $6^{3}$ = 216 = 7 in $Z_{11}$. Hence 6 is the 3-rd root of 7.\n",
    "\n",
    "Note: Not all roots exist. For ex:  the square root of two simply doesn't exist modulo 11. \n",
    "\n",
    "Now that we understand what an e'th root is, the next question is, when do these e'th roots exist, and when we know that they do exist, can we actually compute them efficiently?\n",
    "\n",
    "**The Easy Case**\n",
    "![](./Images/NT-RootEasyCase.png)\n",
    "We'll start with the easy case. The easy case is, when we want to compute an e'th root of something, and it so happens that e is relatively prime to p-1. In this case, $c^{1/e}$ always exists, and there's a very easy algorithm to actually compute the $c^{1/e}$ in $Z_{p}$. So let's see how this works:\n",
    "- Since e is relatively prime to p-1, we know that e has an inverse in $Z_{p-1}$. So let's compute this inverse, and let's call it d. \n",
    "- So, let d be the inverse of e modulo p-1. Then we can claim that in fact $c^{1/e}$ is simply $c^{d}$ modulo p. \n",
    "- So if this equation holds then first of all it proves that for all с in $Z_{p}$ the e'th root to c actually exists. And moreover, it gives a very efficient algorithm to compute this e'th root to c, simply by computing the inverse of e modulo p-1, that's d, and then raising c to the power of that inverse, that is, $c^{d}$. \n",
    "\n",
    "Why this equation, $c^{1/e}$ = $c^{d}$, holds?\n",
    "\n",
    "- First of all the fact that d.e = 1 mod p-1, what that means is there exists some integer k, such that,  d.e = k .(p-1) + 1. That's basically what d times e is equal to one modulo p-1 means. \n",
    "- So, now we can actually confirm that $c^{d}$ is a e'th root of c. Well, how do we confirm that? \n",
    "- Let's take $c^{d}$, and raise it to the power of e. If in fact, $c^{d}$ is an e'th root of c, when we raise it to the power of e; we're supposed to get c back. \n",
    "- Let's see why that's true. Well, $(c^{d})^{e}$, by definition, is equal to $c^{k.(p-1)+1}$ and using the laws of exponentiation, we can write this as $(c^{p-1})^{k}$.$c$. All we did is we distributed the exponentiation using the standard laws of exponentiation. \n",
    "- Now what do we know about $(c^{p-1})$? Since c lives in $Z_{p}$ by Fermat's theorem we know that $(c^{p-1})$ is equal to 1, in $Z_{p}$ and 1 to the k is also equal to 1 and as a result, this is simply equal to c in $Z_{p}$, which is exactly what we needed to prove that $c^{d}$ is an e'th root of c, because $(c^{d})^{e}$ = $c$. <br>\n",
    "[For ex: if e is cube root, i.e. 3, then d = $e^{-1}$ which is 1/3 and we simply proved $(c^{1/3})^{3}$ = $c$.]\n",
    "\n",
    "**Not so easy case: Finding Square Root under odd primes**<br>\n",
    "Overview: A less easy case is when e is not relatively prime to p-1. And the canonical example here is when e is equal to 2. So now suppose we want to compute square roots of c in $Z_{P}$. So if p is an odd prime, and in fact we are going to focus on odd primes from now on, then in fact p-1 is going to be even. Which means that the gcd(2, p-1) is not equal to 1, So this is not the easy case. Therefore the algorithm that we just saw is not gonna work when we want to compute square roots modulo an odd prime.\n",
    "\n",
    ">We specifically require to find ways to compute modular square roots (i.e. when e = 2) in order to be able to solve modular quadratic equations, where we would need to compute square roots.\n",
    "\n",
    "![](./Images/NT-RootNonEasyCase.png)\n",
    "Description:\n",
    "- When we work modulo odd prime, the squaring function (when e = 2 and we have to compute square root) is actually a 2-to-1 function. Namely, it maps x and -x to the same value. It matches both of them to $x^{2}$ . Given above is a simple example. Let's look at what happens when we compute squares modulo eleven. So you can see that 1 and -1 modulo 11 both map to 1, 2 and -2 both map to 4. 3 and -3 both map to 9, and so on and so forth. So you can see that it's a 2-to-1 map. These elements 1, 4, 9, 5, and 3 are all going have square roots. For example, the square root of 4 is simply gonna be 2 and -2 (which is 9). And we can claim that, in fact, none of the other elements of $Z_{11}$ are gonna have a square root. <br><br>\n",
    "- And that motivates this definition to say that an element x in $Z_{p}$, we're gonna say, is called a quadratic residue, if in fact, it has a square root in $Z_{p}$. And if it doesn't have a square root, we'll say that it's a non quadratic residue. For example in modulo 11: 4, 9, 5, 3 and 1 are quadratic residues. <br><br>\n",
    "- So lets think, if p is an odd prime, what do you think is the number of quadratic residues in $Z_{p}$? As the squaring function is a 2-to-1 map, which means that half the elements in $Z_{p}$ can't have a pre-image under this map. So the number of quadratic residues is simply (p-1)/2 + 1. The reason that's true is because we know that exactly half the elements in $Z_{p}$ are gonna be quadratic residues because of the fact that the squaring function is a 2-to-1 map. And then, in $Z_{p}$, there's also zero. We also have to account for zero. Zero is always a quadratic residue, 'cause zero squared is equal to zero. Therefore, overall, we get (p-1)/2 + 1 quadratic residues in $Z_{p}$\n",
    "\n",
    "Note: This case is very different from the easy case, where e was relatively prime to p-1. If you remember in the easy case, every element in $Z_{P}$ had an e'th root. When e is not relatively prime to p-1, that's no longer the case, and in particular in the case of e = 2, only half of the elements in $Z_{p}$ have a square root. \n",
    "\n",
    "**Well, so the natural question then is, given an element x that's in $Z_{p}$, can we tell whether it has a square root or not?**<br>\n",
    "So Euler did some important work on that too and in fact, he came up with a very clean criteria to test exactly which elements are quadratic residues and which are not. And in particular he said that x in $Z_{p}$ is a quadratic residue if and only if $x^{(p-1)/2}$ = 1 modulo p. A very elegant and very simple condition. \n",
    "\n",
    "![](./Images/NT-SqRootEulerThm.png)\n",
    "\n",
    "Let's see a simple example in $Z_{11}$:\n",
    "- So, when we work mod 11 we compute it at the 5th power of all the elements in 11, and we can see that this  $x^{(p-1)/2}$ always evaluates to either 1 or -1, and it evaluates to 1 precisely at the quadratic residues which, indeed, is the case at 1, 3, 4, 5, and 9. Hence, those are the quadratic residues, and the other elements are not quadratic residues. <br><br>\n",
    "- One thing to pay attention is, in fact, if we take an x that's not equal to 0, and we look at  $x^{(p-1)/2}$, we can write that as the $(x^{p-1})^{1/2}$. Well,  $x^{p-1}$ by Fermat's theorem, is 1. So, $(x^{p-1})^{1/2}$ is simply a square root of 1, which must be 1 or -1. So what this proves is that really this exponentiation here must output 1 or -1, and we actually saw that happening here. It outputs 1 when x is a quadratic residue, and it outputs -1 when x is not a quadratic residue. <br><br> \n",
    "-  And just for completeness, the value, $x^{(p-1)/2}$ has a name, it's called the **Legendre's symbol** of x over p. And as we said, Legendre's symbol for elements in $Z_{p}$ is either 1 or -1 depending on the quadratic residuosity of x.\n",
    "\n",
    "Now, the sad thing about Euler's Theorem is that it's not constructive. Even though it tells us exactly which elements are quadratic residues and which aren't, this theorem doesn't do it constructively, in the sense that if we want to compute the square roots of a quadratic residue, the theorem doesn't actually tell us how to do that.\n",
    "\n",
    "**So the next question is then how do we compute square roots modulo primes?**\n",
    "So it turns out that's actually not so hard and, again p here is prime, and the process breaks up into two cases:\n",
    "- The first case is when p =  3 modulo 4\n",
    "- The second case is when p = 1 modulo 4, \n",
    "\n",
    ">Rest all odd p's can be deduced to these 2 cases using modulo 4 and when p = 2 modulo 4 or 0 modulo 4, that means p is even and hence p-1 would be odd in which case e and p-1 would be prime and we will apply the easy case methodology.\n",
    "\n",
    "![](./Images/NT-ComputeSqrRoot.png)\n",
    "\n",
    "First case: <br>\n",
    "When p = 3 modulo 4, it's really easy to compute the square root and there's a simple formula. The square root of c in this case is simply:  $c^{(p+1)/4}$. Notice that because p is equal to 3 modulo 4, p+1 is necessarily equals to 0 modulo 4. Which means that p+1 is divisible by 4, and therefore (p+1)/4 is an integer. And that's exactly what allows us to compute this exponentiation and giving us the square root of c. \n",
    "\n",
    "Verifying the formula:<br>\n",
    "We'll take $c^{(p+1)/4}$ and square that. And if, in fact, if $c^{(p+1)/4}$ is the square root of c, when we square it, we should get c. So let's see what happens:\n",
    "- So first of all, by laws of exponentiation, $[c^{(p+1)/4}]^{2}$ is simply equal to $c^{(p+1)/2}$. And that we can write it as $c^{(p-1)/2}$. $c$, this is basically, we took one-half and moved it out of the exponentiation. \n",
    "- Now, what do we know about $c^{(p-1)/2}$ ? Since c is a quadratic residue, we know that $c^{(p-1)/2}$ is 1. And therefore, this is really equal to 1.c, which is c in $Z_{p}$ as we wanted to show. So this basically proves that $c^{(p+1)/4}$ is the square root of c, at least in the case when p = 3 modulo 4. \n",
    "\n",
    "Second Case:<br>\n",
    "When p = 1 mod 4, in that case, this formula doesn't even make sense. Because this exponent (p+1)/4 is gonna be a rational fraction, and we don't know how to raise c to the power of a rational fraction. Nevertheless, it turns out that even in the case where p = 1 mod 4; we can efficiently find square roots, although it's a little bit harder. And in particular, we don't have a deterministic algorithm to do it. We have to use a randomized algorithm to do it. But this randomized algorithm will actually find the square root of x mod p, very efficiently. \n",
    "\n",
    "If someone could prove that the extended Riemann hypothesis, this is some deep hypothesis of analytic number theory. If someone could prove that, that hypothesis is true, in fact, it would give a deterministic algorithm for computing square roots even when p = 1 modulo 4. But as said, we have good randomized algorithms, and this problem is considered easy. Essentially, it boils down to a few exponentiations. And as a result, as we'll see, the running time of computing square roots essentially is cubic in the number of bits of p. \n",
    "\n",
    "Now we know how to compute square roots mod p, and so now we can talk about solving quadratic equations modulo p. Following image shows the step by step procedure to solve a modular quadratic equation, obviously if the square root exists.\n",
    "![](./Images/NT-SolvinQuadractic.png)\n",
    "\n",
    "The next obvious question is **what about computing e-th roots modulo composites rather than just modulo primes?**\n",
    "\n",
    "So we can ask exactly the same questions that we asked before for primes. When does the e'th root modulo N exist? And if we know that it exists, can we actually compute it efficiently? And here, the problem is much, much, much harder. And in fact it turns out that, for all we know, computing e'th roots modular composites is in fact as hard as factoring that composite.\n",
    "![](./Images/NT-ethRootComposite.png)\n",
    "\n",
    "Now, for computing e'th roots modulo N requires us to factor the modulus. And once we factor the modulus, then it's actually easier to compute e'th roots modulo each of the prime factors. And we can combine all the e'th roots together to get the e'th roots modulo the composite N. So it's a very interesting case, where computing e'th root modulo prime was very easy. In fact, for many e's, it was very easy. But computing e'th root modulo composite is much, much, much harder and, in fact, requires the factorization of N. \n",
    "\n",
    "----\n",
    "\n",
    "### Number Theory 2: Easy and Hard Problems\n",
    "\n",
    "#### Arithmetic Algorithms\n",
    "Corresponding Watch: [Arithmetic Algorithms](https://www.coursera.org/learn/crypto/lecture/wxOal/arithmetic-algorithms)\n",
    "\n",
    "How are we going to compute large integers? But first how do we even represent large integers in a computer?\n",
    "![](./Images/NT-RepresentingBigNums.png)\n",
    "That's actually fairly straightforward:\n",
    "- Imagine we're on a 64 bit machine, what we would do is we would break the number we want to represent, into 32 bit buckets And then, we will basically have these n/32 bit buckets, and together they will represent the number that we want to store on the computer. \n",
    "- Notice that we are only giving 64 bit registers as an example. In fact, many modern processors have 128 bit registers or more, and you can even do multiplications on them. So normally we would actually use much larger blocks than just 32 bits. The reason, by the way, we want to limit yourself to 32 bits is so that you can multiply two blocks together, and the result will still be less than 64 bits, less than the word size on the 64-bit machine. \n",
    "\n",
    "Let's now look at particular arithmetic operations and see how long each one takes:\n",
    "![](./Images/NT-Arithmetic.png)\n",
    "Time Complexity:\n",
    "\n",
    "Addition and Subtraction:<br>\n",
    "Addition and subtraction basically what you would do is that addition would carry or subtraction would borrow and those are basically linear time operations. In other words, if you want to add or subtract two n bit integers the running time is basically linear in n.\n",
    "\n",
    "Multiplication:<br>\n",
    "It naively will take quadratic time. In fact, this is what's called the high school algorithm. So a big surprise in the 1960s was an algorithm due to Karatsuba that actually achieves much better than quadratic time in fact, it achieved a running time of O($n^{1.585}$). Basically, he reduced the otherwise 4 multiplications to 3 multiplications and that achieved the complexity ${log_{2}}^{3}$ which is equivalent to 1.585.\n",
    "\n",
    "Surprisingly, it turns out that Karatsuba isn't even the best multiplication algorithm out there. It turns out that, in fact, you can do multiplication in about nlog(n) time. So you can do multiplication in almost linear time. However, this is an extremely asymptotic results. The big O here hides very big constants. And as a result, this algorithm only becomes practical when the numbers are absolutely enormous. And so this algorithm is actually not used very often. But Karatsuba's algorithm is very practical. And in fact, most crypto-libraries implement Karatsuba's algorithm for multiplication. So, in your mind, you should always be thinking all multiplication really is a little bit faster than quadratic, basically its Karatsuba.\n",
    "\n",
    "Division with Remainder:<br>\n",
    "It turns out that division with remainder is also a quadratic time algorithm. \n",
    " \n",
    "So the main operation that remains, and one that we've used many times so far, and we've never, actually never, ever seen how to actually compute it, is this question of exponentiation. So let's solve this exponentiation problem a bit more abstractly.\n",
    "\n",
    "![](./Images/NT-Exponentiation.png)\n",
    "Description:\n",
    "- Imagine we have a finite cyclic group G. All this means is that this group is generated from the powers of some generator g. So for example think of this group as simply ${Z_{p}}^{*}$ and think of g as some generator of G. So our goal now is, given this element g, and some exponent x, our goal is to compute the value of $g^{x}$. <br><br>\n",
    "- Normally what you would say is, if x is equal to then I'm gonna compute you know, g cubed. But in our case, our exponents are gonna be enormous. And so if you try, you know, think of like a 500-bit number and so if you try to compute g to the power of a 500-bit number simply by multiplying g by g by g by g this is gonna take quite a while. In fact it will take exponential time which is not something that we want to do. <br><br>\n",
    "- So the question is whether even though x is enormous, can we still compute g to the x relatively fast and the answer is YES. The algorithm that does that is called a **repeated squaring algorithm**. So lets see, intuitively, how repeated squaring works:<br><br>\n",
    "    - So let's take as an example, 53. So what we'll do is we'll write 53 in binary. So really 53 is 32 plus 16 plus 4 plus 1 as per the position of ones in the binary representation. But what that means is that $g^{53}$ is $g^{32+16+4+1}$. And we can break that up, using again, the rules of exponentiation. We can break that up as $g^{32}$ times $g^{16}$ times $g^{4}$ times $g^{1}$.<br><br> \n",
    "    - Now that should start giving you an idea for how to compute g to the 53 very quickly. What we'll do is, simply, we'll take g and we'll start squaring it. So we square g to get $g^{2}$. We square it again to get $g^{4}$, again square to get $g^{16}$. and one last squaring to get to $g^{32}$. So we've computed all these squares of g. And now, what we're gonna do is we're simply gonna multiply the appropriate powers to give us the $g^{53}$..<br><br>\n",
    "    - So this is $g^{32}$ times $g^{16}$ times $g^{4}$ times $g^{1}$, is basically gonna give us the value that we want, which is $g^{53}$. So with 9 multiplications we computed $g^{53}$. And it turns out this is a general phenomena that allows us to raise g to very, very high powers and do it very quickly.\n",
    "    \n",
    "Runtime of repeated squaring is:<br> O((log x).n$^{2}$) where exponentiation takes log x iterations, where x is the exponent, and each iteration we basically do a multiplication which naively costs $n^{2}$ where n is the number of bits used to represent number N.\n",
    "\n",
    "[ For in-depth explanation, with pseudocode, of Repeated Squaring Algorithm tune in to corresponding watch at 8:00 ]\n",
    "\n",
    "**Running Times of Arithmetic Algorithms in Modular N ($Z_{N}$)**\n",
    "![](./Images/NT-ModularRuntimes.png)\n",
    "Note: Modular arithmetic runtimes are same as our typical arithmetic runtimes.\n",
    "\n",
    "#### Intractable Problems\n",
    "Corresponding Watch: [Intractable Problems](https://www.coursera.org/learn/crypto/lecture/EKdgY/intractable-problems)\n",
    "\n",
    "Now we're going to look at some hard problems that come up in the context of modular arithmetic. These problems are going to be the basis of the cryptosystems that we are going to build.\n",
    "\n",
    "**Easy Problems**<br>\n",
    "Following are the easy problems in context of Modular Arithmetic:\n",
    "![](./Images/NT-EasyProbs.png)\n",
    "\n",
    "**Intractable Problem: Modulo Primes**\n",
    "\n",
    "Fix some large prime p, so think of p as some 600-digit prime, and let's fix some element g in $(Z_{p})^{*}$. And let's assume that the order of this element g happens to be a number q. Now, consider the exponentiation function that simply maps a number x to the element $g^{x}$. We showed in the last segment that this function is easy to compute using the repeated squaring algorithm, so in fact computing $g^{x}$ can be done quite efficiently, but now let's look at the inverse function.\n",
    "![](./Images/NT-IntractPrimes.png)\n",
    "The inverse problem is basically, given $g^{x}$, now we want you to find its logarithm, namely the value x. Over the real numbers, given $g^{x}$, find x is exactly the definition of the logarithm function, but here we have to find the logarithm modulo a prime p. So this is called the **Discrete logarithm problem, Dlog**, and it is defined as, discrete logarithm of $g^{x}$ base g is basically the exponent x where x is in the range 0 to q-2 (where q is the order and q-1 would cycle back to 1) that happens to be the logarithm of $g^{x}$.\n",
    "\n",
    "In the above example: We calculated the $Dlog_{2}$() for each element in ${Z_{11}}^{*}$ <br> \n",
    "(Note: ${Z_{11}}^{*}$ = $Z_{11}$ - 0, as $Z_{11}$ is set of modulo prime, hence except zero every other element is invertible therefore we can compute each one's Dlog)\n",
    "\n",
    "First of all, the $Dlog_{2}$ of 1 is 0, because $2^{0}$ = 1. <br>\n",
    "The $Dlog_{2}$ of 2 modulo 11 is 1, because $2^{1}$ is equal to 2.<br>\n",
    "The $Dlog_{2}$ of 4 modulo 11 is 2, because $2^{2}$ is equal to 4.<br> \n",
    "The $Dlog_{2}$ of 5 modulo 11 is 4, because $2^{4}$ is equal to 16, and 16 is equal to 5 modulo 11.<br>\n",
    "\n",
    "Pattern: To calculate $Dlog_{base}$ of x in $Z_{prime}$, we have to find a y such that $base^{y}$ would give us x in $Z_{prime}$, that is:<br> **$Dlog_{base}$ of $x$ = $y$, if $base^{y}$ = $x$ in $Z_{prime}$ **\n",
    "\n",
    ">The discrete logarithm function in general is actually quite difficult to compute. Of course for small primes, it's quite easy. We can just make a table and you can read off the discrete log values. But if the prime p happens to be a large number, say a 2000-bit number, then in fact computing the discrete log is quite difficult and we don't have good algorithms to do it.\n",
    "\n",
    "Let's define the discrete log problem more generically:\n",
    "\n",
    "![](./Images/NT-DLOG-Gen.png)\n",
    "Description:<br>\n",
    "The Discrete log problem is hard in the group G if in fact no efficient algorithm can compute the discrete log function. So what do we mean by that? What we mean is if you choose a random element g in the group G, and you choose a random exponent x, if we give an algorithm $g$ and $g^{x}$ -- of course we also have to give it a description of the group, so we gave it the description of the group, G, and the order of the group, but the primary elements are $g$ and $g^{x}$ -- the probability that the algorithm will actually compute the discrete log is negligible. \n",
    "\n",
    "Basically, if  no efficient algorithm is able to compute discrete log with non-negligible probability is true for all efficient algorithms, then we say that the discrete log problem is hard in this group G. So, we have a couple of candidate examples for groups where discrete log is hard:\n",
    "- The canonical example is ${Z_{p}}^{*}$ , this is actually the example that Diffie and Hellman came up with in 1974.\n",
    "- It turns out there are other candidate groups where the discrete log problem happens to be hard, that is the elliptic curve group, or rather, the set of points on an elliptic curve.\n",
    "\n",
    "**Discrete Log:  ${Z_{p}}^{*}$ vs Elliptic Curve**\n",
    "\n",
    "It so happens that the discrete log problem actually is harder, as far as we know, on elliptic curves than it is on  ${Z_{p}}^{*}$. In other words, if you give me equal-sized problems, one set in the group  ${Z_{p}}^{*}$, and one set in an elliptic curve group, the problem set in the elliptic curve group is going to be much harder than the problem in  ${Z_{p}}^{*}$. And because the elliptic curve problem, the discrete log elliptic curve problem is harder, this means that we can use smaller parameters, that is, smaller n-bit prime p, when using elliptic curves than we can for  ${Z_{p}}^{*}$, and as a result, the resulting systems with elliptic curves are going to be more efficient, because the parameters are smaller, and yet the attacker's job is as hard as for a much larger prime in  ${Z_{p}}^{*}$.\n",
    "\n",
    "![](./Images/NT-ZpStarVsElliptic.png)\n",
    "\n",
    "So to make that concrete, as we have seen earlier as wee, in ${Z_{p}}^{*}$ there's what's called a sub-exponential algorithm for discrete log called General Number Field Sieve (GNFS). Therefore, if we have an n-bit prime, this algorithm will run in roughly exponential  $e^{O(\\sqrt[3]{n})}$. In fact there are many other terms in the exact running time of this algorithm, but the dominant term is cube root of the number of bits in the prime, so $\\sqrt[3]{n}$. \n",
    "\n",
    "Because of this algorithm, if we want the discrete log problem to be hard, as hard as it is to break a corresponding symmetric key, we have to use relatively large modulo p in context of  ${Z_{p}}^{*}$. Now in contrast, if you look at an elliptic curve group, the numbers look much better, and in fact on an elliptic curve group, the best algorithm for discrete log that we have runs in time $2^{n/2}$. Hence, this is what we would call a proper exponential-time algorithm, because for a problem of size n, the running time is roughly 2 to the n. It's an exponential in n, not an exponential in cube root of n. And because the problem is so much harder, again the best algorithm we have actually takes exponential time, therefore in elliptic curves we can use much smaller parameters and still remain secure.\n",
    "\n",
    "**Intractable Problems: Modulo Composites**\n",
    "\n",
    "![](./Images/NT-IntracProb-Composites.png)\n",
    "Description:<br>\n",
    "So let's define the set $Z_{2}$(n). This is going to be the set of all integers N, that happen to be a product of two primes p and q, where those two primes are n-bit primes. So the 2 in $Z_{2}$(n) corresponds to the fact that the numbers in this set basically have 2 prime factors, and those two prime factors are roughly the same size. They're both n-bit primes.<br> Now, there are two classic intractable problems in this set:\n",
    "\n",
    "- First problem is: if I choose a random integer in the set $Z_{2}$(n), the problem is, to factor it. And already this is quite a difficult problem for 1024 bits. And although it hasn't been done yet, it's very likely that numbers of this magnitude will be factored soon, and so the recommended value these days is actually to use 2048-bit numbers. That's still beyond our reach, and those are numbers that we still cannot factor.<br><br>\n",
    "- Second intractable problem modulo composites is: if I give you some polynomial that's nonlinear, if the degree is bigger than 1, and I give you some random composite in the set $Z_{2}$(n), your goal is to find a root of this polynomial, find an x that happens to be a root of this polynomial. And again, we don't know how to do that; of course if the degree is equal to 1, that just amounts to solving linear equations, and we already know that, that's easy. But the minute the degree becomes nonlinear, **we don't know how to solve a non-linear polynomial, not even quadratic, in modulo N without actually first factoring the modulus, hence reducing it to first problem which is already hard, and then computing roots**.<br>\n",
    "Note: So there are some systems, for example RSA, that depend on the hardness of this particular problem for specific polynomials, which we're going to see later.\n",
    "\n",
    "There's actually quite a bit known about the factoring problem. It's actually a very old problem. Already the Greeks were interested in factoring, but Gauss actually has a wonderful, wonderful quote that talks about the problem of factoring and the problem of primality testing (testing if the number is prime or not).\n",
    "![](./Images/NT-FactoringProb.png)\n",
    "So, in fact, testing if a number is prime has been completely solved; we now know completely how to do it, using, efficiently using a randomized algorithm, and we even know how to do it using a deterministic algorithm. Factoring numbers, factoring composites into their prime factors, is still believed to be a difficult problem. For factoring, as we saw, the state of the art Algorithm we have is General Number Field Sieve (NFS) which runs in $e^{O(\\sqrt[3]{n})}$, it's sub-exponential and not truly exponential in nature which is why the composite n has to be quite large for the problem to be difficult. \n",
    "\n",
    "The current world record is really just factoring a 768-bit number. This is called the RSA-768 number, it's a challenge number that was recently factored. The number is about 200 digits, and already factoring this number took an enormous amount of work. It took about two years on hundreds of machines, and finally they were able to factor this number. And the estimate is that actually factoring a 1024-bit number is about 1000 times harder than factoring RSA-768, so instead of 2 years, it would take two thousand years. But of course computers are getting faster, we have more cores at our disposal, we have more computers, and so this factor of 1000, assuming Moore's Law and so on, really just means a decade, as computers get faster by about a factor of 1000 every decade, so it's very likely that within the next decade, we'll see a factorization of a 1024-bit number, which would be the end of 1024 bits being used for public-key cryptography. \n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Asymmetric-Key/Public-Key Cryptosystems\n",
    "We have already seen the Formal definition and Semantic Security of Public-Key Encryption as well as its relationship to symmetric cipher security, under the Key Exchange section. Therefore, please refer to [Public-Key Encryption](#Public-Key-Encryption) section before continuing this section. . \n",
    "\n",
    "While public-key encryption has many applications. Lets look at few applications of Public-Key Encryption:\n",
    "![](./Images/PKEnc-Application.png)\n",
    "Session Setup: It is basically key-exchange as we have seen earlier how public-key encryption key exchange protocol works.<br>\n",
    "Non-interactive Applications: Public key encryption is very useful in non-interactive applications. Take email system for example:\n",
    "- Bob wants to send mail to Alice, and as Bob sends the email, the email passes from mail relay to mail relay until finally it reaches Alice, at which point Alice should decrypt. The way the email system is set up is, its designed for kind of non-interactive settings where Bob sends the email then Alice is supposed to receive it. And Alice should not have the need to communicate with Bob in order to decrypt the email because due the non-interactivity setting there's no opportunity for setting up a shared secret between Alice and Bob. \n",
    "- Therefore in such a case, what would happen is, Bob basically would send the email encrypted, using Alice's public key. So he or anyone in the world can send the email to Alice, encrypted using her public key. When Alice receives this email, she uses her secret key to decrypt the ciphertext and recover the plain text message.\n",
    "- Of course the one caveat in a system like this is that in fact Bob needs to somehow obtain Alice's public key. So for now we are just going to assume Bob already has Alice's public key, but later on, actually, when we talk about Digital Signatures we're gonna see how this can actually be done very efficiently using what's called public key management."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
