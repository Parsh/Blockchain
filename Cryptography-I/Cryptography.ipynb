{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cryptography\n",
    "A Quality Read: [Crypto-IT](http://www.crypto-it.net/eng/index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Cryptography\n",
    "\n",
    "**What is cryptography?**\n",
    "> **Cryptography** is the practice and study of techniques for secure communication in the presence of third parties called adversaries. More generally, cryptography is about constructing and analyzing protocols that prevent third parties or the public from reading private messages; various aspects in information security such as **data confidentiality**, **data integrity**, **authentication**, and **non-repudiation** are central to modern cryptography. Modern cryptography exists at the intersection of the disciplines of mathematics, computer science, electrical engineering, communication science, and physics. Applications of cryptography include electronic commerce, chip-based payment cards, digital currencies, computer passwords, and military communications.\n",
    "\n",
    "Cryptography prior to the modern age was effectively synonymous with encryption, the conversion of information from a readable state to apparent nonsense. The originator of an encrypted message shared the decoding technique needed to recover the original information only with intended recipients, thereby precluding unwanted persons from doing the same. The cryptography literature often uses the name Alice (\"A\") for the sender, Bob (\"B\") for the intended recipient, and Eve (\"eavesdropper\") for the adversary. \n",
    "\n",
    "**History of Cryptography:**\n",
    "- Refer to the History segment inside the following PDF: Blockchain/CryptographyI/LectureSlides/Week1/Introduction.pdf\n",
    "- [History of Cryptography](https://www.tutorialspoint.com/cryptography/origin_of_cryptography.htm)\n",
    "\n",
    "**Modern Cryptography:**\n",
    ">Modern cryptography is heavily based on mathematical theory and computer science practice; **cryptographic algorithms are designed around computational hardness assumptions**, making such algorithms hard to break in practice by any adversary. It is theoretically possible to break such a system, but it is infeasible to do so by any known practical means. These schemes are therefore termed computationally secure; theoretical advances, e.g., improvements in integer factorization algorithms, and faster computing technology require these solutions to be continually adapted. There exist **information-theoretically secure** schemes that probably cannot be broken even with unlimited computing power—an example is the one-time pad—but these schemes are more difficult to implement than the best theoretically breakable but computationally secure mechanisms.\n",
    "\n",
    "More on: [Modern Cryptography](https://www.tutorialspoint.com/cryptography/modern_cryptography.htm)\n",
    "\n",
    "**Cryptology:**<br>\n",
    "The art of devising ciphers (i.e cryptography) and breaking them i.e., cryptanalysis) is collectively known as cryptology.\n",
    "\n",
    "**Cryptanalysis:**<br>\n",
    "Cryptanalysis is the study of analyzing information systems in order to study the hidden aspects of the systems. Cryptanalysis is used to breach cryptographic security systems and gain access to the contents of encrypted messages, even if the cryptographic key is unknown.\n",
    "\n",
    "In addition to mathematical analysis of cryptographic algorithms, cryptanalysis includes the study of side-channel attacks that do not target weaknesses in the cryptographic algorithms themselves, but instead exploit weaknesses in their implementation.\n",
    "\n",
    ">Cryptanalysis is the sister branch of Cryptography and they both co-exist. The cryptographic process results in the cipher text for transmission or storage. It involves the study of cryptographic mechanism with the intention to break them. Cryptanalysis is also used during the design of the new cryptographic techniques to test their security strengths.\n",
    "\n",
    "**Kerckhoffs's Principle (also called Open Design or Shannon Maxim):**<br>\n",
    ">Kerckhoffs's principle is one of the basic principles of modern cryptography. It was formulated in the end of the nineteenth century by Dutch cryptographer Auguste Kerckhoffs. The principle goes as follows: **A cryptographic system should be secure even if everything about the system, except the key, is public knowledge**. Basically, it implies that the attacker knows the cryptographic system, i.e., the encryption and decryption schemes and security relies on the secrecy of keys.\n",
    "\n",
    "More on [Kerckhoffs's Principle](http://www.crypto-it.net/eng/theory/kerckhoffs.html).\n",
    "\n",
    "**Steganography:**<br>\n",
    "Steganography is the practice of concealing/hiding a file, message, image, or video within another file, message, image, or video. Steganography works on the principle of **Security by Obscurity** (which is contrary to Kerckhoff's Principle).\n",
    "\n",
    "### Security Services of Cryptography\n",
    "\n",
    "The primary objective of using cryptography is to provide the following **four fundamental information security services:**\n",
    "\n",
    "**Confidentiality**\n",
    "\n",
    "Confidentiality is the fundamental security service provided by cryptography. It is a security service that keeps the information from an unauthorized person. It is sometimes referred to as privacy or secrecy. \n",
    "\n",
    "Confidentiality can be achieved through numerous means starting from physically securing to the use of mathematical algorithms for data encryption.\n",
    "\n",
    "**Data Integrity**\n",
    "\n",
    "It is security service that deals with identifying any alteration to the data. The data may get modified by an unauthorized entity intentionally or accidentally. Integrity service confirms that whether data is intact or not since it was last created, transmitted, or stored by an authorized user.\n",
    "\n",
    "Data integrity cannot prevent the alteration of data, but provides a means for detecting whether data has been manipulated in an unauthorized manner.\n",
    "\n",
    "**Authentication**\n",
    "\n",
    "Authentication provides the identification of the originator. It confirms to the receiver that the data received has been sent only by an identified and verified sender.\n",
    "\n",
    ">Authentication service has two variants:\n",
    "- Message authentication identifies the originator of the message without any regard router or system that has sent the message.\n",
    "- Entity authentication is assurance that data has been received from a specific entity, say a particular website.\n",
    "\n",
    "Apart from the originator, authentication may also provide assurance about other parameters related to data such as the date and time of creation/transmission.\n",
    "\n",
    "**Non-repudiation**\n",
    "\n",
    "It is a security service that ensures that an entity cannot refuse the ownership of a previous commitment or an action. It is an assurance that the original creator of the data cannot deny the creation or transmission of the said data to a recipient or third party.\n",
    "\n",
    "Non-repudiation is a property that is most desirable in situations where there are chances of a dispute over the exchange of data. For example, once an order is placed electronically, a purchaser cannot deny the purchase order, if non-repudiation service was enabled in this transaction.\n",
    "\n",
    "### Cryptography Primitives\n",
    "\n",
    "Cryptographic primitives are well-established, low-level cryptographic algorithms that are frequently used to build cryptographic protocols for computer security systems. Alternatively, cryptography primitives can be defined as the tools and techniques in Cryptography that can be selectively used to provide a set of desired security services. \n",
    "\n",
    "Following are some cryptography primitives:\n",
    "- Encryption\n",
    "- Hash functions\n",
    "- Message Authentication codes (MAC)\n",
    "- Digital Signatures\n",
    "\n",
    "When creating cryptographic systems, designers use cryptographic primitives as their most basic building blocks. Because of this, cryptographic primitives are designed to do one very specific task in a highly reliable fashion.\n",
    "\n",
    "\n",
    "The following table shows the primitives that can achieve a particular security service on their own.\n",
    "\n",
    "![](./Images/CryptoPrimitives.png \"Crypto Primitives and thier corresponding security service\")\n",
    "\n",
    "Note: Cryptographic primitives are intricately related and they are often combined to achieve a set of desired security services from a cryptosystem.\n",
    "\n",
    "### The three fundamental steps in cryptography:\n",
    ">When we introduce/devise a new primitive these 3 steps have to be rigorously followed:\n",
    "1. **Precisely specify threat model:** Threat model basically is knowing the capabilities of the adversaries, i.e., what can an adversarial do to attack the primitive and what is his goal in forging the primitive. In order to show that the primitive or cryptographic protocol is secure we need to prove that an adversary with the following capabilities would not be able to break the primitive/protocol. More on [Threat Model](https://www.youtube.com/watch?v=f4tk2pnOUos)\n",
    "2. **Propose a construction**\n",
    "3. **Prove that breaking construction under threat model will solve an underlying hard problem**: A basic example would be, it is easy to multiply to large prime to get a value N, but it's hard to recover the factors given the value N. So, if our prime works on that concept than if an adversary breaks our primitive/protocol than it would land a solution to solving that hard problem.\n",
    "\n",
    "**Key Note:** For production system usage, never ever use your own implementation of the primitive or any cryptographic algorithm (as aside from the implementation errors there could be many side channels which could potentially result in easy breaching of your implementation). It is always recommended to use a trusted library for applying ciphering to production level data/information. [Explanatory Video](https://www.youtube.com/watch?v=3Re5xlEjC8w)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crash Course on Discrete Probability\n",
    "\n",
    "Why Discrete Probability?\n",
    "> Over the years many natural cryptographic constructions were found to be insecure. In response, modern cryptography was developed as a rigorous science where constructions are always accompanied by a proof of security. The language used to describe security relies on discreet probability.<br>\n",
    "\n",
    "Reference Reads: \n",
    "- **Highly recommended (Easy to Digest and Preferable read to get it all):** [Discrete Probability](https://en.wikibooks.org/wiki/High_School_Mathematics_Extensions/Discrete_Probability)\n",
    "-  Refer to the Discrete Probability Crash Course segment inside the following PDF: Blockchain/CryptographyI/LectureNotes/Week1/Introduction.pdf\n",
    "- [Discrete vs Continuous Random Variables](http://www.henry.k12.ga.us/ugh/apstat/chapternotes/7supplement.html)\n",
    "- [Random Variable vs Events](https://www.quora.com/What-is-the-difference-between-an-event-and-a-random-variable)\n",
    "\n",
    "Reference Videos: \n",
    "- [Discrete Probability Crash Course [Part 1]](https://www.coursera.org/learn/crypto/lecture/qaEcL/discrete-probability-crash-course)\n",
    "- [Discrete Probability Crash Course [Part 2]](https://www.coursera.org/learn/crypto/lecture/JkDRg/discrete-probability-crash-course-cont)\n",
    "- [Probability Distribution for Random Variable X](https://www.youtube.com/watch?v=cqK3uRoPtk0)\n",
    "\n",
    "**Deterministic vs Randomized Algorithms:**\n",
    "> It's due to Discrete Probability that cryptographic algorithms took a leap from being deterministic, producing same output for a given input each time, in nature to being randomized algorithms that we use today. <br><br>\n",
    ">**Randomized Algorithms:** are those which produce different outputs given the same input, i.e., even though the input to the randomized algorithm is the same, it will produce different output each time, as Random Algorithm have an implicit argument, say r, which is sampled anew, from it's give universe, every time the algorithm is run therefore making the outcome different.<br><br>\n",
    "The output of this Random Algorithm is basically a random variable which is a distribution over the set of all possible encryption of message m under a  uniform key r.\n",
    "\n",
    "More on Randomized Algorithm: Refer to the Randomized Algorithms topic undert Discrete Probability segment inside the following PDF: Blockchain/CryptographyI/LectureNotes/Week1/Introduction.pdf\n",
    "\n",
    "**XOR:**\n",
    "XOR is very important when it comes to cryptography. Review: XOR of two bit string is their bitwise addition mod 2. Also, something XORed with itself yields zeros => x XOR x = 0.\n",
    "[Why XOR is imp in cryptography?](https://www.quora.com/Why-is-XOR-important-in-cryptography).\n",
    "\n",
    "![](./Images/XOR-Property.png \"The Important Property of XOR\")\n",
    "\n",
    "Note: Review the following video [Discrete Probability Crash Course [Part 2]](https://www.coursera.org/learn/crypto/lecture/JkDRg/discrete-probability-crash-course-cont), watch it from 6:19 where description of the important property of XOR is explained which makes it so useful in cryptography.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cryptosystems\n",
    "\n",
    "A cryptosystem is an implementation of cryptographic techniques and their accompanying infrastructure to provide information security services. A cryptosystem is also referred to as a cipher system.\n",
    "\n",
    "### Components of a Cryptosystem\n",
    "\n",
    "The various components of a basic cryptosystem are as follows:\n",
    "\n",
    "- **Plaintext:** It is the data to be protected during transmission.\n",
    "\n",
    "- **Encryption Algorithm:** It is a mathematical process that produces a ciphertext for any given plaintext and encryption key. It is a cryptographic algorithm that takes plaintext and an encryption key as input and produces a ciphertext.\n",
    "\n",
    "- **Ciphertext:** It is the scrambled version of the plaintext produced by the encryption algorithm using a specific the encryption key. The ciphertext is not guarded. It flows on public channel. It can be intercepted or compromised by anyone who has access to the communication channel.\n",
    "\n",
    "- **Decryption Algorithm:** It is a mathematical process, that produces a unique plaintext for any given ciphertext and decryption key. It is a cryptographic algorithm that takes a ciphertext and a decryption key as input, and outputs a plaintext. The decryption algorithm essentially reverses the encryption algorithm and is thus closely related to it.\n",
    "\n",
    "- **Encryption Key:** It is a value that is known to the sender. The sender inputs the encryption key into the encryption algorithm along with the plaintext in order to compute the ciphertext.\n",
    "\n",
    "- **Decryption Key:** It is a value that is known to the receiver. The decryption key is related to the encryption key, but is not always identical to it. The receiver inputs the decryption key into the decryption algorithm along with the ciphertext in order to compute the plaintext.\n",
    "\n",
    "For a given cryptosystem, a collection of all possible decryption keys is called a **key space**.\n",
    "\n",
    "An interceptor (an attacker) is an unauthorized entity who attempts to determine the plaintext. He can see the ciphertext and may know the decryption algorithm. He, however, must never know the decryption key.\n",
    "\n",
    "### Types of Cryptosystems\n",
    "Fundamentally, there are two types of cryptosystems based on the manner in which encryption-decryption is carried out in the system:\n",
    "\n",
    "- Symmetric Key Cryptosystems\n",
    "- Asymmetric Key Cryptosystems\n",
    "\n",
    "The main difference between these cryptosystems is the relationship between the encryption and the decryption key. Logically, in any cryptosystem, both the keys are closely associated. It is practically impossible to decrypt the ciphertext with the key that is unrelated to the encryption key.\n",
    "\n",
    "### Cryptographic Attacks\n",
    "The basic intention of an attacker is to break a cryptosystem and to find the plaintext from the ciphertext. To obtain the plaintext, the attacker only needs to find out the secret decryption key, as the algorithm is already in public domain.\n",
    "\n",
    "Hence, he applies maximum effort towards finding out the secret key used in the cryptosystem. Once the attacker is able to determine the key, the attacked system is considered as broken or compromised.\n",
    "\n",
    "Based on the methodology used, attacks on cryptosystems are categorized as follows:\n",
    "\n",
    "- **Ciphertext Only Attacks (COA):** In this method, the attacker has access to a set of ciphertext(s). He does not have access to corresponding plaintext. COA is said to be successful when the corresponding plaintext can be determined from a given set of ciphertext. Occasionally, the encryption key can be determined from this attack. Modern cryptosystems are guarded against ciphertext-only attacks.<br><br>\n",
    "\n",
    "- **Known Plaintext Attack (KPA):** In this method, the attacker knows the plaintext for some parts of the ciphertext. The task is to decrypt the rest of the ciphertext using this information. This may be done by determining the key or via some other method. The best example of this attack is linear cryptanalysis against block ciphers.<br><br>\n",
    "\n",
    "- **Chosen Plaintext Attack (CPA):** In this method, the attacker has the text of his choice encrypted. So he has the ciphertext-plaintext pair of his choice. This simplifies his task of determining the encryption key. An example of this attack is differential cryptanalysis applied against block ciphers as well as hash functions. A popular public key cryptosystem, RSA is also vulnerable to chosen-plaintext attacks.<br><br>\n",
    "\n",
    "- **Dictionary Attack:** This attack has many variants, all of which involve compiling a ‘dictionary’. In simplest method of this attack, attacker builds a dictionary of ciphertexts and corresponding plaintexts that he has learnt over a period of time. In future, when an attacker gets the ciphertext, he refers the dictionary to find the corresponding plaintext.<br><br>\n",
    "\n",
    "- **Brute Force Attack/Extensive Search:** In this method, the attacker tries to determine the key by attempting all possible keys. If the key is 8 bits long, then the number of possible keys is 28 = 256. The attacker knows the ciphertext and the algorithm, now he attempts all the 256 keys one by one for decryption. The time to complete the attack would be very high if the key is long.<br><br>\n",
    "\n",
    "- **Birthday Attack:** This attack is a variant of brute-force technique. It is used against the cryptographic hash function. When students in a class are asked about their birthdays, the answer is one of the possible 365 dates. Let us assume the first student's birthdate is 3rd Aug. Then to find the next student whose birthdate is 3rd Aug, we need to enquire 1.25*√365 ≈ 25 students. <br><br> Similarly, if the hash function produces 64 bit hash values, the possible hash values are 1.8x10^19. By repeatedly evaluating the function for different inputs, the same output is expected to be obtained after about 5.1x10^9 random inputs. If the attacker is able to find two different inputs that give the same hash value, it is a collision and that hash function is said to be broken.<br><br>\n",
    "\n",
    "- **Man in Middle Attack (MIM):**  The targets of this attack are mostly public key cryptosystems where key exchange is involved before communication takes place.\n",
    "    - Host A wants to communicate to host B, hence requests public key of B.\n",
    "    - An attacker intercepts this request and sends his public key instead.\n",
    "    - Thus, whatever host A sends to host B, the attacker is able to read.\n",
    "    - In order to maintain communication, the attacker re-encrypts the data after reading with his public key and sends to B.\n",
    "    - The attacker sends his public key as A’s public key so that B takes it as if it is taking it from A.<br><br>\n",
    "\n",
    "- **Side Channel Attack (SCA):** This type of attack is not against any particular type of cryptosystem or algorithm. Instead, it is launched to exploit the weakness in physical implementation of the cryptosystem. They map things like the time taken for encryption or the power consumed during encryption to deduce the key.<br><br>\n",
    "\n",
    "- **Timing Attacks:** They exploit the fact that different computations take different times to compute on processor. By measuring such timings, it is be possible to know about a particular computation the processor is carrying out. For example, if the encryption takes a longer time, it indicates that the secret key is long.<br><br>\n",
    "\n",
    "- **Power Analysis Attacks:** These attacks are similar to timing attacks except that the amount of power consumption is used to obtain information about the nature of the underlying computations.<br><br>\n",
    "\n",
    "- **Fault analysis Attacks:** In these attacks, errors are induced in the cryptosystem and the attacker studies the resulting output for useful information.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Symmetric Key Cryptosystems\n",
    "\n",
    "The encryption process where **same keys are used for encrypting and decrypting** the information is known as Symmetric Key Encryption. The study of symmetric cryptosystems is referred to as symmetric cryptography. Symmetric cryptosystems are also sometimes referred to as **secret key cryptosystems**.\n",
    "\n",
    "A few well-known examples of symmetric key encryption methods are: Digital Encryption Standard (DES), Triple-DES (3-DES), IDEA, RC4, eStreams and BLOWFISH.\n",
    "![](./Images/SymmetricEncryption.png)\n",
    "\n",
    "\n",
    "**Crypto Lesson:** In a symmetric cryptosystem, you should never use a single shared key to encrypt data/information in both direction i.e. traffic from Client(C) to Sever(S) should not be encrypted with the same key as used for encrypting the traffic from Server to Client. Hence, the shared key should be a pair of keys => $K_{shared}$ = {$K_{C>>S}$, $K_{S>>C}$} where prior is used to encrypt/decrypt the information from client to server and the latter from server to client.\n",
    "\n",
    "**Symmetric Ciphers:**\n",
    "![](./Images/SymmetricCipherDef.png )\n",
    "\n",
    "**Type of symmetric ciphers:**<br>\n",
    "An important distinction in symmetric cryptographic algorithms is between stream and block ciphers. \n",
    "- **[Stream ciphers](#Stream-Ciphers)** convert one symbol of plaintext directly into a symbol of ciphertext. \n",
    "- **[Block ciphers](#Block-Ciphers)** encrypt a group of plaintext symbols as one block. \n",
    "\n",
    "\n",
    "Prior to 1970, all cryptosystems employed symmetric key encryption. Even today, its relevance is very high and it is being used extensively in many cryptosystems. It is very unlikely that this encryption will fade away, as it has certain advantages over asymmetric key encryption.\n",
    "\n",
    "The **salient features of cryptosystem based on symmetric key encryption** are:\n",
    "- Persons using symmetric key encryption must share a common key prior to exchange of information.\n",
    "- Keys are recommended to be changed regularly to prevent any attack on the system.\n",
    "- A robust mechanism needs to exist to exchange the key between the communicating parties. As keys are required to be changed regularly, this mechanism becomes expensive and cumbersome.\n",
    "- In a group of n people, to enable two-party communication between any two persons, the number of keys required for group is $\\frac{n\\times (n-1)}{2}$.\n",
    "- Length of Key (number of bits) in this encryption is smaller and hence, process of encryption-decryption is faster than asymmetric key encryption.\n",
    "- Processing power of computer system required to run symmetric algorithm is less.\n",
    "\n",
    "**Challenge of Symmetric Key Cryptosystem**<br>\n",
    "There are two restrictive challenges of employing symmetric key cryptography:\n",
    "\n",
    "- **Key establishment:** Before any communication, both the sender and the receiver need to agree on a secret symmetric key. It requires a secure key establishment mechanism in place.\n",
    "\n",
    "- **Trust Issue:** Since the sender and the receiver use the same symmetric key, there is an implicit requirement that the sender and the receiver ‘trust’ each other. For example, it may happen that the receiver has lost the key to an attacker and the sender is not informed.\n",
    "\n",
    "These two challenges are highly restraining for modern day communication. Today, people need to exchange information with non-familiar and non-trusted parties. For example, a communication between online seller and customer. These limitations of symmetric key encryption gave rise to **asymmetric key encryption** schemes.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Time Pad and Information Theoretic Security: \n",
    "Short Intuitive Description: [One Time Pad](https://www.khanacademy.org/computing/computer-science/cryptography/crypt/v/one-time-pad \"by Khan Academy\")<br>\n",
    "Recommended Watch: [One Time Pad and Information Theoretic Security](https://www.coursera.org/learn/crypto/lecture/cbnX1/information-theoretic-security-and-the-one-time-pad \"by Coursera: Cryptography I\") <br>\n",
    "Go through the One Time Pad section in: Blockchain/CryptographyI/LectureSlides/Week1/StreamCiphers.pdf\n",
    "\n",
    "One-time pad (OTP), also called Vernam-cipher or the perfect cipher, is a crypto algorithm where plaintext is combined with a random key (where the random key is a uniform random variable from a key space K, i.e., selection of any key from K has equal uniform/equal probability). It is the only existing mathematically unbreakable encryption and is a symmetric cipher.\n",
    "\n",
    ">The one-time pad (OTP) is an encryption technique that cannot be cracked, but requires the use of a one-time pre-shared key the same size as, or longer than, the message being sent. In this technique, a plaintext is paired with a random secret key (also referred to as a one-time pad). Then, each bit or character of the plaintext is encrypted by combining it with the corresponding bit or character from the pad using modular addition. If the key is truly random, is at least as long as the plaintext, is never reused in whole or in part, and is kept completely secret, then the resulting ciphertext will be impossible to decrypt or break.\n",
    "\n",
    ">Even infinite computational power and infinite time cannot break one-time pad encryption, simply because it is mathematically impossible. However, if only one of these rules is disregarded, the cipher is no longer unbreakable.\n",
    "- The key is at least as long as the message or data that must be encrypted.\n",
    "- The key is truly random (not generated by a simple computer function or such)\n",
    "- Key and plaintext are calculated modulo 10 (digits), modulo 26 (letters) or modulo 2 (binary)\n",
    "- Each key is used only once (that's why we call it **One Time Pad**), and both sender and receiver must destroy their key after use. If the same key is used twice, the security will be compromised.\n",
    "- There should only be two copies of the key: one for the sender and one for the receiver (some exceptions exist for multiple receivers)\n",
    "\n",
    "**Perfect Secrecy:** Perfect secrecy is the notion that, given an encrypted message (or ciphertext) from a perfectly secure encryption system (or cipher), absolutely nothing will be revealed about the unencrypted message (or plaintext) by the ciphertext i.e. perfect secrecy could be defined as having an absolute immunity to Cipher text only attacks. <br>\n",
    "\n",
    "How One Time Pad has perfect secrecy?\n",
    ">Shannon proved in 1949 that One Time Pad has perfect secrecy due to uniform probability distribution of all mssgs (of same length) that could have resulted in the cipher text c (that adversary might have hold to) with the key k (of same length). That means, given a cipher text c (generated using a key k of length n) the probability of all the possible message, of length n, to be encrypted to that c is uniform/equal. Hence, c is equally probable of being an encryption of $m_{1}$, $m_{2}$ ...$m_{xyz}$. While there exist only single key that maps m to c (given as k = m XOR c).\n",
    "\n",
    "**Pitfalls:** \n",
    "- One Time Pad though have a perfect secrecy but it still is largely impractical to implement (because of the length of key being equal to that of the message, and if we even found a way to secretly transfer message-long key then it would be a better approach to use that transfer mechanism to secretly transfer the message at the first place).\n",
    "- Thought it is secure to Cipher Text only attacks, but it is vulnerable to other forms of attacks.\n",
    "\n",
    "**Bad News:** Shannon who proved that the OTP has the perfect secrecy later proved a theorem that states: **\"To have perfect secrecy the key size must always be greater than or equal to the size of the message\"**. Hence, ciphers that use keys smaller in size than the messages don't have perfect secrecy. \n",
    "Why? Because if the size of key (say n) is smaller than the message size (m), then the universe of keys (all possible keys of length n) would not have enough unique keys for encrypting each message in the universe of message (containing all the messages of of length m). And therefore we will end up using keys multiple times (at least twice) which breaks the perfect secrecy (Attack 1).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stream Ciphers\n",
    "\n",
    "**Question:** How to make a cipher that, if not have a perfect secrecy but still provides acceptable levels of security (i.e. how to make OTP practical)?\n",
    ">**Solution:** Replace the random keys (of length equal or greater than the message) with psuedorandom keys (smaller length keys). These psuedorandom keys are generated using a **PRG (Psuedo Random Generator)** which is basically a function that takes in a seed space (initial key space, say $[0,1]^{s}$) and expand it to $[0,1]^{n}$ such that n>>s. And it is out of this inflated space a key is chosen at random. Ciphers using PRG are referred to as Stream Ciphers and they also maintain the aspect of using the psuedorandom key only to pad one mssg and not multiple messages.\n",
    "\n",
    "![](./Images/PRG.png \"Generator  G expands the key space and chose a key, which is psuedorandom in nature, at random from it to XOR with the message\")\n",
    "Note: PRG should be efficiently computable by a deterministic algorithm. The key, from the space G(k), XORed with mssg is a psuedorandom pad and not a truly random pad.\n",
    "\n",
    "**Stream Cipher:** A stream cipher is a symmetric key cipher where plaintext digits are combined with a pseudorandom cipher digit stream (keystream). In a stream cipher, each plaintext digit is encrypted one at a time with the corresponding digit of the keystream, to give a digit of the ciphertext stream. Since encryption of each digit is dependent on the current state of the cipher, it is also known as state cipher. In practice, a digit is typically a bit and the combining operation an exclusive-or (XOR).<br>\n",
    "Note: Stream ciphers convert one symbol of plaintext directly into a symbol of ciphertext.\n",
    "\n",
    "**Redefining Security:**<br>\n",
    "**Stream ciphers cannot have perfect secrecy!!** Therefore, we need to rethink how we define security as perfect secrecy is not practically feasible. So:\n",
    "- Need a different definition of security\n",
    "- Security will depend on specific PRG >> [Security Definition](#PRG-Security-Definition)\n",
    "\n",
    "**Fundamental Requirement to secure Stream Ciphers:**<br>\n",
    "A minimal property that a psuedo random generator must have is property of being unpredictable, i.e., **PRG must be unpredictable**. Therefore, for a stream cipher to be secure, at it's minimum, the PRG it uses must be unpredictable in nature.\n",
    "\n",
    "What it mean to be unpredictable for a generator is that given first few bits of the output of the generator (which is the psuedorandom key), say 1...i bits, there is no efficient algorithm that can compute the rest, i+1...n, bits of the stream.\n",
    "\n",
    "**Attacks on One Time Pad/Stream ciphers:**\n",
    "- Attack 1: **Two time pad is insecure**, i.e., if we used the same key (or psuedorandom key) to pad two different messages(m1 and m2) and produce c1 and c2 cipher texts then for an adversary who captured both of those cipher texts, it's fairly easy to recover both m1 and m2 using the CT only attack. Hence a Stream Cipher key or a One Time Pad key should never, never ever, be used more than once.\n",
    "![](./Images/TwoTimePad.png)\n",
    "<br>\n",
    "- Attack 2: One Time Pad or the Stream Ciphers in general provides **no integrity** at all (all they do is try to provide confidentiality when the key is only used once) and therefore are referred as malleables.\n",
    "![](./Images/MalleableOTP.png)\n",
    "\n",
    "Real World Examples:<br>\n",
    "- **Old Stream Ciphers:** RC4, CSS etc.\n",
    "- **Modern Stream Ciphers:** eStream project (qualify 5 Stream ciphers), Modern stream cipher in addition to seed uses nonce which is a non-repeating value for a given key. Hence, we can reuse a key because the nonce make the (k, r) pair unique.\n",
    "![](./Images/ModernStreamCiphers.png)\n",
    "\n",
    "---\n",
    "\n",
    "### PRG Security Definition\n",
    "Recommended Watch: [PRG Security](https://www.coursera.org/learn/crypto/lecture/De10M/prg-security-definitions)\n",
    "\n",
    "Security of a Stream Cipher depends on how secure is the Psuedo Random Generator it uses is. In turn the the PRG is regarded as secure if the output of the PRG is **indistinguishable from the truly random output.** That is, the distribution of pseudo random is indistinguishable from a truly (random) uniform distribution.\n",
    "\n",
    "![](./Images/IndistinguishablePRG.png)\n",
    ">Goal: To show that the psuedorandom output G(k), where k is a random variable from (seed)K = {0, 1}$^{s}$ and G(k) is the psuedorandom output from the expanded space, {0 , 1}$^n$, of the seed is indistinguishable from truly random r selected from a key space of {0, 1}$^n$ (not an expansion space).\n",
    "\n",
    "How to show this indistinguishability from random? : Using **Statistical Test**<br>\n",
    "\n",
    "**Statistical Test:**\n",
    "Let's define what is a Statistical test on space {0, 1}$^{n}$:<br>\n",
    "It's basically an algorithm (A) such that:\n",
    "- A takes and input x (which is an n bit string) and \n",
    "- Outputs 0 (means input don't seem random) and 1 (means the input seems to be random)\n",
    "\n",
    "One can think of any number of statistical tests, therefore, while considering indistinguishability we only account for efficient statistical tests.\n",
    "\n",
    "A statistical test uses the concept of Advantage over a PRG to determine that whether it could distinguish the psuedorandom input from a truly random or not. Following image shows the formulation for calculation of Advantage of a given Statistical test A over a generator PRG.\n",
    "![](./Images/Advantage-ST.png \"G(k) is psuedorandom and r is truly random; Pr abbriviation for probability\")\n",
    "Note: We only want to consider the advantage of efficient statistical test for the generator PRG (we don't give a damn about inefficient ones). Also, we want the advantage to be negligible, i.e., a close to zero as possible (which indicates the statistical test wasn't able to distinguish).\n",
    "\n",
    "Hence, crypto definition for a secure PRG is as follows:\n",
    "![](./Images/SecurePRGs.png)\n",
    "Note: Efficient algo (statistical test) theoretical means that finishes in polynomial time and practically could be regarded as one which finishes in a given time.\n",
    "\n",
    "**Secure PRG is an unpredictable generator and vice versa**\n",
    "\n",
    "A secure PRG implies: It's unpredictable (which covers the minimal requirement for a secure PRG). \n",
    "![](./Images/SecureMeanUnpredict.png)\n",
    "\n",
    "Also, there exist a theorem that proved that: an unpredictable generator is secure in nature.\n",
    "![](./Images/UnpredictMeanSecure.png)\n",
    "\n",
    "**General Representation:**\n",
    "![](./Images/GeneralSecure.png)\n",
    "Note: For Stream Cipher, $P_{1}$ is G(K) [psuedorandom distribution] and $P_{2}$ is a truly random distribution\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semantic Security\n",
    "\n",
    "Recall: Shannon's idea of security: CT should not reveal anything about PT, this is the concept of semantic security. <br>\n",
    "In semantic security, an adversary sends 2 messages (of equal length) and our cipher(E) encrypt it and sends the ciphertext back to the the adversary and if the adversary have no idea about which message this ciphertext correspond to then our cipher is said to be semantically secure.\n",
    "\n",
    "Overview:\n",
    ">An adversary (A) chooses two messages: $m_{0}$,$m_{1}$ and supplies it to the encryption algorithm (E) and it encrypts one of these messages: c←E(k,$m_{b}$) where b = 0, 1 and offer it back to the adversary.<br>\n",
    "The adversary tries to guess which message was ciphered and outputs $b^{'}$ = 0 or 1 corresponding to the message number that the adversary thinks the ciphertext is encryption of (either  $m_{0}$,$m_{1}$).<br>\n",
    "\n",
    "Corresponding Watch: [Semantic Security](https://www.coursera.org/learn/crypto/lecture/q0h9g/semantic-security)                 \n",
    "![](./Images/SemanticSecurity.png)\n",
    "\n",
    "Description: \n",
    ">We have 2 experiments, namely Exp(0) and Exp(1), where in the Exp(0) encryptor (E) gives back the ciphertext for $m_{0}$ (out of the supplied two) and in Exp(1) it sends back the ciphertext for $m_{1}$. Based on the experiments we have 2 events $W_{0}$ and $W_{1}$ where $W_{0}$ represents an event where for Exp(0) adversary outputted $b^{'}$ as 1 (thinking, wrongly, that the ciphertext corresponds to $m_{1}$). Similarly, $W_{1}$ represents an event where for Exp(1) adversary outputted $b^{'}$ as 1 (rightly guessed). The advantage is defined such that if the probability of both the events $W_{0}$ and $W_{1}$ is similar or close to each other then advantage would be close to zero, which would mean that the adversary isn't able to distinguish that whether the ciphertext was of $m_{0}$ or $m_{1}$. \n",
    "\n",
    "Note: Semantic Security (One time key) means that the adversary is provided with only a single ciphertext (which could correspond to any of the two supplied message).\n",
    "\n",
    "**E is said to be semantically secure if for all \"efficient\" A (adversary), Adv$_{SS}$ [A, E] = negligible.**\n",
    "\n",
    "OTP is semantically secure (it has perfect semantic security due to uniform probability distribution):\n",
    "![](./Images/OTPSemantic.png)\n",
    "\n",
    ">Theorem: **Given that G is a secure PRG (i.e. holds the indistinguishability property). A Stream Cipher E derived from or incorporates G is semantically secure.** [Proof!!](https://www.coursera.org/learn/crypto/lecture/VeLNT/stream-ciphers-are-semantically-secure-optional)\n",
    "\n",
    "![](./Images/StreamSemantic.png)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Block Ciphers\n",
    "\n",
    "Overview:\n",
    ">A block cipher is an encryption method that applies a **deterministic algorithm along with a symmetric key to encrypt a block of text**, rather than encrypting one bit at a time as in stream ciphers. For example, a common block cipher, AES, encrypts 128 bit blocks with a key of predetermined length: 128, 192, or 256 bits. **Block ciphers are pseudorandom permutation (PRP) families** that operate on the fixed size block of bits. <br>\n",
    "Note: PRPs are functions that cannot be differentiated from completely random permutations and thus, are considered reliable, until proven unreliable.\n",
    "\n",
    "![](./Images/BlockCiphers.png)\n",
    "\n",
    "Block cipher **modes of operation have been developed to eliminate the chance of encrypting identical blocks of text the same way**, the ciphertext formed from the previous encrypted block is applied to the next block. A block of bits called an **initialization vector (IV)** is also used by modes of operation to ensure ciphertexts remain distinct even when the same plaintext message is encrypted a number of times.\n",
    "\n",
    "Some of the various modes of operation for block ciphers include **CBC** (cipher block chaining), **CFB** (cipher feedback), **CTR** (counter), and **GCM** (Galois/Counter Mode), among others. Above is an example of CBC mode. Where an IV is crossed with the initial plaintext block and the encryption algorithm is completed with a given key and the ciphertext is then outputted. This resultant cipher text is then used in place of the IV in subsequent plaintext blocks.\n",
    "\n",
    "**Working of Block Ciphers (Generic):**\n",
    "\n",
    "![](./Images/BlockCipher-Working.png)\n",
    "Description: \n",
    "1. key is expanded into n number of keys called round keys (where n is the number of rounds which is subjective to individual block cipher).\n",
    "2. Cipher uses these round keys by iteratively encrypting the message again and again and again using what's referred to as the round function.\n",
    "3. Round function takes 2 inputs: Current state of the message and a round key (corresponding to that round). \n",
    "4. The output of one round function acts as the new state of the original message which is fed into the next round function. The output from the $n^{th}$ round function is the ciphertext.\n",
    "\n",
    "In order to specify a particular block cipher (built by iteration, like DES) one has to specify the key expansion mechanism and the round function. (Those are the two dynamic part of a block cipher).\n",
    "\n",
    "Note: Block ciphers are relatively slower than the stream cipher (and slower by large magnitude to eStream ciphers) but we will see that we can do many things with block ciphers that we couldn't do very efficiently with stream ciphers.\n",
    "\n",
    "**Block Cipher aka Psuedo Random Permutation (PRP)**<br>\n",
    "PRP accurately captures what a block ciphers basically is. <br>\n",
    "How?\n",
    ">As per my perception: A block cipher with size of the key as K, used (to say XOR), dictates the size of the block of the message M. Hence limiting the size of message block from its true gigantic universe to a small key-size universe and while we operate the key onto the message block the resultant/output is another state of the message belonging from the key-size universe (i.e. with the help of key we mapped the current state of message from the key-sized message universe to another state in itself, in a one-to-one mapping fashion, therefore permuted).\n",
    "\n",
    "Therefore, in many places PRPs and block ciphers are used interchangebly depending on the context.\n",
    "\n",
    "![](./Images/PRP.png)\n",
    "where,\n",
    "- PRF: [K: Key, X: Input domain, Y: Output domain] \n",
    "- PRP: [K: Key, X: Input and Output Domain]\n",
    "\n",
    "**Why Block ciphers are PRPs and not PRFs?**\n",
    "> Because PRF may or maynot be invertible, however, PRPs are by definition invertible (with one-to-one mapping) and block ciphers needs to be invertible for being able to be decrypted using the reverse process of the encryption mechanism (as we will see in DES, AES etc.), and therefore PRPs capture the essence of block ciphers.\n",
    "\n",
    "Explanatory Read: [Psuedorandom Functions and Permutations](http://www.crypto-it.net/eng/theory/prf-and-prp.html)\n",
    "\n",
    "![](./Images/PRP&PRF.png)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Secure Block Cipher:\n",
    "Explanatory video: [Block Ciphers and Secure PRFs](https://www.coursera.org/learn/crypto/lecture/t4JJr/what-are-block-ciphers)\n",
    "\n",
    "Exploring what it means for a PRP or PRF (in general) to be secure and this concept will essentially captures what it means for a block cipher to be secure.\n",
    "\n",
    "![](./Images/SecurePRF.png)\n",
    "Description: \n",
    "- The set of all the possible function from X to Y is gigantic which is referred, above, as Funs[X,Y]. However, we get a relatively smaller set of functions $S_{F}$ (which is regarded as a set of psuedo random function cuz it is in some sense determined by the key) when we restrict the size of X to be equal to the size of key (as we have to perform XOR or another operation b/w input domain X and Key K, therefore there lengths must be equal). \n",
    "- Hence, the PRF is restricted in it's domain by the size of the key (say 128 bits for AES then domain is of size $2^{128}$).\n",
    "- Given that $S_{F}$ <<<< Funs[X, Y] a PRF is considered secure if the uniform distribution from a set of psuedo random functions ($S_{F}$) is indistinguishable from the uniform distribution of truly random functions (Funs[X,Y]).\n",
    "\n",
    "Note: The above is a description for a secure PRF. For a secure PRP instead of choosing a random function from X to Y we are going to choose a random permutation on the set X (Perms[X]), in other words,  a random one-to-one function on the set x. The adversary can either query this random permutation on the set X or it can query a psuedo random permutation $S_{F}$ (which is <<< then random permutation Perms[X]) and if the adversary cannot tell the difference then the PRP is secure.\n",
    "\n",
    "\n",
    "**Secure PRP Implies a Secure PRF**\n",
    "![](./Images/SecurePRP2PRF.png)\n",
    "\n",
    "\n",
    "**Relation between PRF(Psuedo Random Functions) and PRG (Psuedo Random Generators):**\n",
    "![](./Images/PRF2PRG.png)\n",
    "Description: \n",
    "- Assume we have a psuedo random function F (here, it's PGP as defined one to one on {0, 1}$^{n}$) which is secure.\n",
    "- Now we define a PRG (G) whose seed space (K) is same as the Key Space (K) for the PRF and its output space is basically going to be t blocks of n bits each and concatenated to get the generator value. So we basically took the key of the PRF and expanded to t times of n bits each.\n",
    "- Key property of such a generator would be that it's parallelizable, which means, if we have 2 cores to compute on than we can compute the even entries on one core and odd entries on the other and concatinate at the end. Hence, we a cipher using such a generator would be paralellizable. Where as many of the previous stream ciphers that we looked before were inherently sequential like RC4 which therefore can't take the advantage of multi cores.\n",
    "- Such a PGF derived PGR is secure because the PGF is indistinguishable from truly random therefore as we can see the Generator is just a concatination of t different PGFs and hence it would also be indistinguishable and therefore secure in nature.\n",
    "\n",
    "Bottom line: A secure PRF gives rise to secure PRG which has this key property of being parallelizable.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DES (Data Encryption Standard):\n",
    "\n",
    "Recommended Watch: \n",
    "- [DES Explained Concisely](https://www.youtube.com/watch?v=Y61qn_SQl40)\n",
    "- [DES In Depth](https://www.coursera.org/learn/crypto/lecture/TzBaf/the-data-encryption-standard)\n",
    "<br>\n",
    "\n",
    "Read: [DES Quick Read](https://www.tutorialspoint.com/cryptography/data_encryption_standard.htm)\n",
    "\n",
    "The Data Encryption Standard (DES) is a symmetric-key block cipher which is an implementation of a Feistel Network. It uses 16 round Feistel structure. The block size is 64-bit. Though, key length is 64-bit, DES has an effective key length of 56 bits, since 8 of the 64 bits of the key are not used by the encryption algorithm (function as check bits only). General Structure of DES is depicted in the following illustration:\n",
    "\n",
    "![](./Images/DES.png)\n",
    "where, [IP: Initial Permutation]\n",
    "<br>\n",
    "\n",
    "**Fundamental Component of DES: The Feistel Network:**\n",
    "![](./Images/FeistelNetwork.png)\n",
    "\n",
    "The key property of the Feistel Network is that it is invertible:<br>\n",
    "![](./Images/Invertible-Feistel.png)\n",
    "\n",
    "This property of the Feistel Network results in an easy formulation of the Decryption algorithm for DES.\n",
    "![](./Images/DES-Decryption.png)\n",
    "Note: The Feistel mechanism is a general method for making invertible functions from arbitrary functions and is infact used in many different block ciphers. Although, interestingly it's not used in AES.\n",
    "\n",
    "**Is DES a secure block cipher?**<br>\n",
    "There is this theorem that states: given that we use a secure PRF (F) in each round, then a 3-round Feistel network (therefore, also a 16 round Feistel network i.e. DES), with 3 independently derived keys being passed to F, results in a secure PRP (which implicitly means a secure block cipher).\n",
    "![](./Images/SecureFeistel.png)\n",
    "\n",
    "**Overview of DES and the Round function:**\n",
    "\n",
    "![](./Images/DES-View.png)\n",
    "\n",
    "\n",
    "The heart of DES cipher is the round function. The function applies a 48-bit key to the rightmost 32 bits to produce a 32-bit output. Following are the steps:\n",
    "\n",
    "- **Expansion Permutation Box:** Since right input is 32-bit and round key is a 48-bit, we first need to expand right input to 48 bits. \n",
    "- **XOR (Whitener):** After the expansion permutation, DES does XOR operation on the expanded right section and the round key to generate a 48-bit output. The round key is used only in this operation.\n",
    "- **Substitution Boxes:** The S-boxes carry out the real mixing (confusion). DES uses 8 S-boxes, each with a 6-bit input and a 4-bit output. There are a total of eight S-box tables taking a 48-bit input. The output of all eight s-boxes is then combined in to 32 bit section.\n",
    "- **Straight Permutation:** The 32 bit output of S-boxes is then subjected to the straight permutation.\n",
    "\n",
    "![](./Images/DES-Round.png)\n",
    "\n",
    "\n",
    "**Status of DES:**<br>\n",
    "DES is no more recommended for use in production level applications as it can be broke using exhaustive search (brute force over the entire key space) attacks and now a days with the present hardware we can recover a DES key within 24 hours, hence highly insecure. Also, there are many more types of attacks that DES is subjected to like: linear and differential attacks and quantum exhaustive attacks. DES has been superseded by the more secure Advanced Encryption Standard (AES) algorithm. <br>\n",
    "Bottom line: **DES is completely DEAD** [i.e. 56-bits ciphers shouldn't be used anymore].\n",
    "\n",
    "As DES was really popular it was deployed at many places and a lot of hardware support was developed for it, then naturally the next question was what to do next and organically people thought that in order to thwart the exhaustive search lets increase the key space such that it becomes computationally infeasible to do an exhaustive search attack. Hence, **Triple-DES** was born.\n",
    "\n",
    "**Triple DES:**\n",
    "It has, as the name says, triple the key space($2^{168}$) of the normal DES, however it is 3 times slower as well. There is still an attack that can be done on 3-DES in $2^{118}$, but practically it takes too long to perform. In general, anything that has a key space beyond $2^{90}$ is considered secure to exhaustive search. If you are, for some reason, are forced use DES in production then only use Triple DES.\n",
    "\n",
    "![](./Images/3-DES.png)\n",
    "\n",
    "The Whys?:\n",
    "- In triple DES we first do an Encryption of message block with key 1, then a decryption with key 2 and again an encryption with key 3 and all 3 keys are used in the decryption process inversely. Why did we have a decryption in b/w and not 3 consecutive encryptions? cuz there exist a possibility that k1 = k2 = k3 and hence what we have is a single DES but 3 times slower.\n",
    "- Why not use 2-DES, while it also have a secure $2^{112}$ key space? Because it is prone to a special kind of attack known as Meet in the middle attack.\n",
    "\n",
    "**You should never ever use your own crypto implementations or even design a new cipher for delivering security**, due to the following reason:\n",
    "![](./Images/ImplementationAttacks.png)\n",
    "\n",
    "Note: Use a well implemented library instead which take care of these side channel and fault attacks.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AES (Advanced Encryption Standard)\n",
    "\n",
    "Recommended Watch: [AES in Depth](https://www.coursera.org/learn/crypto/lecture/cHOMl/the-aes-block-cipher)\n",
    "\n",
    "The more popular and widely adopted symmetric encryption algorithm likely to be encountered nowadays is the Advanced Encryption Standard (AES). It is found at least six time faster than triple DES.\n",
    "\n",
    "A replacement for DES was needed as its key size was too small. With increasing computing power, it was considered vulnerable against exhaustive key search attack. Triple DES was designed to overcome this drawback but it was found slow.\n",
    "\n",
    "The features of AES are as follows:\n",
    "- Symmetric key symmetric block cipher\n",
    "- encrypts 128-bit block of data using either 128/192/256-bit keys\n",
    "- Stronger and faster than Triple-DES\n",
    "\n",
    "**Security vs Speed Trade-off:** The larger the key size is, the more secure the block cipher is as a psuedo random permutation (PRP) but as it would also have more rounds involve in its operation the slower the cipher become. Hence, AES-128 is fastest while AES-256 is the most secure.\n",
    "\n",
    "**Foundation of AES** [Generic Construction]:\n",
    "![](./Images/AES-Generic.png \"Generic Construction of AES\")\n",
    "\n",
    ">AES is built as a **Substitution Permutation (Subs-Perm) Network** and not a Feistel network. Note that in a Feistel network only have the bits are changed from round to round (the left half of the next round are simply the copy of the right half of the previous round). While in Subs-Perm network all the bits are changed in every round. <br><br>\n",
    "AES also uses the concept of round keys which are derived from 128-bit key space. AES is built to be completely reversible, otherwise the decryption would have not been possible, therefore the substitution layers as well the permutation layers are reversible, i.e., given the ciphertext we can applying all the steps in AES in reverse order (with the same round keys) and produce the original text.\n",
    "\n",
    "Having a view of the generic construction of the AES, now lets look at the specifics of AES:\n",
    "\n",
    "**AES-128**<br>\n",
    "![](./Images/AES-128.png)\n",
    "\n",
    "The Flow(Encryption):\n",
    "1. AES-128 operates on blocks of 128 bits, hence we start off with a $4\\times 4$ byte input block (each cell with 1 byte).\n",
    "2. Then we XOR the input block with a $4\\times 4$ byte block of round key (which are derived, by expansion, from the 16-byte[128] AES key).\n",
    "3. Then a round function is applied which contains 3 sub-routines, namely Byte Substitution, Shift Row and Mix-Column.\n",
    "4. This is done again and again for 10 rounds, but interestingly in the last round the Mix-column routine is absent.\n",
    "5. The output, ciphertext, is the XOR of the last round key and with the output of the last round function.\n",
    "\n",
    "Decryption is just the inverse:\n",
    "The process of decryption of an AES ciphertext is similar to the encryption process in the reverse order. The round keys are applied in reverse order followed by inverted round function. Following are the steps, except for the initial round in reverse order (as it do not contains the mix-column sub-routine) :\n",
    "\n",
    "- Add round key\n",
    "- Mix columns\n",
    "- Shift rows\n",
    "- Byte substitution\n",
    "\n",
    "The round function:\n",
    "\n",
    "![](./Images/AES-Round.png)\n",
    "\n",
    "Description:\n",
    "- ByteSub: Applies a 256-byte S-box(just a lookup table) to each byte in the $4\\times 4$ byte message block and outputs a $4\\times 4$ byte block.\n",
    "- ShiftRows: Applies a cyclic shift to the rows in the $4\\times 4$ byte block (no shift on the first row)\n",
    "- MixColumns:Applies linear transformation independently to each column\n",
    "\n",
    "Note: AES is being used everywhere now as it is easily computable as well as compact. Even Intel and AMD have integrated AES into their processors itself.\n",
    "\n",
    "Attacks on AES:\n",
    "- Best key recovery attack $2^{124}$: Just 4 times better than the exhaustive search($2^{128}$)\n",
    "- Related key attack: Given that we have inp/out pairs from four related keys, key could be recovered in $2^{99}$. But it would require related keys while we chose keys at random.\n",
    "\n",
    "The above two are the only, non efficient, attacks on AES.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Block Ciphers: Modes of Operation\n",
    "There are other modes of operations (which are not discussed below), they can be explored at: [Modes of Operations](https://www.tutorialspoint.com/cryptography/block_cipher_modes_of_operation.htm)\n",
    "\n",
    "Suggestion: Don't bother about the inner-working of AES and 3-DES. Assume both are secure PRPs and we will see how to use them.\n",
    "\n",
    ">**Modes of Operation** are procedural rules for a generic block cipher. Interestingly, the different modes result in different properties being achieved which add to the security of the underlying block cipher.\n",
    "\n",
    "A block cipher processes the data blocks of fixed size. Usually, the size of a message is larger than the block size. Hence, the long message is divided into a series of sequential message blocks, and the cipher operates on these blocks one at a time.\n",
    "\n",
    "#### Electronic Code Book (ECB) Mode\n",
    "Corresponding Watch: [Modes of Operation: One Time Key](https://www.coursera.org/learn/crypto/lecture/QZAHs/modes-of-operation-one-time-key)<br>\n",
    "Take a look at the CryptographyI/LectureSlides/Week 2/UsingBlockCiphers.pdf for more on ECB.\n",
    "\n",
    "This mode is a most straightforward way of processing a series of sequentially listed message blocks.\n",
    "\n",
    "Operations:\n",
    "- Cipher the first block of plaintext and encrypts it with the key to produce the first block of ciphertext.\n",
    "- It then takes the second block of plaintext and follows the same process with same key and so on so forth.\n",
    "\n",
    ">The ECB mode is **deterministic**, that is, if plaintext block $p_{1}$, $p_{2}$,…, $p_{m}$ are encrypted twice under the same key (i.e if there exist an identical plaintext $p_{x}$ = $p_{y}$), the output ciphertext for those blocks will be the same. Therefore, ECB is terrible as it **breaks the semantic security** (the adversary will learn something about the plaintext from the given ciphertext) given that we have two identical plaintext blocks. Attacks like CPA (chosen plain text attacks) breaks ECB, hence,**ECB is not CPA secure**.\n",
    "\n",
    "Bottom line: ECB is not semantically secure for messages that would take more than one block. More generally, deterministic algorithms aren't semantically secure (as they output same ciphertext for same plaintext, hence, allowing the adversary to know that there exist two identical plaintexts in the message just by analyzing their corresponding, identical, ciphertexts).\n",
    "\n",
    "#### Security for Many Time Keys (CPA Security):\n",
    "For in-depth look: [Security for Many Time Keys](https://www.coursera.org/learn/crypto/lecture/1pnne/security-for-many-time-key-cpa-security)\n",
    "\n",
    "Following represents the Threat Model for Many Time Keys(keys that are used to encrypt multiple messages):\n",
    "![](./Images/SSforManyTimeKeys.png)\n",
    "\n",
    "Why deterministic ciphers Insecure against CPA(chosen plain text attack)?\n",
    "![](./Images/DeterministicCiphersInsecure.png)\n",
    "Description:\n",
    "- The CPA ability allows the attacker to do q queries/challenges to the cipher. Where as everything else is same as in the [Semantic Security](#Semantic-Security) setting.\n",
    "- The cipher is deterministic and under the same key, it will produce the same ciphertext given that adversary supplied the same plaintext $m_{0}$, so in both the Exp(0) and Exp(1) the ciphertext for $m_{0}$ will be returned.\n",
    "- The adversary will again challenge the Cipher (as it can do it q times), while the cipher is using the same key. Adversary now sends in $m_{0}$, $m_{1}$ and it can accurately tell which ciphertext is returned (as it already know what is the ciphertext corresponding to $m_{0}$ from the previous query).\n",
    "- Hence, the deterministic quality of the cipher (and that it uses same key for multiple message/query encryption) coupled with CPA ability of the adversary breaks the semantic security.\n",
    "\n",
    "Bottom line: **Deterministic Encryption cannot be semantically secure under a Chosen Plaintext Attack (CPA).**<br>\n",
    "\n",
    "**What do we require to provide CPA Security?**\n",
    "![](./Images/RequisiteForCPASecurity.png)\n",
    "\n",
    "**Solutions for CPA Security:**\n",
    "- **Randomized Encryption:** The Encryption Algorithm chooses some random string and uses that random string along side the plaintext to generate the ciphertext. This would allow for the generation of different ciphertexts (blocks) for the same plaintexts (blocks). Also, the size of the ciphertext is relatively longer, roughly speaking, $CT-size = PT-size + #random-bits$ (# stands for number of). Note, the random string should be large enough such that we can use it without repetition of the ciphertext for multiple encryptions of the same plaintext.<br><br>\n",
    "\n",
    "- **Nonce-Based Encryption:** Here we use a nonce which is a unique value such that the pair (k, n) which is used to encrypt message m becomes unique and until we keep changing the nonce for encrypting even the identical messages with the same key, we will generate a unique ciphertext.\n",
    "![](./Images/NonceBasedEncryption.png)\n",
    "- **Nonce as counter:** Both encryptor and decryptor uses a counter for keeping state from mssg to mssg and this counter can be used as a nonce as the counter will be a unique value for each mssg and would be synced at both ends, therefore could be used as a nonce (no explicit nonce would be required). It's a stateful method.\n",
    "\n",
    "- **Random Nonce:** Here nonce is a random variable from a Nonce Space N, which should be large enough such that there is a really low (or negligible) probability of a nonce being repeated in a given key's lifetime. This is a stateless method.\n",
    "\n",
    "General definition of Nonce: Nonce is a unique value that doesn't repeat. It does not have to be random.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discovering the CPA Secure Ciphers [There are 2 prominent Constructions to achieve CPA Security]**\n",
    "\n",
    "#### Cipher Block Chaining(CBC) Mode\n",
    "Recommended Watch: [Cipher Block Chaining](https://www.coursera.org/learn/crypto/lecture/wlIX8/modes-of-operation-many-time-key-cbc)\n",
    "\n",
    ">**Cipher block chaining (CBC)** is a mode of operation for a block cipher (one in which a sequence of bits are encrypted as a single unit or block with a cipher key applied to the entire block). Cipher block chaining uses what is known as an initialization vector (IV) of a certain length. One of its key characteristics is that it uses a chaining mechanism that causes the decryption of a block of ciphertext to depend on all the preceding ciphertext blocks. As a result, the entire validity of all preceding blocks is contained in the immediately previous ciphertext block. A single bit error in a ciphertext block affects the decryption of all subsequent blocks. Rearrangement of the order of the ciphertext blocks causes decryption to become corrupted. Basically, in cipher block chaining, each plaintext block is XORed (see XOR) with the immediately previous ciphertext block, and then encrypted.\n",
    "\n",
    "Note: CBC cannot be parallelized as it is inherently sequential.\n",
    "\n",
    "**How $AES_{CBC}$ is CPA secure (Semantically secure under CPA)?**<br>\n",
    "Identical ciphertext blocks can only result if the same plaintext block is encrypted using both the same key and the initialization vector, and if the ciphertext block order is not changed. It has the advantage over the Electronic Code Book mode in that the XOR'ing process hides plaintext patterns. Ideally, the initialization vector should be different for any two messages encrypted with the same key.\n",
    "\n",
    "**Construction 1: CBC with rand IV**\n",
    "![](./Images/CBC-1.png \"CBC Construction with rand IV\")\n",
    "\n",
    "The Flow:<br>\n",
    "$E_{CBC}$ is the our AES encryption scheme using the CBC mode of operation. When it's asked to encrypt a message m, the first thing it's going to do is it's going to choose a random IV (Initialization) that's exactly one block of the block cipher. So IV is one cypher block. So in the case of AES the IV would be 16 bytes (128 bits). And then we're gonna run through the algorithm here: \n",
    "\n",
    "The IV basically that we chose is gonna be XORed to the first plain text block. And then the result is gonna be encrypted using the AES block cipher and output the first block of the ciphertext. And now comes the chaining part where we actually use the first block of the ciphertext to kind of mask the second block of the plaintext. So we XOR the two together and the encryption of that becomes the second ciphertext block. And so on, and so on, and so forth. So this is cIpher block chaining, you can see that each cipher block is chained and XORed into the next plaintext block, and the final ciphertext is going to be essentially the initial IV that we chose along with all the ciphertext blocks. \n",
    "\n",
    "**Initialization Vector:** IV stands for Initialization Vector. And we're going to be seeing that term used quite a bit, every time we need to pick something at random at the beginning of the encryption scheme typically we'll call that an IV for initialization vector. So you notice that the **ciphertext is a little bit longer than the plaintext** because we had to include this IV in the ciphertexts which basically captures the randomness that was used during encryption.\n",
    "\n",
    "**CBC Construction 1[Decryption]:**\n",
    "![](./Images/CBC-1Decrypt.png)\n",
    "\n",
    "**CBC - CPA Analysis:**\n",
    "So the following theorem is going to show that in fact CBC mode encryption with a random IV is in fact semantically secure under a chosen plaintext attack.\n",
    "![](./Images/CBC-CPA-Analysis.png)\n",
    "So let's take it more precisely, basically if we start with a PRP, in other words, our block cipher E, that is defined over a space X, then we are gonna to end up with a encryption algorithm $E_{CBC}$ that takes messages of length L and outputs ciphertexts of length L+1. And then suppose we have an adversary that makes q chosen plaintext queries. \n",
    "\n",
    "Then we can state the following security fact, that for every such adversary that's attacking $E_{CBC}$, to exist an adversary that's attacking the PRP, the block cipher, with the following relation between the two algorithms: the advantage of algorithm A against the encryption scheme is less than the advantage of algorithm B against the original PRP plus some noise term. So lets  interpret this theorem, so what this means is that essentially since E is a secure PRP $Adv_{PRP}$[B, E] is negligible, and our goal is to say that adversary A's advantage is also negligible. However, here we are prevented from saying that because we got this extra error term. This is often called an error term and to argue that CBC is secure we have to make sure that the error term is also negligible. Because if both of these terms on the right are negligible, there sum is negligible and therefore the advantage of A against $E_{CBC}$ would also be negligible.\n",
    "\n",
    "So this says that in fact for $E_{CBC}$ to be secure it has better be the case that $q^{2}$.$l^{2}$ is much, much, much smaller than the value X, where L is simply the length of the messages that we're encrypting (so L could be like say a 1000, which means that we are encrypting messages that are at most 1000 AES blocks) and q is the number of ciphertexts that the adversary gets to see under the CPA attack, but in real life what q is, is basically the number of times that we have used the key K to encrypt messages.\n",
    "\n",
    "Example:\n",
    "![](./Images/CBC-CPA-Ex.png)\n",
    "Note: Using the given Adv formulation, we are able to precisely calculate after how many encryptions [and therefore after how many bytes of encryption], here in AES-128 it's $2^{48}$blocks, we must change the key.\n",
    "\n",
    "Warning: CBC where attacker can predict the IV is not CPA-secure!!. Hence, it's crucial that the IV be random and not predictable.\n",
    "\n",
    "**Construction 1': Nonce Based CBC**\n",
    "\n",
    "![](./Images/NonceBasedCBC.png)\n",
    "\n",
    "Description:\n",
    "This is a nonce based version of the CBC where the IV is replaced by a nonce (if the nonce is already known to the recipient, ex: counter nonce, then we don't need to include the nonce explicitly in the ciphertext, so ciphertext is exactly the same as the plaintext). \n",
    "\n",
    "If the nonce is random then we don't need the below explained extra step (we can use it directly to XOR with the initial plaintext block).\n",
    "\n",
    "However, it's perfectly fine to use a non random unique nonce, however, it's absolutely crucial to know that if we do this then we would have to take an **extra step** before using the nonce in the CBC chain, that is: **to first encrypt the nonce using a key $k_{1}$** (which is different from the key, k, that is used in the rest of the mechanism) **so that the output is going to be a random IV which is then used in the CBC chain.** So, this extra step is extremely crucial without CBC mode encryption with nonce wouldn't be CPA secure. <br>\n",
    "Note: Key $k_{1}$ could not be equal to key k, as that would also not be CPA secure.\n",
    "\n",
    "Example of a Cyrto API [AES-CBC with rand IV]:\n",
    "![](./Images/ExampleCryptoAPI.png)\n",
    "\n",
    "### Implementation of AES (CBC with random IV) using PyCrypto API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the key [16, 24, 32byte long (here each char is 1 byte)]: Awesome Crypto!!\n",
      "Enter the IV [corresponding to the size of the key]: This is 16-B IV!\n",
      "Please enter the message to be encrypted: Here is a basic implementation of the Advanced Encryption Standard.\n",
      "\n",
      "Encrypting...\n",
      "Ciphertext: b'\\x7f\\x08\\xa0\\x10\\xd1l\\xa3\\xe5\\xc7x\\x98\\xe1\\xf1\\xf5\\x90H'b'\\x8f\\xd3 g\\x80\\xca\\r\\x11\\xb6\\x9d9\\xd1\\xfc\\xa5t\\xd7'b\"h\\x88\\xef\\xf1S\\x8a\\xea\\x8f.\\xcb/\\xc3h\\xff'\\x1d\"b'\\xd2\\xbc\\x80=S\\xda#\\x8dI\\x0e\\xa2\\xeb\\x1b\\xd5F\\x8a'b'\\x1b\\xf6\\x1f\\x9dSn^\\xf1\\x9b\\x0ei\\x19&\\x80\\x0f\\x1d'\n",
      "\n",
      "Decrypting...\n",
      "Plaintext: Here is a basic implementation of the Advanced Encryption Standard.\n"
     ]
    }
   ],
   "source": [
    "from Crypto.Cipher import AES\n",
    "import random, string\n",
    "\n",
    "def split_txt(text, splitter):\n",
    "    \"Constructs the splitted_text [Block-size division]\"\n",
    "     \n",
    "    if len(text)%splitter == 0:\n",
    "        extras = 0\n",
    "        splitted_text = [text[start: start+splitter] for start in range(0, len(text), splitter)]\n",
    "    else:\n",
    "        extras = splitter - len(text)%splitter\n",
    "        text = text + random_generator(extras)\n",
    "        splitted_text = [text[start: start+splitter] for start in range(0, len(text), splitter)]\n",
    "    return splitted_text, extras\n",
    "\n",
    "def random_generator(n): \n",
    "    \"Generates n random characters for padding\"\n",
    "        \n",
    "    return ''.join(random.choice(string.ascii_letters) for x in range(n))\n",
    "\n",
    "\n",
    "def encryption(key, IV):\n",
    "    \"AES Encryption Scheme\"\n",
    "    \n",
    "    block_size = len(key)\n",
    "    obj = AES.new(key , AES.MODE_CBC, IV)\n",
    "    message = input('Please enter the message to be encrypted: ')\n",
    "    print('\\nEncrypting...')\n",
    "    splitted_text, extras = split_txt(message, block_size)\n",
    "    ciphertexts = []\n",
    "    for text in splitted_text:\n",
    "        ciphertexts.append((obj.encrypt(text)))\n",
    "    return ciphertexts,extras\n",
    "\n",
    "def decryption(key, IV, ciphertexts, extras):\n",
    "    \"AES Decryption Scheme\"\n",
    "    \n",
    "    print('Decrypting...')\n",
    "    obj2 = AES.new(key, AES.MODE_CBC, IV)\n",
    "    original_mssgs = []\n",
    "    for index in range(len(ciphertexts)):\n",
    "            original_mssgs.append(obj2.decrypt(ciphertexts[index]))\n",
    "\n",
    "    original_mssgs = list(map(lambda x: x.decode(\"utf-8\"), original_mssgs))\n",
    "    original_mssgs[-1] = original_mssgs[-1][:-extras]\n",
    "    return ''.join(original_mssgs)\n",
    "\n",
    "def AES_fxn():\n",
    "    key = input('Enter the key [16, 24, 32byte long (here each char is 1 byte)]: ')\n",
    "    IV  =  input('Enter the IV [corresponding to the size of the key]: ')\n",
    "    assert len(key) in [16, 24, 32], \"AES key must be either 16, 24, or 32 bytes long\"\n",
    "    assert len(IV)  in [16, 24, 32], \"AES IV must be of the same size as the key\"\n",
    "    \n",
    "    ciphertexts, extras = encryption(key, IV)\n",
    "    print('Ciphertext: {}\\n'.format(\"\".join(map(str, ciphertexts))))\n",
    "    original_mssg = decryption(key, IV, ciphertexts, extras)\n",
    "    print('Plaintext: {}'.format(original_mssg))\n",
    "    \n",
    "AES_fxn()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Counter (CTR) Mode\n",
    "\n",
    "CTR mode is method to achieve CPA security, it is actually superior to CBC and is also referred to as randomized counter mode. Unlike CBC, randomized counter mode uses a secure PRF. It doesn't need a block cypher (PRP). It's enough for counter mode to just use a PRF because we're never going to be inverting this function F. So we're going to let F be the secure PRF and it acts on N byte blocks. Again if we use AES, N will be 128.\n",
    "\n",
    "**Construction 2: Random Counter Mode**\n",
    "![](./Images/CounterMode.png)\n",
    "\n",
    "Work Flow:\n",
    "The way the encryption algorithm works in counter mode is it starts off by choosing a random IV, that's 128 bytes random IV in the case of AES, and the essentially we start counting. From this random IV, so you notice the first encryption is of IV then IV+1 up to IV+L. So we generate this random pad. We XOR the result with the message, and that gives us the cipher text. And, as usual, you notice that the IV here is included along with the cipher text.<br>\n",
    "\n",
    "So that, in fact, the cipher text is a little longer than the original plain text. And the point, of course, is that, encryption algorithm chooses a new IV for every message. And so even if I encrypt the same message twice, I'm gonna get different resulting cipher texts. One thing to notice that this mode is completely paralyzable, unlike CBC. CBC was sequential. Hence, if you have three AES engines encryption basically will work three times as fast. So that's the beauty of counter mode. \n",
    "\n",
    "**Construction 2': Nonce Counter Mode**\n",
    "![](./Images/CounterMode-2.png)\n",
    "\n",
    "Description:<br>\n",
    "Counter mode also has a corresponding nonce based counter mode. Where the IV is not truly random, but rather, is just a nonce which could be a counter. And the way you would implement nonce based counter mode is:\n",
    "- you would take the 128 bits block that used in AES. And then you would split it in two. \n",
    "- You would use the left 64 bits as the nonce. \n",
    "- And then once you specify the nonce, the lower order, 64 bits, would be doing the counting inside of the counter modes encryption. \n",
    "- So nonce goes on the left, and the counter mode encryption counter goes on the right. \n",
    "\n",
    "And it's perfectly fine if this nonce is unpredictable. The only restriction is that you encrypt at most $2^{64}$ blocks using one particular nonce. The danger is that you don't want the right side counter to reset to zero (that's what will happen after $2^{64}$ block encryption), then, you will have two blocks that are encrypted using the same one time pad. Therefore, we should change the block, after $2^{64}$ blocks, to avoid two time pading.\n",
    "\n",
    "**Counter mode - CPA Analysis**\n",
    "![](./Images/Counter-CPA-Analysis.png)\n",
    "\n",
    "Description: Everything is same as that of CBC Analysis, with just the following exceptions:\n",
    "- In counter mode, we use a secure PRF instead of a secure PRP.\n",
    "- Counter mode is secure as long as $q^{2}l$ is << |X|, which is better than that of CBC ($q^{2}l^{2}$ << |X|). Which means that we can encrypt more blocks using AES in counter mode as compared to AES in CBC.\n",
    "\n",
    "\n",
    "Example:\n",
    "![](./Images/Counter-CPA-Ex.png)\n",
    "Note: We can encrypt $2^{64}$ blocks in counter mode without the requirement of changing the key which is much better that $2^{48}$ blocks in CBC.\n",
    "\n",
    "#### Counter Mode vs Cipher Block Chaining\n",
    "![](./Images/CounterVsCBC.png)\n",
    "\n",
    "A quick comparison of counter mode and CBC unveils that **in every single aspect, counter mode is superior to CBC** with parallelizability and ability to encrypt more blocks with the same key being the major advantages of counter mode. And that's actually why most modern encryption schemes actually are starting to migrate to counter mode, and abandon CBC. Even though CBC is still quite widely used.\n",
    "\n",
    "\n",
    "<br>\n",
    "### Summarizing the Block Ciphers\n",
    "![](./Images/BlockCipherSummary.png)\n",
    "\n",
    "The security notions discussed up to here only provides security against eavesdropping(**provides confidentiality**) but not against tampering. And **because neither one is designed to defend against tampering, neither one provides data integrity. And we're going to see this as a real problem. As a result, in fact, these modes actually should never, ever be used. You should only be using these modes in addition to an integrity mechanism.** \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAC (Message Authentication Code)\n",
    "Corresponding Watch: [MAC](https://www.coursera.org/learn/crypto/lecture/iVGR5/message-authentication-codes)\n",
    "\n",
    "A Message Authentication Code (MAC) is a cryptographic primitive used to:\n",
    "- Provide **Data Integrity** by allowing verifiers (who also possess the secret key) to detect any changes to the message content.\n",
    "- **Authenticate** a message, in other words, to confirm that the message came from the stated sender (its authenticity).\n",
    "\n",
    "Note: MAC do not provide, standalone, confidentiality services.\n",
    "\n",
    "Here we have, Alice and Bob. They have a shared key, K, which is not known to the attacker, but known to both of them. And there's a public message M that Alice wants to send to Bob, such that an attacker along the way cannot modify this message on its way to Bob. \n",
    "![](./Images/MAC.png)\n",
    "[S: Signing Algoritm, V: Verification Algorithm, K: Key Space, M: Message Space and T: Tag Space]\n",
    "\n",
    "The Flow:<br>\n",
    "The way Alice does it, is by using what's called a MAC signing algorithm, we'll denote it by S, where the MAC signing algorithm takes as input the key and the message, and produces a very short tag. The tag could be like 90 bits or 100 bits, or so on. Even though the message is gigabytes long, the tag is actually very, very short. Then, she appends the tag to the message and sends the combination of the two to Bob. Bob receives the message and the tag, and then he runs what's called a MAC verification algorithm on this tag. So the MAC verification algorithm takes as input to the key, the message, and the tag and it says basically yes or no, depending on whether the message is valid or whether it's been tampered with. \n",
    "\n",
    "So more precisely, **what is a MAC? **\n",
    ">Well, MAC basically consists of two algorithms, a **Signing algorithm** and a **Verification algorithm**. As usual, they're defined over a key space, a message space, and a tag space. And as we said, it's a pair of algorithms. So the signing algorithm will output a tag in the tag space using the shared key, and the verification algorithm, basically given the key, the messages and the tag, will output yes or no. \n",
    "\n",
    "And there are these consistency requirements, such that for every K in the key space and for every message in the message space, it so happens that if I sign a message using a particular key, and then I verify the tag using the same key, I shall get yes in response. So this is the standard consistency requirement which is the analog of the one that we saw for encryption.\n",
    "\n",
    "**Common Mistake:**<br>\n",
    "There's a common mistake that people make, where they try to **provide integrity without actually a shared key**. So here's an example. So consider CRC. CRC stands for cyclic redundancy check. Alice basically uses a CRC algorithm which is keyless. Doesn't take any key, to generate a tag. And then she appends this tag to the message, she sends it over to Bob. Bob will still verify the tag is equal to CRC(m). And if so the verification algorithm will say yes, and no otherwise.\n",
    "\n",
    "![](./Images/IntegrityRequireSKey.png)\n",
    "**Integrity mechanism with Secret Key = Authenticated Integrity [Source/Entity + Message Integrity]**, whereas keyless Integrity mechanism results only in message integrity.\n",
    "\n",
    "So the problem with this is it's very easy for an attacker to defeat a keyless integrity mechanism. In CRC, an attacker can very easily modify the message and fool Bob into thinking that the new message is a valid one. The way the attacker will do it is he'll simply block the message and the tag. And then he'll produce his own message, say m', and compute CRC on m', and then send the concatenation of the two over to Bob. Bob will run the verification algorithm, verification will work properly because in fact the tag is a valid CRC for the received message. And as a result, Bob would think that this message came from Alice but in fact its been completely modified by the attacker and had nothing to do with the original message that Alice sent.\n",
    "\n",
    "Bottom Line: **We can use an key-less integrity mechanism, such as CRC, to provide integrity service but that mechanism would not provide, a much necessary, authentication service.**\n",
    "\n",
    "**Secure MACs**<br>\n",
    "What does it take for a MAC to be secure?\n",
    "\n",
    "![](./Images/SecureMAC.png)\n",
    "\n",
    "Note: Chosen Message Attack(CMA) is analog to Chose Plaintext Attack(CPA) with a difference that in CPA, attacker has the ability to post q plaintext queries to the Encryption Scheme and and is given back the ciphertexts. Whereas in CMA, adversary has the ability to feed/query q messages to the MAC Signing algorithm and receives the corresponding tags.\n",
    "\n",
    "![](./Images/SecureMAC-2.png)\n",
    "\n",
    "Though the above snippets for Secure MACs are self explanatory, if an explanation is required then please refer to the corresponding watch mentioned above.\n",
    "\n",
    "\n",
    "**Building Secure MACs**\n",
    "\n",
    "Any Secure PRF directly gives us a Secure MAC. \n",
    "![](./Images/S-PRFgivesS-MAC.png)\n",
    "Description:<br>\n",
    "**Given a secure PRF we can construct a secure MAC simply by defining the signature on the message m as the value of the PRF at the point m.** The only caveat is that the output(Y) of the PRF F has to be large. For example, it could be 80 bits or 128 bits, and that would generate a secure MAC. Why? (Explained Below!)\n",
    "\n",
    "Note: The domains K, X and Y in Secure PRF (F), above, corresponds to Key Space(K), Message Space(M) and Tag Space(T) in the MAC. And the MAC is psuedorandom because the size of the key, used to operate on the message, delimits the Message Space.\n",
    "\n",
    "![](./Images/SecurityThm4S-MAC.png)\n",
    "Description:<br>\n",
    "Given that we use a secure PRF ($Adv_{PRF}$ = negligible) to build our MAC, the whole aspect of security gets loaded on to the size of Y (|Y|) which is the PRF representation of the size of Tag. So, our MAC is secure as long as the |T| is sufficiently large.<br>\n",
    "Hence, if the size of Tag is large enough to make 1/|Y| term negligible the then the $Adv_{MAC}$ = $Adv_{PRF}$(neg) + 1/|Y|(neg) = negligible.\n",
    "\n",
    "Key Note: \n",
    ">**Tags can't be too short.** They have to have some length to them. And in fact, the typical tag length would be, 64, 96, or 128 bits. Here let's for example use the tags that are 96 bits long. If you try to guess the tag for a message when the tag is 96 bits the probability of guessing it correctly is 1/$2^{96}$ . So the adversary's advantage would just be 1/$2^{96}$ which is negligible. \n",
    "\n",
    "Property of Secure PRF based MACs: \n",
    "![](./Images/TruncateMACs.png)\n",
    "Suppose we have a Secure PRF (F) then a truncated version of F would also be a secure PRF.<br>\n",
    "Hence, for a MAC constructed using the Secure PRF F outputting n-bits, we can have a truncated MAC outputting w-bits(therefore the output tag would be of more reasonable size) which  would still be secure as long as |w| is large enough.\n",
    "\n",
    "**Our 1st PRF based MAC:**<br>\n",
    "So now that we know that any secure PRF is also a secure MAC, we already have our first example i.e. AES. In particular, we know that AES, or at least we believe that AES is a secure PRF. Therefore, the AES cipher essentially gives us a MAC that can match messages that are exactly sixteen bytes(128 bits). So, that's our first example of a MAC. However, this AES MAC is for small inputs (16-bytes). \n",
    "\n",
    "**The question of MAC for large Messages:**<br>\n",
    "Now the question is: If we have a PRF for small inputs like AES that only acts on sixteen bytes, can we build a MAC for big messages that can act on gigabytes of data? Basically given a small MAC can we build a big MAC out of it. In other words, **given a MAC for small messages and we build a MAC for large messages?** \n",
    "\n",
    "There are these two prominent constructions (however, we are going to discuss 4 constructions as we proceed), which provides solution to the above question, used in practice (for building secure MACs):\n",
    "- **CBC-MAC**: It is an AES-Based MAC used primarily in the Banking Industry, for ex, in Automated Clearing House (ACH) which banks use to clear cheques with one another.\n",
    "- **HMAC**: It's a MAC from a Hash function and is used on the Internet by protocols such as SSL, IPsec, SSH etc.<br>\n",
    "\n",
    "(They both convert a small-PRF into a big-PRF, in other words, converts a MAC for small messages into a MAC for large messages)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CBC-MAC and NMAC\n",
    "Corresponding watch: [CBC-MAC](https://www.coursera.org/learn/crypto/lecture/QYT6i/cbc-mac-and-nmac)\n",
    "\n",
    "The Goal:\n",
    "![](./Images/MACs&PRFs.png)\n",
    "Note: We are going to denote by X, the set {0,1}$^{n}$ where n is the block size for the underlying secure PRF. So, since we're always going to be thinking of AES as the underlying PRF, we can think of n as essentially 128 bits. \n",
    "\n",
    "#### CBC-MAC\n",
    "\n",
    "![](./Images/CBC-MAC.png)\n",
    "Note: Each F in the blue box is the PRP (small-PRF: can produce MAC for small messages), and the entire setup is our new PRF $F_{ECBC}$ (big-PRF: can produce MAC for large messages)\n",
    "\n",
    "The Concept:\n",
    ">So CBC uses a PRF that takes messages in the set X {0,1}$^{n}$ and outputs messages in the same set X (i.e. an invertible PRF aka PRP). And what we're going to be building is a PRF that basically takes pairs of keys and it takes very long messages, in fact arbitrarily long messages, and it outputs tags in {0,1}$^{n}$ (a small tag for arbitrary length message). So that's our goal. <br> \n",
    "Now whats that X to the less than or equal to L? The point here is that in fact CBC MAC can take very long messages of up to L blocks (where L can be huge, million to even billions). Thereby we are trying to achieve that goal: given a MAC for small messages(AES), we build a MAC for large messages (CBC).\n",
    "\n",
    "Work Flow:\n",
    "1. We start by taking our message and breaking it into blocks, each block is as long as a block of the underlying function F, and then essentially we run through the CBC chain except that we don't output intermediate values. \n",
    "2. So, we basically encrypt the first block and then feed the results into the XOR with the second block and then feed that into F again, and we do that again and again and again.\n",
    "3. Finally we get a value which is called the raw CBC output, this output is still not a secure MAC. Therefore, we do one more, critical, encryption step. \n",
    "4. This final encryption step is actually done using an independent key, K1 (remember $F_{ECBC}$ takes a pair of keys: $K^{2}$). That's different and chosen independently of the key K, and finally the output gives us the tag (which is secure). \n",
    "\n",
    "In this case the tag would be n bits long (if AES is the underlying PRF, so n would be 128 bits), but, as mentioned in the previous earlier, it's fine to truncate the tag to w bits as long as $1/2^{w}$ is negligible.\n",
    "\n",
    "#### NMAC\n",
    "\n",
    "So another class of construction for converting a small PRF(our good small AES) into a large PRF is called NMAC, for Nested MAC.\n",
    "![](./Images/NMAC.png)\n",
    "\n",
    "Note: Each F in the blue box is the PRP (small-PRF: can produce MAC for small messages), and the entire setup is our new PRF $F_{NMAC}$  (big-PRF: can produce MAC for large messages)\n",
    "\n",
    "The Concept:\n",
    ">NMAC starts from PRF that, as before, takes inputs in X, but outputs elements in the key space K. And remember that for CBC, the output has to be in the set X. Here, the output needs to be in the key space. Therefore, we basically obtain the PRF, which takes pairs of keys as inputs, can process variable length messages up until L blocks (where L can get real big) and outputs an element in the key space.\n",
    "\n",
    "Work Flow:\n",
    "1. We take our message, and we break it into blocks. Each block is, again, as big as the block length of the underlying PRF (here, AES hence 128 bits). \n",
    "2. And now we take our key and feed into the function F. And the message block is given as the data input into the function F. What comes out is the key for the next block of NMAC. \n",
    "3. So now we have a new key for the next evaluation of the PRF. And the data for the next evaluation is the next message block and so on and so forth until we reach the final output.\n",
    "4. The final output is gonna be an element in K. If we stop here, the function that we obtain is called a cascade function. So, cascade will output an element in K. However, that is not a secure MAC. \n",
    "5. To get a secure MAC, what we do is we need to map this element t, which is, right now, in K, into the set X. And so, typically, NMAC is used with PRFs where the block length, X, is much bigger than the key length. And so what we do is we simply append fixed pad. Usually, the fixed pad that gets appended to this tag t is referred to as fpad. \n",
    "6. This then becomes an input to the final function which uses an independent key K1 for the last encryption step. And then finally, the last tag is an element of K which is the output of NMAC (finally, we got a secure tag). \n",
    "\n",
    "So remember without the last encryption step, the function is called a cascade. With the last step, which is necessary for security, we actually get a PRF which outputs elements in K, and can process variable length messages that are up to L blocks long.\n",
    "\n",
    "Note: NMAC is the basis for a popular MAC called **HMAC**.\n",
    "\n",
    "Ques: Why raw CBC (of CBC MAC) and Cascade (of NMAC) are insecure MACs?<br>\n",
    "Ans : As they can be subjected to **extension attacks** due their extension property. Explained in detail here, [CBC-MAC and NMAC](https://www.coursera.org/learn/crypto/lecture/QYT6i/cbc-mac-and-nmac), tune in at 7:30. Therefore, those **last encryption steps with independent key K1 are crucial.**\n",
    "\n",
    "**CBC-MAC and NMAC Analysis**\n",
    "\n",
    "![](./Images/CBC&N-MACAnalysis.png)\n",
    "[q: number of messages MACed with key k]<br>\n",
    "\n",
    "![](./Images/CBC&N-MACAnalysisEx.png)\n",
    "If we use the key for MACing blocks more than $2^{48}$ (with AES as underlying PRF) we will start getting collision, i.e., the tags for two different messages would turn out to be the same. \n",
    "\n",
    "Warning: **The Birthday Attack**<br>\n",
    "If we keep using the same key K after MACing q messages where q exceeds |X|$^{1/2}$ for CBC-MAC or |K|$^{1/2}$ for NMAC. We will get collisions, i.e., the the tags for different messages would start to collide. So, if we made this mistake of omitting the final encryption steps and therefore using only the raw CBC or Cascade to encrypt then they are subjected to extension attacks and we can prove that the extensions, from the extension attacks, will collide as well, which will result in birthday attack as depicted below.\n",
    "\n",
    "![](./Images/InsecureMACBirthdayAttack.png)\n",
    "<br>\n",
    "\n",
    "**MAC Padding**\n",
    "\n",
    "The Problem:<br>\n",
    "Till now we have assumed that the message length is a multiple of the block size, but what if the message length is not a multiple of the block size?\n",
    "\n",
    "Solution 1: suggested by ISO<br>\n",
    "The padding function must be one to one. In other words, it should be the case that two distinct messages always map to two distinct padded messages. We shouldn't actually have a collision on the padding function. Another way of saying it is that the padding function must be invertible. That guarantees that the padding function is one to one. So a standard way to do this was proposed by the International Standards Organization ISO.\n",
    "\n",
    "What they suggested is basically, let's append the string 100.. to the end of the message to make the message be a multiple of the block length. Now to see that this padding is invertible, all we do is describe the inversion algorithm which simply is gonna scan the message from right to left, until it hits the first one and then it's gonna remove all the bits to the right of this one, including the one. And you see that once we've removed the pattern this way, we obtain the original message.\n",
    "\n",
    "![](./Images/CBC-ISOPadding.png)\n",
    "\n",
    "Common Mistake: \n",
    "Now there's one corner case that's actually quite important, and that is what do we do if the original message length is already the multiple of a block size? In that case it's really very, very important that we add an extra dummy block. That contains the pad 100... and again, there are many products and standards that have actually made this mistake where they didn't add a dummy block and as a result, the MAC is insecure because there exist an easy existential forgery attack.\n",
    "\n",
    "Solution 2: **CMAC** (NIST Standard)\n",
    "\n",
    "The Concept:<br>\n",
    "There is a very clever idea called CMAC, standardized by NIST, which shows that using a randomized padding function we can avoid having to ever add a dummy block. So CMAC actually uses three keys. And, in fact, sometimes this is called a three key construction. So this first key, K, is used in the CBC, the standard CBC MAC algorithm. And then the keys, K1 and K2, are used just for the padding scheme at the very last block. And in fact in the CMAC standard, the keys K1, K2 are derived from the key K by some sort of a pseudo random generator.\n",
    "\n",
    "![](./Images/CMAC.png)\n",
    "Work Flow:\n",
    "- The way CMAC works is as follows. Well, if the message happens to not be a multiple of a block length, then we append the ISO padding to it. But then we also XOR this last block with a secret key, K1, that the adversary doesn't know. \n",
    "- However, if the message is a multiple of the block length, then of course, we don't append anything to it. But we XOR it with a different key, K2, that, again, the adversary doesn't actually know. \n",
    "\n",
    "So it turns out, just by doing that, it's now **impossible to apply the extension attacks that we could do on the cascade function, and on raw CBC**. Because the poor adversary actually doesn't know what is the last block that went into the function. Hence, **we don't need that last, critical, encryption step in CMAC that we absolutely needed in CBC-MAC and NMAC**.<br><br>\n",
    "Note: CMAC is a federal standard standardized by NIST and if you now, these days, wanted to use a CBC-MAC for anything, you would actually be using CMAC as the standard way to do it.\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### PMAC (Parallel MAC)\n",
    "Corresponding watch: [PMAC](https://www.coursera.org/learn/crypto/lecture/u8xyE/pmac-and-the-carter-wegman-mac)\n",
    "\n",
    "Till now we have talked about the CBC-MAC and NMAC to convert a PRF for small messages into a PRF for much larger messages. Those two constructions were sequential, in the sense that if you had multiple processors you couldn't make the construction work any faster.<br> \n",
    "PMAC stands for Parallel MAC that also converts a small PRF into a large PRF, but does it in a very parallelizable fashion and therefore is very fast given a multiprocessor system.\n",
    "\n",
    "![](./Images/PMAC.png)\n",
    "\n",
    "Work Flow:\n",
    "1. We take our message and we break it into blocks. And then we process each block independently of the other. \n",
    "2. So, the first thing we do, is we evaluate some function P and we XOR the result into the first message block, and then we apply our function F using a key k1. We do the same for each one of the message blocks and notice that we can do it all parallel, all message blocks are processed independently of one another.\n",
    "3. Finally, we collect all these results into some final XOR and then we encrypt one more time to get the final tag value.\n",
    "\n",
    "Note: For a technical reason, actually on the very last one, we actually don't need to apply the PRF F, but as said, this is just for technical reason, we are going to ignore that for now.\n",
    "\n",
    "**What's that P function for?**\n",
    "\n",
    "The problem that PMAC is subjected to without the function P:<br>\n",
    "Imagine, just for a second, that the function P isn't actually there. That is, imagine we actually, directly feed each message block into the PRF without applying any other processing to it. Then the resulting MAC is completely insecure and the reason is essentially no order is enforced between the message blocks. In particular, if I swap two message blocks, that doesn't change the value of the final tag. Because the XOR is commutative, the tag will be the same whether we swap the blocks or not. As a result, an attacker can request the tag for a particular message, and then he obtains the tag for a message where two of the blocks are swapped and that counts as an existential forgery.\n",
    "\n",
    "How the function P solves it:<br>\n",
    "So what this function P tries to do is essentially enforce order on these blocks. And notice that the function takes, first of all, a key as input, which is different from the key used for the PRF. And second of all, more importantly, it takes the block number as input. In other words, the value of the function is different for each one of the blocks. And that's actually exactly what's preventing this, blocks swapping attack. So the function P actually, is a very easy to compute function. Essentially given the key and the message block, all it is, is just a multiplication in some finite fields. So it's a very, very simple function to compute. It adds very little to the running time of PMAC. And yet, it's enough in ensure that the PMAC is actually secure.\n",
    "\n",
    "**What about Padding for PMAC?**<br>\n",
    "If the message length is not a multiple of the block length. That is, imagine the last block is shorter than full block length, then PMAC actually uses a padding that's similar to CMAC, so that there is no need for an additional dummy block, ever\n",
    "\n",
    "**PMAC Analysis**\n",
    "![](./Images/PMAC-Analysis.png)\n",
    "\n",
    "PMAC is secure, as long as $qL$ product is less than the square root of the block size |X|. So for AES as the underlying PRF, |X| would be $2^{128}$, and the square root, therefore, would be $2^{64}$. So the MAC would be secure, as long as $q.L$ is less than $2^{64}$. And every time, as it gets closer to that value, of course, we would have to change the key in order to continue MAC-ing more messages securely.\n",
    "\n",
    "An Interesting Property of PMAC:<br>\n",
    "**PMAC is incremental in nature**, i.e., if just a single block (or couple blocks in general) have changed, maybe because only certain parts of the message got changed, and rest of the blocks of the message are intact. Then we don't need to recompute PRF for all other blocks, we can just apply function P and recompute the PRF (specifically PRP, as explained in the corresponding watch) for the changed block(s) alone and perform the final XOR with all other block's PRF outputs(which were already computed) to quickly regenerate the tag. (This save the recomputing, as would have done in CBC-MAC and NMAC because they are sequential).<br>\n",
    "For in-depth explanation regarding this property: tune in to the corresponding watch at 4:05.\n",
    "\n",
    "### One Time MAC\n",
    "\n",
    "It is basically the analog of the one time pad, but in the world of integrity. So let me explain what I mean by that. So imagine we wanna build a MAC that is only used for integrity of a single message. In other words, every time we compute the integrity of a particular message, we also change the key. So that any particular key is used only for integrity of one message. This is referred to as One Time MAC.\n",
    "\n",
    "![](./Images/OneTimeMAC.png)\n",
    "Description:<br>\n",
    "- We can define the security game as basically saying, the attacker's gonna see one message. Therefore, we only allow him to do one chosen message attack(as the key is going to change per message MACing). \n",
    "- So, adversary gets to submit one message query, and he is given the tag corresponding to that one message query. And now his goal is to forge a message tag pair, i.e., to produce one message tag pair that verifies correctly and is different from the pair that he was actually given. \n",
    "- We would say that a one time act is secure, because basically no adversary can win this game. Now the interesting thing is that one time MACs, just like the one time pad can be secure against infinitely powerful adversaries. \n",
    "\n",
    "Catch: The only thing, with One Time MAC is that we would need to use a different key for MACing different messages and as these keys are secret keys, hence, the keys needs to be securely communicated to the recipient's end for verification.\n",
    "\n",
    "A classic example of One Time MAC:\n",
    "![](./Images/OTM-Example.png)\n",
    "Description:<br>\n",
    "The key is a pair of two random integers from [1...q] where q is a large prime number (usually greater than the number of blocks).<br>\n",
    "Basically, we construct a polynomial that corresponds to our message, if there are L blocks in the message then the polynomial would be L degree polynomial, then we evaluate that polynomial at half, K, of the secret key, and add the other half (a) of the secret key to the result, and of course reduce final result modulo q and that's the whole MAC. As a result, even though adversary have seen the value of the MAC on a particular message, he have no way of forging this MAC on some other message. \n",
    "\n",
    "Note: One Time MAC is way faster than PRF based MACs but it's just a one time MAC, hence not two time secure. In other words, if adversary get to see the value of the MAC on two different messages, that actually completely compromises the secret key. And adversary can actually predict a MAC for a third or fourth message of his choice. So then the MAC becomes forgeable.\n",
    "\n",
    "**One Time MAC to Many Time MAC**<br>\n",
    "Why we want to do that? <br>\n",
    "Because One Time MACs are very fast as compared to PRF Based MACs and hence for MACing large messages One Time MAC would be efficient (in terms of time). Now, we can use this great potential of One Time MAC if we can just find a way to get a Many Time MAC(single key for MACing multiple messages) out of it.\n",
    "\n",
    "Carter-Wegman MAC is general construction for a Many Time MACs which are built over a One Time MACs.\n",
    "![](./Images/OTM2MTM.png)\n",
    "\n",
    "The Flow:\n",
    "- Basically what we would do is we would apply the one time MAC to the message m and then we're going to encrypt the results using the PRF. \n",
    "- So how do we encrypt the result? Well, we choose a random r (nonce) and then we compute kind of a one time path from this r by applying the PRF to it.\n",
    "- And finally we XOR the result with the actual one time MAC to get the output tag.<br><br>\n",
    "So the neat thing about this construction is that the fast one time MAC is applied to the long message, which could be gigabytes long. And the slower PRF is only applied to this nonce r, which is then used to encrypt the final results of the MAC. And we can argue that if the MAC that was given to us as a building block is a one time secure MAC, and the PRF is secure, then, in fact, we get a Many Time secure MAC that happens to output 2n bit tags.\n",
    "\n",
    "We're gonna see Carter-Wegman MACs later on at authenticated encryption. And, in fact, one of the NIST standard methods for doing encryption with integrity, uses a Carter-Wegman MAC for providing integrity. Carter-Wegman MAC is a good example of a randomized MAC where this nonce r is chosen afresh every time the tag is computed. And so for example if we try to compute a tag for the same message twice each time you'll choose a different r and as a result you'll get different tags both the time.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAC from Collision Resistant Hash-Functions (The Rise of the HMAC)\n",
    "\n",
    "Note: In order to understand HMAC we would first need to understand Collision Resistant Hash functions and ways to construct them. Once done, we can explore one of the most popular MAC of the all, the HMAC.\n",
    "\n",
    "**Hash Function:** A hash function is any function that can be used to map data of arbitrary size to data of a fixed size. The values returned by a hash function are called hash values, hash codes, digests, or simply hashes.<br>\n",
    "\n",
    "![](./Images/CollisionResistance.png)\n",
    "\n",
    "**What does it mean for a hash function to be collision resistant?**<br> \n",
    "We have a hash function from some message space M to a tag space T, where |M| >>>> |T|. So, the messages could be gigabytes long, but the tags would only be like 160 bits. \n",
    "\n",
    "A collision for the function H could be described as follows: there exist a pair of messages $m_{0}$, $m_{1}$ (in the message space), that happen to be distinct, however, when you apply the function H to them, you end up with the same output(in the tag space), which is referred to as **collision**.\n",
    "\n",
    "Now we say that the function is collision resistant if it's hard to find collisions for this function. Now this should seem a little bit counterintuitive because we know that the output space is tiny compared to the input space. So, by the [pigeonhole principle][], there must be lots and lots and lots of messages that map to the same output. Just because there isn't enough space in the output space to accommodate all the messages without collisions.\n",
    "\n",
    "[pigeonhole principle]: https://en.wikipedia.org/wiki/Pigeonhole_principle\n",
    "\n",
    "So, we know that there are lots of collisions, and the question is, is there an efficient algorithm that finds any such collisions explicitly? So we say the, **the function is collision resistant, if, for all explicit efficient algorithms A, these algorithms are not able to print/find the collision for the function H.**\n",
    "\n",
    "Example:<br>\n",
    "Classic example of a collision resistant hash function is SHA-256 (Secure Hash Algorithm-256) which happens to output 256 bits (called hash or digest) for arbitrary large inputs. For example, it can take gigabytes and gigabytes of data and it will map it all to 256 bits. And yet nobody knows how to find collisions for this particular function. **SHA-256 is commonly used in Blockchain**.\n",
    "\n",
    "**How can we build, trivially, a MAC given a collision resistant hash function?**<br>\n",
    "We aren't trying to build a MAC here, but instead we are trying to build a secure MAC for large messages with collision resistant hash functions as the building block.\n",
    "\n",
    "![](./Images/MACfrmHashFxn.png)\n",
    "Description:\n",
    "- Suppose we have a MAC for short messages (you should be thinking something like AES, which can MAC sixteen byte messages) and then, suppose we have a hash function, a collision resistant hash function from a large message space, that contains gigabyte messages into our small message space (say, into sixteen byte outputs).\n",
    "- Then, basically, we can define a new MAC, let's call it $I^{big}$, which happens to be MACing large messages. And we'll define it simply by applying the small MAC to the output of the hash function. <br>\n",
    "Note: As the hash fxn spits out 16 bytes output for arbitrary len messages, our small MAC, which can MAC 16-bytes messages, can take the output of the hash fxn and MAC it. \n",
    "- And how do we verify a MAC? Well, basically, given a tag we verify it by rehashing the given message and then checking that small MAC(our AES-based MAC) actually verifies under the given tag.\n",
    " \n",
    "Example build:<br>\n",
    ">Let's say we use SHA-256 as our collision resistant hash function. So, SHA-256 outputs 256 bit outputs, which is 32 bytes. Therefore we have to build a small MAC that can MAC these 32 byte outputs from SHA-256. And the way we could do that is basically by applying the sixteen byte AES, plugging it into a two block CBC. **A two block CBC would expand AES from a PRF on sixteen bytes to a PRF on 32 bytes**. And then take the output of SHA-256 and plug it into this two block CBC based on AES. And then we get a very, very simple, MAC which is secure assuming AES is a PRF and SHA-256 is collision resistant.\n",
    "\n",
    "KeyNote: Collision Resistant is crucial for this $I^{big}$ MAC to be secure. What if the Hash function isn't collision resistant? Then an adversary would be able to make an existential forgery as depicted below.\n",
    "\n",
    "![](./Images/InsecureMACfromHash.png)\n",
    "<br>\n",
    "A real world application where Collision Resistance(CR) Hash functions are used for message/file integrity:\n",
    "\n",
    "![](./Images/ApplicationCRHash.png)\n",
    "\n",
    ">**CR Hash functions provides message integrity without the need of a secret key (referred to as public verifiability), however they require a read-only public space** (i.e. these spaces cannot be modified by any adversary). Whereas with MACs we have an exact complement i.e. we need a secret key, but won't require this read only public space. \n",
    "\n",
    "Later on, we will see that with Digital Signatures we will get the best of both worlds, i.e., with **Digital Signatures** we can achieve public verifiability without the need for read-only space.\n",
    "\n",
    "**General Attack on CR Hash Functions: Generic Birthday Attack**<br>\n",
    "Recommended  Watch: [Generic Birthday Attack](https://www.coursera.org/learn/crypto/lecture/pyR4I/generic-birthday-attack)\n",
    "\n",
    "Overview of **Birthday Paradox**:\n",
    ">In probability theory, the birthday paradox concerns the probability that, in a set of n randomly chosen people, some pair of them will have the same birthday. By the pigeonhole principle, the probability reaches 100% when the number of people reaches 367 (since there are only 366 possible birthdays, including February 29). However, 99.9% probability is reached with just 70 people, and 50% probability with 23 people (it's called a paradox because 23, 70 being such a small number still generates a probability of 50% and 70%, which is paradoxical). These conclusions are based on the assumption that each day of the year (excluding February 29) is equally probable for a birthday, i.e. uniformly distributed.\n",
    "\n",
    "Fact: Under the BDay attack we consider bdays to be uniformly distributed but in reality birthdays aren't equally distributed rather they have a bias towards the month of September, thereby lifting the probability of collisions.\n",
    "\n",
    "Theorem and Proof of the Birthday Paradox:<br>\n",
    "![](./Images/TheBirthdayParadox.png)\n",
    "\n",
    "Note: To profoundly understand birthday paradox and its formulation tune in to the recommended watch at 2:25.\n",
    "\n",
    "General Attack Overview:<br>\n",
    "We saw a general attack on block ciphers which we called **exhaustive search**. And that attack **forced the key size for a block cipher to be 128 bits or more**. Similarly, on collision resistance there is a general attack called the **birthday attack** which **forces the output of collision resistant hash functions to be more than a certain bound**. \n",
    "\n",
    "Following is the algorithm for the Birthday Attack, collisions could be found within 2 iterations due to the birthday paradox.\n",
    "![](./Images/BirthdayAttackAlgo.png)\n",
    "\n",
    "Shown below are the CR Hash functions with their digest size and based on the birthday attack their generic attack time(in which a collision can be found).\n",
    "\n",
    "![](./Images/SampleCRHashFxn.png)\n",
    "\n",
    "With **increase in the digest size that these CR Hash functions produce, we compromise the hashing speed** and therefore we need to, depending on the context, balance between the performance and security trade-off.\n",
    "\n",
    "Note: Attack time below $2^{90}$ aren't considered safe, and therefore, although there is no collision found for SHA-1 till date but is not considered a safe algorithm anymore, because collisions can be found for it in very near future. Hence, don't use SHA-1 for integrity purposes, it's better to use SHA-256.\n",
    "\n",
    "While using Quantum Computers, we can find collisions in cube root time of the digest(output) length.\n",
    "![](./Images/QuantumFinder.png)\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Collision Resistant Hash Functions\n",
    "\n",
    "![](./Images/Goal-CRHashFxn.png)\n",
    "We're gonna construct these collision resistant hash functions, in two steps:\n",
    ">1. The first step is to show that if you give me a collision resistant hash function for short messages, we can extend it and build a collision resistant hash function for much, much, much longer messages. \n",
    "2. In the second step, we'll actually build collision-resistant Hash functions for short messages [that we used in the first step]. \n",
    "\n",
    "#### Step 1: Merkle-Damgard Paradigm \n",
    "It is basically a construction to achieve the first step of constructing the collision resistant hash functions. The construction is actually very general and in fact all collision-resistant hash functions follow this paradigm.\n",
    "\n",
    "![](./Images/Merkle-DamgardParadigm.png)\n",
    "How it works:\n",
    "- We have our function h which we're gonna assume is a collision-resistant hash function for small sized inputs all known as the **compression function**. <br><br>\n",
    "- So the way we're gonna use this little function h is we're gonna take a big message M and break this message in to blocks. And then we use a fixed value called the IV(Initialization Vector), which acts the first chaining variable $H_{0}$. Here in this case the IV is fixed forever. And it's basically embedded in the code and in the standards (the fixed size is equal to the length of the hash function's digest domain). <br><br> \n",
    "- Then we apply the small compression function h to the first message block along with this IV. What comes out of that is what's called a chaining variable that's gonna be fed into the next compression function which compresses the next block along with the previous chaining variable and out comes the next chaining variable, and the next message block is compressed, and so on and so forth until we reach the final message block.<br><br>\n",
    "- Then at the final message block, the one special thing that we do, is that we must append a padding block (PB), after we append the padding block we again compress the last chaining variable with the last message block, and the output of that is the actual output of the hash function i.e. the digest/tag.\n",
    "\n",
    "To summarize, we basically use these small hash functions (who are able to compress/hash only small messages), called compression functions, to build a large hash function (that can hash really long messages).\n",
    "\n",
    "**Why that Padding Block(PB)?**<br>\n",
    "The padding block is actually very important. Well it's a sequence of 1000 that denotes the end of the actual message block. And then the most important part of it is that we encode the message length in this padding block. And the message length is basically fixed to be 64 bits. So, **in all the SHA hash functions the maximum message length is $2^{64} - 1$** such that the message length fits into a 64 bit block. An this upper bound of $2^{64} - 1$ bit on the message length is actually sufficiently long to handle all of the messages that we're ever gonna throw at it.\n",
    "\n",
    "Ques: What do we do if the last block really is a multiple of the compression function block length? Where are we gonna fit the padding block?<br>\n",
    "Ans: Basically if there's no space for the padding block in the last block of the message, then we're gonna add another dummy block (of the compression function block length) and stick the padding block in there. And of course put the 1000.. in the right place. Okay so the point is that it's very, very important that the padding block contains the message length as we'll see later.\n",
    "\n",
    "**The Theorem that made Merkle-Damgard popular**\n",
    "\n",
    ">As mentioned above, all standard hash functions follow this paradigm for constructing a collision resistant hash function from a compression function. The reason that this paradigm is so popular is because of the following theorem, which says basically that: **If the little compression function is collision resistant, then the big Merkle-Damgard hash function is also collision resistant.** In other words, if we're going to build collision resistant functions for large inputs, all we have to do is just build compression functions that are collision resistant. \n",
    "\n",
    "So, given below is the proof for this theorem. It's a elegant proof and not too difficult. The way we're gonna prove it is using the contrapositive, that is, if you can find me a collision on the big hash function then we're gonna deduce a collision on the little compression function. Therefore, if little h is a collision resistant, so will be the big H.\n",
    "\n",
    "![](./Images/MD-Theorem.png)\n",
    "![](./Images/MD-Theorem-cont.png)\n",
    "Note: For in depth explanation of the theorem, please refer to [The Merkle-Damgard Paradigm](https://www.coursera.org/learn/crypto/lecture/Hfnu9/the-merkle-damgard-paradigm) at 4:32.\n",
    "\n",
    "#### Step 2: Constructing secure compression/small-hash function\n",
    "\n",
    "So we're going to see a couple of constructions. And so the first question that comes to mind is well, can we build compression functions from primitives that we already have? In particular, we spent a lot of work to build block ciphers and the question is can we build compression functions from block ciphers? And the answer is yes.\n",
    "\n",
    "**Compression function from Block Ciphers**\n",
    "\n",
    "Assume we have a certain block cipher E that operates on n bits blocks, so the input is n bits, output is n bits. And then there's this classic construction called a **Davies-Meyer** compression function construction (there are many other block cipher based compression function constructions but Davies-Meyer is the prominent one). \n",
    "\n",
    "![](./Images/Davies-Meyer.png)\n",
    "The way it works is:\n",
    ">Given the message block and the chaining variable, all it do is encrypt the chaining variable using the message block as the key. And then it do one more XOR with the chaining variable H to produce the output. So this might seem a little bizarre, because remember the message block is something that's completely under the control of the adversary. He's trying to find the collision so he can choose the message blocks however he wants. And yet we're using this message block as a key into a block cipher. But nevertheless, we can argue that this construction, at least when E is what's called an ideal cipher, we can argue that this construction is in fact as collision resistant as possible.\n",
    "\n",
    "KeyNote: **The best possible collision resistance that a Hash function could ever achieve is $O(2^{n/2})$ as per the Generic Birthday Attack (where n represents the tag/digest length)**. Hence, the what the above theorem (and its provable) is trying to say is, given that E is an ideal block cipher and Davies-Meyer using message as the key to the cipher, still finding a collision would be of the order $O(2^{n/2})$, which is best collision resistance possible.\n",
    "\n",
    "Warning: If we drop the final XOR of the output of the Encryption function with the chaining variable H in the Davies-Meyer construction then the compression function will, provably, not be collision resistant. So, that XOR b/w the output from E and chaining variable H is very crucial.\n",
    "\n",
    "**Case Study: SHA-256** <br>\n",
    "Now, basically, we have all the ingredients to describe the SHA-256 hash function.\n",
    "\n",
    "![](./Images/CaseStudy-SHA256.png)\n",
    "- SHA-256 is a Merkel-Damgard construction, exactly as the one that we saw before. \n",
    "- It uses a Davies-Mayer compression function. And so the only question is, what's the underlying block cipher for Davies-Mayer? - The block cipher is called SHACAL-2. We will just see its parameters. \n",
    "    - It uses a 512 bit key. And remember the key is taken from the message block in Davies-Mayer. So, this is really what the  size of the message block is i.e. SHA-256 will process its input message 512 bits at a time. \n",
    "    - It uses a 256-bit block size for messages and these are the chaining variable in Davies-Mayer, therefore SHA-256 produces a 256-bit digest.\n",
    "    \n",
    "**Provable Compression Functions**\n",
    "\n",
    "It turns out there's another class, besides the block cipher class, of compression functions that's built using hard problems from number theory. We call these compression functions **provable because if you can find the collision on this compression function then you're going to be able to solve a very hard number theoretic problem which is believed to be intractable**. And as a result, if the number theory problem is intractable, the resulting compression function is provably a collision resistant.\n",
    "\n",
    "Given below is an example of a provable compression function.\n",
    "![](./Images/ProvableCompressionFunc.png)\n",
    "Note: Why do we don't use these compression functions? Due to the fact that they give very slow performance as compared to block cipher based compression functions.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HMAC (a MAC from SHA-256)\n",
    "Corresponding Watch: [HMAC](https://www.coursera.org/learn/crypto/lecture/OjMrT/hmac)\n",
    "\n",
    "The fundamental question that we are trying to address here is: Can we use a Hash function(large) to build a MAC?\n",
    "\n",
    "Suppose we have a Merkle-Damgard hash function (say SHA-256), it hashes large messages into small digests and we want to convert that directly into a Mac. The first thing that comes to mind is well why don't we just hash the concatenation of the MAC key as long with the message that we're trying to MAC? It turns out that this is completely insecure. Why is this is insecure? The answer is the standard extension attack.\n",
    "\n",
    "![](./Images/MDExtensionAttack.png)\n",
    "Description:<br>\n",
    "Realize that if adversary gets the tag T = H(m) of a particular message, in other words he gets the value at the blue point. It's very easy for the attacker to just add another block (m' = blocks of m + w block), and then compute one last stage of the compression function H (with Tag T as the chaining variable and w as the final message block). And now he'll be able to get a valid tag (as we are using this output of Merkle-Damgard as tag) for the new message m' (which is original message concatenated the padding block, concatenated the w block that he added himself) and as a result this is an existential forgery. \n",
    "\n",
    "Then how do we construct MAC out of Hash?<br>\n",
    ">There's a **standardized method to convert a collision resistant hash function to a MAC and that method is called HMAC**. In particular, we could use the SHA-256 hash function to build this MAC. The output is going to be 256 bits and in fact HMAC is believed to be a pseudo-random function, so out of SHA-256 we build a pseudo-random function that outputs 256 bit outputs. \n",
    "\n",
    "![](./Images/StandardMethod-HMAC.png)\n",
    "[ || represents prepending ]\n",
    "\n",
    "The Flow:<br>\n",
    "- First we take our key k and we concatenate what's we call an internal pad to it, an ipad to it. This makes it into one block of the Merkle-Damguard construction, so for example this would be 512 bits in the case of SHA256 (as it uses SHACAL-2). <br><br>\n",
    "- We prepend(||) this to the message m (i.e. the k XOR ipad block is prepended to the m blocks) and then we do the complete hashing process. Now this by itself we just said is completely insecure. <br><br>\n",
    "- However, what HMAC does in addition, it takes the output, which is 256 bits, it prepends to that the key again XOR with, what's called the outer pad, the opad. This also becomes 512 bits. It's one block. And then it hashes the combination of these two to finally obtain the resulting tag on the message m. \n",
    "\n",
    "Note: The ipad and the opad are fixed 512-bits constants that never changes.\n",
    "\n",
    "![](./Images/HMACinPicture.png)\n",
    "HMAC is very identical to NMAC (see corresponding watch for explanation), the only difference is that keys k1 and k2 in NMAC were independent whereas in HMAC are dependent.\n",
    "\n",
    "Following are the properties of HMAC:\n",
    "![](./Images/HMAC-Properties.png)\n",
    "\n",
    "#### Time Attacks on MAC verification\n",
    "\n",
    "Lets look at a general attack that affected and still affects many implementations of MAC algorithms. And there's a nice lesson to be learned from an attack like this.\n",
    "\n",
    "We'll look at a particular implementation of HMAC verification. This happens to be an implementation from the Keyczar library, that happens to be written in Python. So given below is a snippet of the simplified version of the code that's used to verify a tag generated by HMAC. \n",
    "![](./Images/WeaknessInImplementation.png)\n",
    "\n",
    "The inputs are as follows: the key, the message, and the tag bytes. The way it verify it is, it re-compute the HMAC on the message and then compares the resulting sixteen bytes to the actual given signature bites. So this looks perfectly fine. In fact, anyone might implement it like this. And, in fact, many people have implemented it like this.\n",
    "\n",
    ">The problem is, that if you look at how the comparison is done, the comparison, as you might expect, is done byte by byte. There's a loop inside of the Python interpreter that loops over all sixteen bytes. And it so happens that the first time it finds an inequality, the loop terminates and says the strings are not equal. And the fact that the comparator exits when the first inequality is found introduces a significant timing attack on this library. . \n",
    "\n",
    "Let's see how an attack can be done against the above verification implementation.\n",
    "![](./Images/VerificationTimingAttacks.png)\n",
    "Description:<br>\n",
    "- What the attacker is gonna do is to submit many message tag queries, where the message is always the same but with a tag, he's gonna experiment with lots and lots and lots of different tags.<br><br>\n",
    "- So in the first query, what he's gonna do is just submit a random tag along with the target message. And he's gonna measure how long the server took to respond.<br><br>\n",
    "- With the next query that he's gonna submit, he's gonna try all possible first bytes for the tags. So, the remaining bytes of the tags that he submits are just arbitrary, doesn't really matter what they are. But for the first byte, what he'll do is he'll submit a tag starting with a byte value zero. And then he's gonna see whether the server took a little bit longer to verify the tag than before. If the server took exactly the same amount of time to verify the tag as in step one, then he's gonna try again, this time with (first)byte's value one. If still the server responded very quickly, he's going to try with byte value two and so on.<br><br>\n",
    "- Until finally, let's say, when the byte sets of as 3 the server takes a little bit longer to respond. What that means is actually when it did the comparison between the correct MAC and the MAC submitted by the attacker. The two matched on the 1st byte, and the rejection happened on the second bytes. Aha. So now the attacker knows that the first byte of the tag is set to 3 and now he can mount exactly the same attack on the second byte and similarly for all the remaining bytes of the tag.\n",
    "\n",
    "This way the attacker can use this implementation weakness and commit a side channel attack (here timing attack) to achieves the goal of existential forgery.\n",
    "\n",
    "Following are the Defenses against timing verification attack:\n",
    "\n",
    "Defense 1\n",
    "![](./Images/Defense1-VTA.png)\n",
    "Description:<br>\n",
    "What we do is implement our own comparator. And it will always take the same amount of time to compare the two strings. So in particular, this uses the zip function in Python, which will, essentially, if you are giving it two sixteen byte strings, it will create sixteen pairs of bytes. So it'll just create a, a list of sixteen elements, where each element is a pair of bytes. One taken from the left and one taken from the right. And then you loop through this list of pairs. You compute the XOR of the first pair, and the OR into the result. Then you compute the XOR of the second pair, and you OR that into the result. And you note that, if at any point in this loop, two bytes happen to be not equal, then the XOR will evaluate to something that's non zero and when we OR'ed (result = result | ord(x)^ord(y)) it into the result. The result will also become non-zero, and then we'll return false, at the end of the comparison. So, the comparison this way will always take the same time.\n",
    "\n",
    "However, this can be quite problematic, because compilers tries to be too helpful here. So an optimized compiler might look at this code and say, hey, wait a minute. I can actually improve this code by making the four loop end. As soon as an incompatible set of bytes is discovered.\n",
    "\n",
    "Defense 2\n",
    "![](./Images/Defense2-VTA.png)\n",
    "Description:<br>\n",
    "The way we do the comparison is we first of all, compute the correct MAC on the message. But then instead of directly comparing the MAC and the signature bytes from adversary, what we're gonna do is we're gonna hash one more time. So we compute a hash here of the MAC. We compute a hash of the signature bytes. Of course, if these two happen to be the same, then the resulting HMACs will also be the same, so the comparison will actually succeed. But the point is now, if signed bytes happen to equal MAC on say first 3 bytes, but not on the remaining bytes. Then, when we do this additional hash layer, it's likely that the two resulting values are completely different. And as a result, the byte by byte comparator will just output on the first iteration. The point here is that the adversary doesn't actually know what strings are being compared. And as a result, he can't mount a timing attack that we discussed earlier.\n",
    "\n",
    "The Ultimate Lesson: \n",
    ">Realize that people who even are experts at implementing crypto libraries, get this stuff wrong (as seen with Keyczar). And even the right code that works perfectly fine and yet is completely vulnerable to a timing attack that completely undo all security of the system. So **the lesson here is, of course, you should not be inventing your own crypto but you shouldn't even be implementing your own crypto** because most likely it'll be vulnerable to the side channel attacks. Just use a standard library like OpenSSL etc.\n",
    "\n",
    "![](./Images/UltimateLesson.png)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Authenticated Encryption\n",
    "\n",
    "In this section, we're going to see how to combine these confidentiality and integrity mechanisms to obtain encryption schemes that are secure against a much, much stronger adversary, namely an adversary that can tamper with traffic while it's in the network, inject its own packets, block certain packets, and so on.\n",
    "\n",
    "Goal: And our goal is basically to ensure that even against such powerful adversaries, we maintain confidentiality. In other words, the adversary can't learn what the plain text is and the adversary can't even modify the cipher text. \n",
    "![](./Images/AuthEncryp-Recap.png)\n",
    "\n",
    "**Passive vs Active Adversary**\n",
    ">Passive Adversary: In crypto, we tend to think of a passive adversary (Eve) as someone who is able to listen to all communications sent between two parties, (Alice and Bob). So, you create a security goal based on the \"power\" of your adversary. If all that Eve is doing is listening on communications, then Alice and Bob need to ensure that Eve cannot understand whatever it is she reads (hence achieve confidentiality via CPA-security).<br><br>\n",
    "Active Adversary: Intuitively, active adversary is an adversary which is has the ability to interact actively with the communicating parties or to tamper with the communication data over the medium, besides just eavesdropping or sniffing over the communication. \n",
    "\n",
    "Note: \n",
    "- In general, Eve is name assigned to a Passive attacker and Mallory to an Active attacker.\n",
    "- We create a security goal based on the \"power\" of the adversary (Threat Model).\n",
    "\n",
    "#### Why Authenticated Encryption is so important? (Active Attacks on CPA-Secure Encryptions)\n",
    "\n",
    "We'll understand this via an example of adversaries that can tamper with traffic and as a result completely break security of CPA-secure encryption. This will show you that, without providing integrity, confidentiality can also be destroyed. In other words, the two must go together, integrity and confidentiality, if we're going to achieve security against active adversaries. So let's look at an example from the world of networking. \n",
    "\n",
    "![](./Images/SampleTamperingAttack.png)\n",
    "Description:<br>\n",
    "Let's look at TCP/IP. We are going to use a highly simplified version of TCP/IP. Here we have two machines communicating with one another. A user sits at one machine, and the other machine is a server. Now, the server, of course, has a TCP/IP stack that's receiving packets. And then, based on the destination field in those packets, it forwards the packets to the appropriate place/port. So here we have, for example, two processes listening to these packets. A web server and another user (we'll call him Bob). The web server listens on port 80, and Bob listens on the port 25. \n",
    "\n",
    "When a packet arrives, the TCP/IP stack looks at the destination port. In case, it would be destination port 80, and as a result, the stack forwards the packets over to the web server. If the destination port said port 25, the TCP/IP stack would forward the packet over to Bob, who's listening on port 25.\n",
    "\n",
    "Now, a fairly well known security protocol called IPsec, encrypts these IP packets between the sender and the recipient(server). So here, the sender and the recipients basically have a shared key. And when the sender sends IP packets, those IP packets are encrypted using the secret key K. Now when a packet arrives at the destination, and I mean it arrives at the server, the TCP/IP stack will go ahead and decrypt the packet, and then look at the destination port and send it to the appropriate place decrypted. \n",
    "\n",
    "![](./Images/ReadingSomeone'sData.png)\n",
    "\n",
    "Imagine the attacker intercepts a certain packet that's intended for the web server. In other words, it's an encrypted packet intended for port 80. So what Bob (who is playing the adversary here) is going to do is he's gonna intercept this packet and prevent the packet from reaching the server as it is, and instead, he's going to modify the packet (i.e. change the destination port value). So now the destination port is going to read like port 25. This is done on the cipher text and we're going to see how to do that. When this packet now arrives at the server, the destination port says 25, the server will decrypt the packet, see that the destination is 25 and forward the data over to Bob. So, simply by changing the destination port, Bob was able to read data that was not intended for himself.\n",
    "\n",
    "**How can adversary switch the port address on the ciphertext?**<br>\n",
    "So, if the data is encrypted, say, using a CBC encryption with a random IV, remember this is a CPA-secure scheme. Nevertheless, if this is the case then it's trivial for the attacker to change the cipher text. So that now he can obtain new cipher text where the destination port is 25 instead of 80. The only thing that's gonna change is just the IV field. In fact, everything else is gonna remain the same. By simply modifying the IV field the attacker would be able to switch the destination port number. This would be done as follows:\n",
    "\n",
    "![](./Images/ModifyingPortAddress.png)\n",
    "\n",
    "The way adversary decrypts CBC encrypted data is essentially the first plain text block is simply decryption of the first cipher text block XORed with IV, that is, **m [ 0 ] = D ( k , c [ 0 ] ) XOR IV** and this equation is going to read 80 (when first block is representing the destination port) now to if he simply XOR this equation with a message size block that represents value 80 then that would make the first block's value zero and now if he further XOR this with a message size block that represents value 25, then that would make the first block's value to be 25. Following would be the equation **m[ 0 ] = D ( k , c [ 0 ] ) XOR IV XOR (..80..) XOR (..25..)**, where (..xx..)represents a block with value corresponding to xx in binary representation. Hence, the destination port now has the value of 25 and the server on receiving the packet will decrypt it, check the the port value, and send to the adversary (Bob) who listening at port number 25.\n",
    "\n",
    "Note: There are different types of Active attacks that adversary can do, if we only use security schemes that provide confidentiality, CPA-security, without integrity (and that would be result in confidentiality of no use, as it would get compromised).\n",
    "\n",
    "![](./Images/LessonFromAttack-AuthEncryp.png)\n",
    "<br>\n",
    "\n",
    "----\n",
    "<br>\n",
    "\n",
    "### Authenticated Encryption: Definition\n",
    "\n",
    "Authenticated encryption is a cipher where as usual the encryption algorithm takes a key, a message and optionally a nonce and outputs a cipher text. The decryption algorithm as usual outputs a message. However, here the decryption algorithm is allowed to output a special symbol called bottom (inverted T). When the decryption algorithm outputs the symbol bottom, basically it says that the cipher text is invalid and should be ignored. The only requirement is that this bottom is not in the message space so that in fact it is a unique symbol that indicates that the cipher text should be rejected. \n",
    "![](./Images/AuthenticatedEncryption.png)\n",
    "Now what does it mean for an authenticated encryption system to be secure? Well the system has to satisfy two properties:\n",
    "- It has to be **semantically secure** under a chosen plaintext attack just as before. \n",
    "- But now there's a second property which says that the system also has to satisfy what's called **cipher text integrity**. What that means is that even though the attacker gets to see a number of cipher texts, it should not be able to produce another cipher text that decrypts properly. In other words, that decrypts to something other than bottom.\n",
    "\n",
    "More precisely, let's look at the ciphertext integrity game:\n",
    "\n",
    "![](./Images/EncryptionWithCiphertxtIntegrity.png)\n",
    "Description:<br>\n",
    "- So here, (E,D) is a cipher with message space M. As usual, the challenger begins by choosing a random key K. And the adversary can submit messages of his choice, and receive the encryptions of those messages. So here, $c_{1}$ is the encryption of $m_{1}$, where $m_{1}$ was chosen by the adversary. And the adversary can do this repeatedly. Therefore, he submits many more messages up until $m_{q}$ and obtains the encryption of all those messages. \n",
    "- Hence, the adversary obtained q ciphertexts for messages of his choice. Then his goal is to produce some new cipher text that's valid. So we'll say that the adversary wins the game if basically this new cipher text that the adversary created decrypts correctly, in other words decrypts to something other than bottom (inverse T). \n",
    "- As usual we defined the adversary's advantage in the cipher text integrity game as the probability that the challenger outputs one at the end of the game and we'll say that the cipher has cipher text integrity if in fact for all efficient adversaries the advantage in winning this game is negligible.\n",
    "\n",
    "Following is a bad example of Authenticated Encryption (a CPA secure cipher that doesn't provide authenticated encryption):\n",
    "![](./Images/BadExOfAuthEncryp.png)\n",
    "The CBC with a random IV does not provide authenticated encryption because it's very easy for the adversary to win the cipher text integrity game. The adversary simply submits a random cipher text and since the decryption algorithm for CBC encryption never outputs bottom, it always outputs some message, the adversary just easily wins the game. Any old random cipher text will decrypt to something other than bottom and therefore the adversary directly wins the cipher-text integrity game. So this is just a trivial example of a CPA secure cipher that does not provide authenticated encryption.\n",
    "\n",
    "**Implications of Authenticated Encryption**:\n",
    "\n",
    "**Implication 1: Authenticity**\n",
    "\n",
    "![](./Images/Implication1-AE.png)\n",
    "\n",
    "The first implication is Authenticity, which means that, basically, an attacker cannot fool the recipient, Bob, into thinking that Alice sent a certain message that she didn't actually send. What it means is: \n",
    "- Here, the attacker basically gets to interact with Alice, and get her to encrypt arbitrary messages of his choice. So this is a chosen plain text attack. And then the attacker's goal is to produce some cipher text that was not actually created by Alice. - Because the attacker can't win the cipher text integrity game, he can't do this. What this means is, when Bob receives the cipher text that decrypts correctly under the decryption algorithm, he knows that the message must have come from someone who knows the secret key K. In particular, if Alice is the only one who knows K, then he knows the cipher text really did come from Alice, and it's not some modification that was sent by the attacker. \n",
    "\n",
    "Caveat to Authenticity:<br>\n",
    "The only caveat to that is that authenticated encryption doesn't defend against replay attacks. In particular, the attacker could've intercepted some cipher text from Alice to Bob. And could have replayed it and both cipher text would look valid to Bob. So for example, Alice might send a message to Bob saying transfer 100 dollars to Charlie. Then Charlie (playing an adversary) could replay that cipher text and as a result, Bob would transfer another 100 dollars to Charlie. So in fact, any encryption protocol has to defend against replay attacks and this is not something that's directly prevented by authenticated encryption. \n",
    "\n",
    "**Implication 2: Security against CCA (Chosen Ciphetext Attack)**\n",
    "![](./Images/Implication2-AE.png)\n",
    "\n",
    "The second implication of authenticated encryption is that it defends against a very powerful type of adversary, namely an adversary that can mount what's called a chosen cipher text attack. \n",
    "\n",
    "#### Chosen Ciphertext Attacks (and Security)\n",
    "Corresponding Watch: [Chosen Ciphertext Attacks](https://www.coursera.org/learn/crypto/lecture/MKepS/chosen-ciphertext-attacks)\n",
    "\n",
    "Following depicts the Threat model (powers and goals of the adversary) for Chosen ciphertext security.\n",
    "![](./Images/CCA-ThreatModel.png)\n",
    "\n",
    "**Chosen Ciphertext Security Model:**\n",
    "\n",
    "Lets define the Chosen ciphertext security model more precisely. So, as usual, we have a cipher (E, D). And we're gonna define two experiments, EXP(0) and EXP(1). The challenger is gonna start off by choosing a random key. And now the adversary is gonna submit queries to this challenger. <br> \n",
    "Every query can be one of two types:\n",
    "- It can be a chosen plain text query(CPA-query), or \n",
    "- It can be a chosen cipher text query(CCA-query). \n",
    "\n",
    "![](./Images/ChosenCiphertxtSecurityModel.png)\n",
    "\n",
    "CPA Query:<br>\n",
    ">In a chosen plain text query, as we already know, the adversary submits two messages, $m_{0}$ and $m_{1}$. They have to be the same length. And the adversary receives the encryption of either $m_{0}$ if we're in EXP(0), or $m_{0}$, if we're in EXP(1). \n",
    "\n",
    "CCA Query:<br>\n",
    ">This is where the adversary submits an arbitrary cipher text of his choice and what he gets back is the decryption of that cipher text (such scenarios do take place in real-world). So you notice the adversary is allowed to decrypt arbitrary cipher texts of his choice. The only restriction is that the ciphertext is not one of the ciphertexts (referred to as challenge ciphertexts) that were obtained as a result of a CPA query. And of course this wouldn't be fair otherwise, because the attacker can simply take one cipher text that was obtained from a CPA query. That's gonna to be either the encryption of $m_{0}$ or the encryption of $m_{1}$. If he could submit a CCA query for that particular ciphertext, he will in response either obtain $m_{0}$ or $m_{1}$, and then he'll know whether he is in EXP(0) or EXP(1) and that would breach the CPA-security. \n",
    "\n",
    "Adversary's goal is to determine whether he's in EXP(0), or in EXP(1). Remember that this is an extremely powerful adversary. One that can decrypt any cipher text of his choice other than the challenge cipher text (and can obviously get messages of his choice encrypted and getting back the challenge ciphertexts). And still, he can't distinguish whether he is in EXP(0), or in EXP(1). \n",
    "\n",
    "**CCA Secure Ciphers**<br>\n",
    ">So, we say that the cipher is CCA secure, chosen cipher text secure, if the adversary behaves the same in EXP(0) as it does in EXP(1) i.e. the cipher(E) is CCA secure if, for all efficient Adversaries A, the $Advantage_{CCA}$ of A over the E is negligible. And $Advantage_{CCA}$ will be negligible if the probability that adversary outputs 1 in EXP(0) (wrongly identifying that the exp gave the ciphertext for $m_{1}$ whereas the output was for $m_{0}$) is same as the probability that he outputs 1(correctly identifying) in EXP(1). Basically, he isn't able to distinguish the two experiments.\n",
    "\n",
    "![](./Images/CCA-Secure.png)\n",
    "\n",
    "CBC, and similarly other CPA-secure ciphers, aren't CCA-Secure <br>\n",
    "Lets see why? \n",
    "- The adversary's gonna start by submitting two distinct messages, $m_{0}$ and $m_{1}$. And let's just pretend that these messages are one block messages. And what he's gonna get back is the CBC encryption of either $m_{0}$ or $m_{0}$. Notice that the cipher text only has one block, because the plain texts were only one block long. Now what is the attacker gonna do?<br><br> \n",
    "- Well, attacker is gonna modify this cipher text c that he was given into c' simply by changing the IV. So, he just takes the IV and XORs it with one. That's it. This gives a new cipher text, c', which is different from c and as a result it's perfectly valid for the adversary to submit c' (as it's not a challenge ciphertext) as a chosen ciphertext query. So he asks the challenger please decrypt this c' for me. <br><br>\n",
    "- The challenger, because c' is not equal to c, must decrypt c'. And now let's see, what happens when he decrypts c prime? Well, what's the decryption of c', you probably remember from earlier, that if we XOR the IV by one, that simply XORs the plaintext by one. So now that adversary received $m_{0}$ XOR 1, or $m_{1}$ XOR 1, therefore now he can perfectly tell whether he's in EXP(0) or EXP(1). So the advantage of this adversary is basically one, because he can very easily tell which experiment he's in. And as a result he can win the chosen cipher text security game.\n",
    "\n",
    "**How do we design crypto-systems that are CCA secure? Ans: Authenticated Encryption**\n",
    "\n",
    "The theorem, given below, basically says, if you give me a cipher that provides authenticated encryption then the cipher can withstand chosen cipher text attacks. And more precisely, the theorem says the following: if we have an adversary that issues q queries (at most, q CPA queries and q chosen cipher text queries), then there are two efficient adversaries, B1 and B2, that satisfy the given inequality. \n",
    "![](./Images/AuthEncrypIsCCASecure.png)\n",
    "Since the scheme has authenticated encryption, we know that $Adv_{CPA}$ is negligible because it's CPA secure. And we know that $Adv_{CI}$ is negligible because the encryption scheme has Ciphertext Integrity. And as a result, since both terms are negligible we know that adversary's advantage, $Adv_{CCA}$, in winning the CCA game is also negligible.\n",
    "\n",
    "Proof: The proof of the above theorem is pretty simple. Lets look at it:\n",
    "![](./Images/AE-CCAProof.png)\n",
    "\n",
    "Description<br>\n",
    "- Here, on the left, we have two copies of the CCA game. The above would be EXP(0). And the bottom one represents EXP(0).<br><br> \n",
    "- You can see the adversary's issuing CPA queries, and he's issuing CCA queries, and at the end he outputs, you know, a certain guess b prime, and our goal is to show that this b prime is indistinguishable in both cases. In other words, probability that b prime is equal to one in the top, left, game is the same as the probability that b prime is equal to one in the bottom, left, game. <br><br>\n",
    "- Assume that we change/upgrade the challenger a little bit, so that instead of actually outputting the decryption of CCA queries, the challenger is just gonna always output bottom(inverted T). In picture, we changes the top left challenger to top right. Therefore, every time the adversary submits a CCA query, the challenger says bottom. And these two, top-left and right, games are indistinguishable. In other words, the adversary can't distinguish these two games, for the simple reason that, because the scheme has Ciphertext Integrity, the adversary simply cannot create a ciphertext that's not a challenge ciphertext that decrypts to anything other than bottom. And since the scheme has cipher-text integrity, these left and right games are indistinguishable.<br><br>\n",
    "- The same thing exactly applies on the bottom (left and right games), where we can simply replace the chosen cipher-text responses by just always saying bottom, thereby upgrading bottom left to bottom right. But now, since the chosen cipher text queries always respond in the same way, they're not giving the adversary any information. So he might as well just remove these queries, cause they don't contribute any information to the adversary and is only left with CPA-security aspect thing to win the game.\n",
    "\n",
    "![](./Images/AE-CCAProof-2.png)\n",
    "- Now, once we remove these queries, the resulting upgraded games should look fairly familiar. The top right game, and the bottom right game are basically the two games that come up in the definition of CPA security. And as a result, because the scheme is CPA secure, we know that the adversary can't distinguish the top from the bottom.\n",
    "\n",
    "Hence, Authenticated Encryption schemes are CCA-Secure.\n",
    "\n",
    "Limitations of Authenticated Encryption:\n",
    "- does not prevent replay attacks\n",
    "- does not account for side channels (timing) attacks.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Authenticated Encryption: Standard Constructions\n",
    "\n",
    "Since we already have CPA secured encryption, and we have secure MACs, the natural question is whether we can combine the two somehow, in order to get authenticated encryption and that's exactly what we're gonna do.\n",
    "\n",
    "History of Authenticated Encryption:\n",
    "\n",
    "![](./Images/AuthEncryp-History.png)\n",
    "\n",
    "Authenticated encryption was introduced in the year 2000, in two independent papers. But before then, many crytpo libraries provided an API that separately supported CPA secure encryption, and MAC-ing. \n",
    "- So there was one function for implementing CPA secure encryption (providing confidentiality). For example, CBC with a random IV. \n",
    "- And another function for implementing a MAC (providing integrity). \n",
    "\n",
    "And then every developer that wanted to implement encryption, had to, himself, call separately the CPA secure encryption scheme and the MAC scheme. In particular, every developer had to invent his own way of combining Encryption and MAC-ing to provide some sort of authenticated encryption. But since the goals of combining encryption and MAC-ing wasn't well understood since authenticated encryption hasn't yet been defined, it wasn't really clear which combinations of encryption and MAC-ing are correct and which aren't. And so, every project as said had to invent its own combination. And in fact, not all combinations were correct. And the most common mistake in software projects were basically incorrectly combining the encryption and integrity mechanisms.\n",
    "\n",
    "**Different Ways of Combining Encryption and MAC to achieve Authenticated Encryption**\n",
    "\n",
    "Given below are three examples (ways of combining). In all three examples, there's a separate key for encryption, and a separate key for MACing. These two keys are independent of one another, and both are generated at session setup time. And we're gonna see how to generate these two keys later down the road.\n",
    "\n",
    "![](./Images/CombiningMAC&Enc.png)\n",
    "\n",
    "1. First example is the SSL protocol. So the way SSL combines encryption and MAC in the hope of achieving authenticated encryption is the following: basically you take the plain text, m, and then you compute a MAC on the plain text, m. So you use your MAC key, $k_{I}$, to compute tag for this message m. And then you can concatenate the tag to the message and then you encrypt the concatenation of the message and the tag and what comes out is the actual final ciphertext.<br><br>\n",
    "\n",
    "2. The second option is what IPsec does. So here, you take the message. The first thing you do is you encrypt the message. And then, you compute a tag on the resulting cipher text. So you notice the tag itself is computed on the resulting cipher text. <br><br>\n",
    "\n",
    "3. Third option is what the SSH protocol does. So here, the SSH takes the message, and encrypts it using a CPA secure encryption scheme. And then, to it, it concatenates a tag of the message. The difference between IPsec and SSH, is that in IPsec, the tag is computed over the cipher text, whereas, in SSH, the tag is computed over the message.\n",
    "\n",
    "And so these are three completely different ways of combining encryption and MAC. And the question is, which one of these is secure (as we mentioned that not all combinations are secure)?\n",
    "\n",
    "**Analyzing Combinations for CCA-Security**\n",
    "\n",
    "The SSH Method <br>\n",
    "Approach: **Encrypt-and-MAC**<br>\n",
    "Status: Insecure, don't use it.<br>\n",
    "Description:<br>\n",
    "In the SSH method you notice that the tag is computed on the message and then concatenated in the clear to the ciphertext. Now this is actually quite a problem because MACs themselves are not designed to provide confidentiality. MACs are only designed for integrity. And in fact, there's nothing wrong with a MAC that as part of the tag outputs a few bits of the plain text. That would be a perfectly fine tag. And yet if we did that, that would completely break CPA security here, because some bits of the message are leaked in the cipher text. And so the SSH approach, even though the specifics of SSH are fine and the protocol itself is not compromised by this specific combination, generally it's advisable not to use this approach. Simply because the output of the MAC signing algorithm might leak bits of the message. \n",
    "\n",
    "The SSL Method<br>\n",
    "Approach: **MAC-then-Encrypt**<br>\n",
    "Status: Partially Secure, can be used with certainty of providing Authenticated Encryption when Encryption scheme is rand-CTR mode or rand-CBC <br>\n",
    "Description:<br>\n",
    "As it turns out, for the SSL approach, there actually are kind of pathological examples, where you combine CPA secure encryption system with a secure MAC. And the result is vulnerable to a chosen cipher text attack, so that it does not actually provide authenticated encryption. And basically, the reason that could happen, is that there's some sort of a bad interaction between the encryption scheme and the MAC algorithm. Such that, in fact, there will be a chosen cipher text attack.\n",
    "\n",
    "The IPsec Method<br>\n",
    "Approach: **Encrypt-then-MAC**<br>\n",
    "Status: Completely Secure, recommended way to achieve authenticated encryption <br>\n",
    "Description:<br>\n",
    "The recommended method actually is the IPsec method because it turns out no matter what CPA secure system and MAC key you use the combination is always gonna provide authenticated encryption. We'll very, very briefly see why. Basically what happens is once we encrypt the message, well the message contents now is hidden inside the cipher text and now when we compute a tag of the cipher text basically we're locking, this tag locks the cipher text and makes sure no one can produce a different cipher text that would look valid. And as a result this approach ensures that any modifications to the cipher text will be detected by the decrypter simply because the MAC isn't gonna verify.\n",
    "\n",
    "![](./Images/AE-Theorems.png)\n",
    "\n",
    "Bottom Line: So if you're designing a new project the recommendation now is to always use Encrypt-then-MAC (IPsec method) because that is secure no matter which CPA secure encryption and secure MAC algorithm you're combining. \n",
    "\n",
    "**Authenticated Encryption: Standards**<br>\n",
    "Once the concept of authenticated encryption became more popular, a number of standardized approaches for combining encryption and MAC turned up. So we are going to see three of these standards, namely GCM, CCM and EAX. Two of these were standardized by NIST and they are called Galois Counter Mode(GCM) and CBC Counter Mode(CCM) .\n",
    "\n",
    "![](./Images/AE-Standards.png)\n",
    "Description: <br>\n",
    "1. **Galois Counter Mode(GCM)**: GCM basically uses counter mode encryption, so a randomized counter mode with a Carter-Wegman MAC, so a very fact Carter-Wegman MAC. And the way the Carter-Wegman MAC works in GCM is it's basically a hash function of the message that's being MACed. And then the result is encrypted using a PRF. Now this hash function in GCM is already quite fast to the point where the bulk of the running time of GCM is dominated by the counter mode encryption and it's even made more so in that Intel introduces a special instruction PCLMULQDQ specifically designed for the purpose of making the hash function in GCM run as fast as possible.<br><br>\n",
    "\n",
    "2. **CBC Counter Mode(CCM)**: CCM is another NIST standard. It uses a CBC MAC and then counter mode encryption. So this mechanism uses MAC, then encrypt, like SSL does. So this is actually not the recommended way of doing things, but because counter mode encryption is used this is actually a perfectly fine encryption mechanism. <br>\n",
    "One thing about CCM is that everything is based on AES. You notice, it's using AES for the CBC MAC, and it's using AES for the counter mode encryption. And as a result, CCM can be implemented with relatively little code. Cause all you need is an AES engine and nothing else. And because of this, CCM actually was adopted by the Wi-Fi alliance, and in fact, you're probably using CCM on a daily basis if you're using encrypted Wi-Fi 802.11i then you're basically using CCM to encrypt traffic between your laptop and the access point.<br><br>\n",
    "\n",
    "3. **EAX:** EAX uses counter mode encryption, and then CMAC. So, again you notice encrypt-then-MAC and that's another fine mode to use.\n",
    "\n",
    "Note: \n",
    "- All these modes are nonce-based. In other words, they don't use any randomness but they do take as input a nonce and the nonce has to be unique per key i.e. the pair (key, nonce) should never ever, ever repeat. But the nonce itself need not be random, so it's perfectly fine to use a counter as a nonce. \n",
    "- And the other important point is that, in fact, all these modes are what's called **Authenticated Encryption with Associated Data**. \n",
    "\n",
    "\n",
    "What's Authenticated Encryption with Associated Data (AEAD)?\n",
    " \n",
    ">This is an extension of authenticated encryption, that comes up very often in networking protocols. So the idea between AEAD is that, in fact, the message that's provided to the encryption mode is not intended to be fully encrypted. Only part of the message is intended to be encrypted, but all of the message is intended to be authenticated. \n",
    "\n",
    "To get more clarity on AEAD, let's understand it with an example:\n",
    "\n",
    "A good example of this is a network packet. Think of a IP packet where there's a header and then there's a payload. And typically the header is not gonna be encrypted. For example, the header might contain the destination of the packet, but then the header had better not be encrypted otherwise routers along the way wouldn't know where to route the packet. And so, typically the header is sent in the clear, but the payload, of course, is always encrypted.\n",
    "\n",
    "But what you'd like to do is have the header be authenticated. Not encrypted but authenticated. So this is exactly what these AEAD modes do. They will authenticate the header and then encrypt the payload. But the header and the payload are bound together in the authentication so they can't actually be separated. So this is not difficult to do. What happens is in these three modes GCM, CCM, and EAX, basically the MAC is applied to the entire data. But the encryption is only applied to the part of the data that needs to be encrypted.\n",
    "\n",
    "An example API for Authenticated Encryption Standard (GCM):\n",
    "![](./Images/AE-ExampleAPI.png)\n",
    "<br>\n",
    "\n",
    "----\n",
    "<br>\n",
    "\n",
    "**Detour: Rewinding and Clarifying an obscure Notion of MAC Security**\n",
    "\n",
    "The obscure notion in the definition of secure MAC:<br>\n",
    "Recall, one of the requirements that followed from our definition of secure MACs meant that given a message-MAC pair on a message m, the attacker cannot produce another tag on the same message m. In other words, even though the attacker already has a tag for the message m, he shouldn't be able to produce a new tag for the same message m. And it's really not clear, why does that matter? Who cares, if the adversary already has a tag on the message m, who cares if he can produce another tag? \n",
    "\n",
    "Well, it turns out if the MAC didn't have this property. In other words, **given a message-tag pair you can produce another MAC on the same message, then that MAC would result in an insecure Encrypt-then-MAC mode**. And so if we want our encrypt-then-MAC to have cipher text integrity, it's crucial that our MAC security would imply this strong notion of security, which, of course, it does because we defined it correctly.\n",
    "\n",
    "![](./Images/MACSecurity-Explanation.png)\n",
    "\n",
    "So let's see what would go wrong, if, in fact, it was easy to produce this type of tag forgery: \n",
    "- The adversary's gonnna start by sending two messages, $m_{0}$ and $m_{1}$ . And he's gonna receive, as usual, the encryption of one of them, either the encryption of $m_{0}$  or the encryption of $m_{1}$ . <br><br>\n",
    "- Since we're using Encrypt-then-MAC, the adversary receives the cipher text we'll call it $c_{0}$  and a MAC on the cipher text $c_{0}$ . Well now we said that given the MAC on a message the adversary can produce another MAC on the same message. So what he's gonna do is he's gonna produce another MAC(tag) on the message $c_{0}$ . Now he has a new cipher text c' = ($c_{0}$ ,T'), which is a perfectly valid cipher text because T' is a valid MAC of $c_{0}$ . Therefore, the adversary now can submit a chosen cipher text query on c' and this is a valid chosen cipher text query because it's different from c. It's a new cipher text.<br><br> \n",
    "- The poor challenger now is forced to decrypt this cipher text c', so he's going to send back the decryption of c'. It's a valid cipher text therefore the decryption of c' is the message $m_{b}$  but now the attacker just learned the value of b because he can test whether $m_{b}$  is equal to $m_{0}$  or to $m_{1}$ . <br><br>\n",
    "- As a result he can just output the correct b and he gets advantage 1 in defeating the scheme. \n",
    "\n",
    "Therefore, if our MAC security did not imply this, unforgeable tag property here, then there would be a Chosen Ciphertext Attack on Encrypt-then-MAC. And therefore, it would not be secure. So the fact that we define MAC security correctly means that encrypt-then-MAC really does provide authenticated encryption. And throughout all the MACs that we discussed actually do satisfy this strong notion of unforgeability. \n",
    "<br>\n",
    "\n",
    "----\n",
    "\n",
    "### A direct Authenticated Encryption construction from PRP: OCB\n",
    "\n",
    "**Prior to formalization of Authenticate Encryption:**<br>\n",
    "Before the concept of authenticated encryption was introduced everyone was just combining MACs and encryption in various ways in the hope of achieving some authenticated encryption. \n",
    "\n",
    "**Post Authenticated Encryption formalization:**\n",
    "\n",
    "After the notion of authenticated encryption became formalized and rigorous, people kind of started scratching their heads and said, hey, wait a minute, maybe we can achieve authenticated encryption more efficiently than by combining a MAC and an encryption scheme. \n",
    "\n",
    "In fact, if you think about how this combination of MAC and encryption works, let's say we combine counter mode with CMAC, then for every block of plaintext, you first of all have to use your block cipher for counter mode, and then you have to use to your block cipher again, for the CBC-MAC. **This means that if you're combining CPA secure encryption with a MAC, for every block of plaintext, you have to evaluate your block cipher twice, once for the MAC and once for the encryption scheme**. \n",
    "\n",
    "So the natural question was, can we construct an authenticated encryption scheme directly from a PRP, such that we would have to only evaluate the PRP once per block? <br>\n",
    "And it turns out the answer is yes, and there's this beautiful construction called **OCB**, that pretty much does everything you want, and is much faster than constructions that are separately built from an encryption and a MAC. \n",
    "\n",
    "![](./Images/AE-OCB.png)\n",
    "High Level Explanation:<br>\n",
    "- Here we have our input plain text, at the top. Notice that, first of all, OCB is parallelizable, completely parallelizable. So every block can be encrypted separately of every other block. <br><br>\n",
    "- The other thing to notice is that, you only evaluate your block cipher once per plain text block. And then you evaluate it one more time at the end to build your authentication tag and then the overhead of OCB beyond just a block cipher is minimal.<br><br>\n",
    "- All you have to do is evaluate a certain very simple function P. The nonce goes into the P you notice, the key goes into this P and then there is a block counter that goes into this P. So you just evaluate this function P, twice for every block and you XOR the result before and after encryption using the block cipher and that's it. That's all you have to do and then you get a very fast and efficient authenticated encryption scheme built from a block cipher. \n",
    "\n",
    "Why OCB isn't used?<br>\n",
    "So, if OCB is so much better than everything you've seen so far, all these three standards CCM, GCM and EAX why isn't OCB being used or why isn't OCB the standard? And the answer is a little sad. The primary answer that OCB is not being used is actually because of various patents. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
